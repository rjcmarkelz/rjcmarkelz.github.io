[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am generally interested in the complexities of nature and choose problems that require at least a paper and pencil to work out. I use data, mathematical models, and illustrations as tools to understand the beauty and complexity of nature.\nWhen not behind the command-line in my current role at Berkeley Institute for Data Science, I can be found exploring California’s extensive backcountry on foot, bicycle, or skis and documenting my adventures through illustration, photos or prose.\nCheck out my art portfolio: www.codymarkelz.art"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts. static/images/profile2.jpg\n\nstatic/images/profile2.jpg"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "BIDS Illustration\n\n\n\nproject management\n\n\nresearch\n\n\nBIDS\n\n\nscicomm\n\n\nscience\n\n\ncommunications\n\n\nvisualization\n\n\nillustration\n\n\ncontent creation\n\n\nscicomm portfolio\n\n\nurban sketching\n\n\n\n–Building Illustration for Event\n\n\n\nRJ Cody Markelz\n\n\nFeb 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScience Communications Manager\n\n\n\nproject management\n\n\nresearch\n\n\nBIDS\n\n\nscicomm\n\n\nscience\n\n\ncommunications\n\n\nvisualization\n\n\nillustration\n\n\ncontent creation\n\n\n\n–Professional SciComm, Illustration, DataViz Projects\n\n\n\nRJ Cody Markelz\n\n\nFeb 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Obsidian - 3\n\n\n\nproject management\n\n\nresearch\n\n\ntools\n\n\nobsidian\n\n\n\n–Personal Obsidian Knowledge Workflow\n\n\n\nRJ Cody Markelz\n\n\nFeb 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrinity Alps Trail Run\n\n\n\nspecies distribution\n\n\nmodeling\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\ntrail run\n\n\nexercise\n\n\nexplore\n\n\n\n–White Pines Revisited\n\n\n\nRJ Cody Markelz\n\n\nJan 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMount Eddy Trail Run\n\n\n\nspecies distribution\n\n\nmodeling\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\ntrail run\n\n\nexercise\n\n\nexplore\n\n\n\n–Foxtail Pines Revisited\n\n\n\nRJ Cody Markelz\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBaja Species 3\n\n\n\nGIS\n\n\ndata\n\n\ntrail run\n\n\nhike\n\n\nexplore\n\n\nphotography\n\n\nnature journal\n\n\nzine\n\n\nadventure\n\n\nGBIF\n\n\nbaja\n\n\nmexico\n\n\ntravel\n\n\n\n–Sierra La Leguna Biodiversity\n\n\n\nRJ Cody Markelz\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBaja Species 2\n\n\n\nGIS\n\n\ndata\n\n\ntrail run\n\n\nhike\n\n\nexplore\n\n\nphotography\n\n\nnature journal\n\n\nzine\n\n\nadventure\n\n\nGBIF\n\n\nbaja\n\n\nmexico\n\n\ncacti\n\n\n\n–Giant Cardon Cacti\n\n\n\nRJ Cody Markelz\n\n\nDec 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBaja Species 1\n\n\n\nGIS\n\n\ndata\n\n\ntrail run\n\n\nhike\n\n\nexplore\n\n\nphotography\n\n\nnature journal\n\n\nzine\n\n\nadventure\n\n\nGBIF\n\n\nbaja\n\n\nmexico\n\n\n\n–Crested Cara Cara\n\n\n\nRJ Cody Markelz\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdventure Zines\n\n\n\nGIS\n\n\ndata\n\n\ntrail run\n\n\nhike\n\n\nexplore\n\n\nillustration\n\n\nnature journal\n\n\nzine\n\n\nadventure\n\n\nart\n\n\n\n–Trail Running Zines\n\n\n\nRJ Cody Markelz\n\n\nNov 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nADSA Meeting Sketchnote\n\n\n\nresearch\n\n\nBIDS\n\n\nscicomm\n\n\nscience\n\n\ndata science\n\n\ncommunications\n\n\nvisualization\n\n\nillustration\n\n\ncontent creation\n\n\nscicomm portfolio\n\n\nsketchnotes\n\n\ndesign\n\n\nADSA\n\n\nUS-RSE\n\n\n\n–Live Meeting Sketchnote and Summary\n\n\n\nRJ Cody Markelz\n\n\nOct 25, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPyrodiversity\n\n\n\nGIS\n\n\ndata\n\n\nUSFS\n\n\nwildfire\n\n\ntrail run\n\n\nhike\n\n\nexplore\n\n\nnational geographic\n\n\nillustration\n\n\nnature journal\n\n\n\n–Fire History in the Klamath Mountains\n\n\n\nRJ Cody Markelz\n\n\nOct 14, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLAC Method for Comics Creation\n\n\n\nart\n\n\ncomics\n\n\ncolor\n\n\nprocess\n\n\nillustration\n\n\ncolor\n\n\nprocess art\n\n\ndrawing\n\n\nthumbnails\n\n\ncartographer\n\n\n\n–A Relentless Forward Progress Method\n\n\n\nRJ Cody Markelz\n\n\nOct 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDSxD Sketchnote\n\n\n\nresearch\n\n\nBIDS\n\n\nscicomm\n\n\nscience\n\n\ndata science\n\n\ncommunications\n\n\nvisualization\n\n\nillustration\n\n\ncontent creation\n\n\nscicomm portfolio\n\n\nsketchnotes\n\n\ndesign\n\n\nDSxD\n\n\n\n–Live Meeting Sketchnote and Summary\n\n\n\nRJ Cody Markelz\n\n\nSep 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShasta Sketchers\n\n\n\nart\n\n\nsketching\n\n\nadventure\n\n\nnature\n\n\nnature journaling\n\n\nmount shasta\n\n\nshastasketchers\n\n\ncommunity\n\n\n\n–Nature Journaling Club\n\n\n\nRJ Cody Markelz\n\n\nSep 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShasta Sketchers\n\n\n\nart\n\n\nsketching\n\n\nadventure\n\n\nbeer\n\n\nbikes\n\n\nmount shasta\n\n\nshastasketchers\n\n\ncommunity\n\n\n\n–Monthly Drink and Draw\n\n\n\nRJ Cody Markelz\n\n\nSep 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeart Rate Data Analysis\n\n\n\nGIS\n\n\ndata\n\n\nexercise\n\n\nquantified self\n\n\nheart rate\n\n\ncardio\n\n\ntraining\n\n\nadventure\n\n\n\n–Exercise Data Analysis\n\n\n\nRJ Cody Markelz\n\n\nAug 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMount Shasta Wilderness Wildflowers\n\n\n\nspecies distribution\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\nhike\n\n\nexercise\n\n\nexplore\n\n\nAnemone occidentalis\n\n\nwildflowers\n\n\nplants\n\n\nGBIF\n\n\ndr. seuss\n\n\n\n–Anemone occidentalis population\n\n\n\nRJ Cody Markelz\n\n\nAug 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArt-venture Kit and Sketches\n\n\n\nart\n\n\nexplore\n\n\nwatercolor\n\n\npaint\n\n\ndraw\n\n\nadventure\n\n\nsketch\n\n\n\n–Lightweight Portable Art Kits\n\n\n\nRJ Cody Markelz\n\n\nJul 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUC Reserve Fire Data\n\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\nfire\n\n\nwildfire\n\n\nclimate\n\n\nresearch\n\n\ngeospatial\n\n\n\n–2020 Fire Data Visualization\n\n\n\nRJ Cody Markelz\n\n\nJul 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeadwaters Race\n\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\ntrail run\n\n\nexercise\n\n\nrace\n\n\nexplore\n\n\n3D\n\n\n\n–56km Ultra Marathon\n\n\n\nRJ Cody Markelz\n\n\nJul 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalifornia Pitcher Plant\n\n\n\nspecies distribution\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\ntrailrun\n\n\nexercise\n\n\nexplore\n\n\ncobra lily\n\n\n\n–Cobra Lily (Darlingtonia californica)\n\n\n\nRJ Cody Markelz\n\n\nJun 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEdward Stuhl Wildflowers\n\n\n\ndata\n\n\nscraping\n\n\nweb\n\n\nextraction\n\n\nmeta-data\n\n\nwater color\n\n\nwildflowers\n\n\nplants\n\n\nmount shasta\n\n\nstuhl\n\n\n\n–Mount Shasta Wildflowers GBIF data\n\n\n\nRJ Cody Markelz\n\n\nJun 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBay Area Insects\n\n\n\nspecies distribution\n\n\nmodeling\n\n\nGIS\n\n\nmaps\n\n\nexplore\n\n\nGBIF\n\n\ndata visualization\n\n\n\n–Insect Species Occurance Data Visualization\n\n\n\nRJ Cody Markelz\n\n\nMay 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMiracle Mile Species 5 and 6\n\n\n\nspecies distribution\n\n\nmodeling\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\ntrail run\n\n\nexercise\n\n\nexplore\n\n\n\n–Jeffrey’s and Ponderosa Pine\n\n\n\nRJ Cody Markelz\n\n\nMay 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSugar Pine (Pinus lambertiana)\n\n\n\nspecies distribution\n\n\nmodeling\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\ntrail run\n\n\nexercise\n\n\nexplore\n\n\nPCT\n\n\nsugar pine\n\n\nPacific Crest Trail\n\n\n\n–Another Miracle Mile Species\n\n\n\nRJ Cody Markelz\n\n\nApr 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMiracle Mile Species 2 and 3\n\n\n\nspecies distribution\n\n\nmodeling\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\ntrail run\n\n\nexercise\n\n\nexplore\n\n\n\n–Foxtail Pine and Western White Pine\n\n\n\nRJ Cody Markelz\n\n\nApr 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMiracle Mile Species 1\n\n\n\nspecies distribution\n\n\nmodeling\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\ntrailrun\n\n\nexercise\n\n\nexplore\n\n\n\n– Pacific Yew (Taxus brevifolia)\n\n\n\nRJ Cody Markelz\n\n\nMar 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrout and Food Species\n\n\n\nspecies distribution\n\n\nmodeling\n\n\nGBIF\n\n\nGIS\n\n\nmaps\n\n\ndata\n\n\ntrout\n\n\n\n–Overlapping Species Occurance Data\n\n\n\nRJ Cody Markelz\n\n\nMar 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSki Touring Movement Data\n\n\n\ndata\n\n\nmovement\n\n\nski touring\n\n\ndata visualization\n\n\ndata integration\n\n\nmeta-data\n\n\n\n–Visualization of Ski-Tours Around Mount Shasta\n\n\n\nRJ Cody Markelz\n\n\nFeb 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUC Reserve System Environmental Data\n\n\n\ndata\n\n\nresearch\n\n\nforest\n\n\nreserve\n\n\nfire\n\n\ntutorial\n\n\n\n–Basic Plotting of Environmental Variables\n\n\n\nRJ Cody Markelz\n\n\nFeb 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneric Markdown Comic Script\n\n\n\ncomics\n\n\nart\n\n\nscript\n\n\nwriting\n\n\nrmarkdown\n\n\n\n–Comic Script Template\n\n\n\nRJ Cody Markelz\n\n\nJan 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScraping Weather Data\n\n\n\nweather\n\n\ndata\n\n\nscraping\n\n\nwebsite\n\n\nmeta-data\n\n\nresearch\n\n\n\n–Avalanche Website Data Scraping\n\n\n\nRJ Cody Markelz\n\n\nJan 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZotero + Obsidian\n\n\n\nproject management\n\n\nresearch\n\n\ntools\n\n\nobsidian\n\n\nzotero\n\n\n\n–Knowledge Graph with PDF Management\n\n\n\nRJ Cody Markelz\n\n\nJan 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Obsidian\n\n\n\nproject management\n\n\nresearch\n\n\ntools\n\n\nobsidian\n\n\n\n–Personal Knowledge Graph in Markdown\n\n\n\nRJ Cody Markelz\n\n\nDec 15, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Comic Book Coloring Process\n\n\n\nart\n\n\ncomics\n\n\ncolor\n\n\nprocess\n\n\nillustration\n\n\ncolor theory\n\n\n\n–Clip Studio Paint Coloring Workflow\n\n\n\nRJ Cody Markelz\n\n\nAug 25, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMLK Shoreline iNaturalist data\n\n\n\nnature\n\n\niNaturalist\n\n\nGIS\n\n\nmaps\n\n\n\n–Overlapping Exercise and Species Occurance Data\n\n\n\nRJ Cody Markelz\n\n\nJun 23, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMiracle Mile Conifer Species\n\n\n\nspecies distribution\n\n\nmodeling\n\n\nGBIF\n\n\nGIS\n\n\nmaps\n\n\n\n–Mapping Species Occurance\n\n\n\nRJ Cody Markelz\n\n\nJun 17, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCycling Commuting Data 1\n\n\n\ndata\n\n\ncycling\n\n\nmeta-data\n\n\nexercise\n\n\n\n–Introduction to Tidy Data in R\n\n\n\nRJ Cody Markelz\n\n\nMar 15, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Trello for Project Management\n\n\n\nproject management\n\n\ntrello\n\n\nGTD\n\n\nSCRUM\n\n\n\n–Kanban Project Management Workflow\n\n\n\nRJ Cody Markelz\n\n\nNov 18, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArt Science Hackathon\n\n\n\nartsciencehack\n\n\noutreach\n\n\ndesign\n\n\nvisualization\n\n\nart\n\n\n\n–Design Experiments With Data\n\n\n\nRJ Cody Markelz\n\n\nJan 1, 2015\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-12-15-Obsidian-Intro.html",
    "href": "posts/2021-12-15-Obsidian-Intro.html",
    "title": "Introduction to Obsidian",
    "section": "",
    "text": "Obsidian Knowledge Graph\n\nWhat is it?\nObsidian is a way to take notes in markdown and link those notes together. Linking ideas is a powerful way to form new ones and reinforce old ones. Obsidian is fairly flexible, has a large number of extensions, an active community for ideas and troubleshooting, and is kind of an addictive productivity tool.\n\n\nWhy is it interesting?\nI was originally attracted to this option because I spend a lot of my time making markdown documents as part of daily research activities. Obsidian allows you to do this, but also version control your research notes by tracking the hidden .obsidian/workspace vault that lives inside a research notes directory. You can use the obsidian app viewer to look at all the documents in the directory, make new notes (all markdown documents), click on them, edit them, render them to html/webpage format or export them to other formats like PDF. It does not lock the notes into only being viewed by Obsidian so you can open the individual markdown notes in some other text editor if convenient. Obsidian can view the changes as soon as you hit save from another editor.\nOne of the most powerful features is the ability to create links between the documents similar to the way a wiki works by allowing hyperlinks between topics. In the case of Obsidian it is linking to other markdown documents within your “vault”. It also has a nifty visualization tool to view your own research knowledge graph.\n\n\nHow to use it for research?\nAs an example, let us say you are researching some ideas for a series of blog posts where you want to start broad and end up with a post or two as the final research output. Each idea that you are researching can start as its own new markdown document (also called a Note in Obsidian). The main points of all the individual notes documents could then be summarized in a “Summary” note markdown file with links to all the individual notes for future reference. The summary of main points is then used to create a blog post markdown document to further refine the ideas.\nCheck out Obsidian here\nFuture obsidian posts include: bibliographies, video information capture from captions, scrapping notes and links to passages in eBooks, and integrating LaTex tools for equation writing."
  },
  {
    "objectID": "posts/2021-04-26-gbif-miracle-mile-species/index.html",
    "href": "posts/2021-04-26-gbif-miracle-mile-species/index.html",
    "title": "Miracle Mile Conifer Species",
    "section": "",
    "text": "Introduction\nOverall, my research aims to understand how environmental factors, like wild fires, influence biodiversity. One of the most used databases for measuring biodiversity is the Global Biodiversity Information Facility GBIF. This is post is a brief introduction of how to use GBIF, using the example of mapping a few conifer species in California.\n\nLoad the libraries\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(maps)\nlibrary(leaflet)\n\n\n\n\nPart 1 -Mapping one species\nUsing the R package function occ_data() request data from the GBIF database with the species name, selecting the observations that have a coordinate, and limiting the query to 10000 observations.\n\npinus_balfouriana <- occ_data(scientificName = \"Pinus balfouriana\", hasCoordinate = TRUE, limit = 1000)\n\nInspect the data structure.\n\nsummary(pinus_balfouriana)\n\n     Length Class  Mode\nmeta   4    -none- list\ndata 124    tbl_df list\n\n\nThere are many different groups that contribute data to GBIF. Make sure you cite them accordingly so we can continue to have a great stream of species occurrence data. As a a few examples this species has curated research grade observations from iNaturalist and many from the Humboldt State University.\n\nhead(gbif_citation(pinus_balfouriana), 2)\n\nWarning: gbif_citation() for occ_search() and occ_data() is deprecated. \nUse rgbif::occ_download() or rgbif::derived_dataset() instead.\n\n\n[[1]]\n<<rgbif citation>>\n   Citation: iNaturalist contributors, iNaturalist (2023). iNaturalist\n        Research-grade Observations. iNaturalist.org. Occurrence dataset\n        https://doi.org/10.15468/ab3s5x accessed via GBIF.org on 2023-03-29..\n        Accessed from R via rgbif (https://github.com/ropensci/rgbif) on\n        2023-03-29\n   Rights: http://creativecommons.org/licenses/by-nc/4.0/legalcode\n\n[[2]]\n<<rgbif citation>>\n   Citation: Rancho Santa Ana Botanic Garden (2023). RSA - California Botanic\n        Garden Herbarium. Occurrence dataset https://doi.org/10.15468/0yosx9\n        accessed via GBIF.org on 2023-03-29.. Accessed from R via rgbif\n        (https://github.com/ropensci/rgbif) on 2023-03-29\n   Rights: http://creativecommons.org/licenses/by-nc/4.0/legalcode\n\n\nTake a look at what types of data are collected.\n\nhead(names(pinus_balfouriana$data))\n\n[1] \"key\"              \"scientificName\"   \"decimalLatitude\"  \"decimalLongitude\"\n[5] \"issues\"           \"datasetKey\"      \n\n\nThe default GBIF query returns 126 columns of data. We do not have time to go through all of them for a single post so I will subset some important ones for some exploratory plotting purposes. Here I subset the Latitude and Longitude coordinates that we will use for mapping, if the species does occur (important for modeling in future posts), how uncertain the observation is in meters, and the references for the observation.\n\npinus_balfouriana_coords <- pinus_balfouriana$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n\"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"references\")]\n\n\n# check out how the data is structured\nhead(pinus_balfouriana_coords)\n\n# A tibble: 6 × 5\n  decimalLongitude decimalLatitude occurrenceStatus coordinateUncertai…¹ refer…²\n             <dbl>           <dbl> <chr>                           <dbl> <chr>  \n1            -118.            36.5 PRESENT                             4 https:…\n2            -118.            36.5 PRESENT                             4 https:…\n3            -118.            36.5 PRESENT                            NA https:…\n4            -123.            41.2 PRESENT                            11 https:…\n5            -118.            36.5 PRESENT                            65 https:…\n6            -118.            36.5 PRESENT                            47 https:…\n# … with abbreviated variable names ¹​coordinateUncertaintyInMeters, ²​references\n\nsummary(pinus_balfouriana_coords)\n\n decimalLongitude decimalLatitude occurrenceStatus  \n Min.   :-123.3   Min.   :35.92   Length:1000       \n 1st Qu.:-118.4   1st Qu.:36.45   Class :character  \n Median :-118.4   Median :36.58   Mode  :character  \n Mean   :-118.8   Mean   :37.04                     \n 3rd Qu.:-118.3   3rd Qu.:36.62                     \n Max.   :-118.0   Max.   :42.01                     \n                                                    \n coordinateUncertaintyInMeters  references       \n Min.   :    2                 Length:1000       \n 1st Qu.:    5                 Class :character  \n Median :   19                 Mode  :character  \n Mean   : 2234                                   \n 3rd Qu.:  185                                   \n Max.   :28534                                   \n NA's   :777                                     \n\n# pinus_balfouriana_coords$decimalLongitude # remove this row of bad data\npinus_balfouriana_coords <- slice(pinus_balfouriana_coords, -(278))\n\n\n# two map functions... be clear! There are a few map functions with these different libraries loaded.\n#?map()\nmaps::map(database = \"state\", region = \"california\")\npoints(pinus_balfouriana_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\nSubset our search to only Northern California\n\nmm_geometry <- paste('POLYGON((-124.4323 42.0021, -121.5045 42.0021, -121.5045 40.194, -124.4323 40.194, -124.4323 42.0021))')\n\n\npinus_balfouriana_NC <- occ_data(scientificName = \"Pinus balfouriana\", hasCoordinate = TRUE, limit = 1000,\n                     geometry = mm_geometry )\nhead(pinus_balfouriana_NC)\n\n$meta\n$meta$offset\n[1] 0\n\n$meta$limit\n[1] 300\n\n$meta$endOfRecords\n[1] TRUE\n\n$meta$count\n[1] 151\n\n\n$data\n# A tibble: 151 × 125\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n   <chr>  <chr>     <dbl>   <dbl> <chr>  <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 39470… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 2 39474… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 3 39472… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 4 39612… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 5 38729… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 6 38734… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 7 39609… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 8 40548… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 9 38736… Pinus …    41.3   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n10 39471… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n# … with 141 more rows, 115 more variables: lastCrawled <chr>,\n#   lastParsed <chr>, crawlId <int>, hostingOrganizationKey <chr>,\n#   basisOfRecord <chr>, occurrenceStatus <chr>, taxonKey <int>,\n#   kingdomKey <int>, phylumKey <int>, classKey <int>, orderKey <int>,\n#   familyKey <int>, genusKey <int>, speciesKey <int>, acceptedTaxonKey <int>,\n#   acceptedScientificName <chr>, kingdom <chr>, phylum <chr>, order <chr>,\n#   family <chr>, genus <chr>, species <chr>, genericName <chr>, …\n\npinus_balfouriana_NC_coords <- pinus_balfouriana_NC$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nPlot the data in a few different ways to see if there is anything strange.\n\nplot(pinus_balfouriana_NC_coords$decimalLongitude, pinus_balfouriana_NC_coords$decimalLatitude) # examine the data\n\n\n\npinus_balfouriana_NC_coords %>% leaflet() %>% addTiles() %>%\naddMarkers(~decimalLongitude, ~decimalLatitude)\n\n\n\n\n\n\n\nPart 2- Map Multiple species\nFirst test the workflow with only a few species then do entire batch.\n\n# The test is commented out. Uncomment to test first.\n# mm_species <- c(\"Pinus balfouriana\", \"pinus albicaulis\", \"pinus monticola\") # uncomment to run small test version\n\n# Entire miracle mile species set\nmm_species <- c(\"Pinus balfouriana\", \"pinus albicaulis\", \"pinus monticola\", \"pinus jeffreyi\", \"pinus ponderosa\", \"pinus contorta\", \"pinus lambertiana\", \"abies concolor\", \"abies magnifica\", \"abies lasiocarpa\", \"picea engelmannii\", \"picea breweriana\", \"tsuga mertensiana\", \"pseudotsuga menziesii\", \"taxus brevifolia\", \"calocedrus decurrens\", \"juniperus communis\", \"juniperus occidentalis\")\n\nmm_all <- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 1000,\n                   geometry = mm_geometry)\nsummary(mm_all)\n\n                       Length Class  Mode\nPinus balfouriana      2      -none- list\npinus albicaulis       2      -none- list\npinus monticola        2      -none- list\npinus jeffreyi         2      -none- list\npinus ponderosa        2      -none- list\npinus contorta         2      -none- list\npinus lambertiana      2      -none- list\nabies concolor         2      -none- list\nabies magnifica        2      -none- list\nabies lasiocarpa       2      -none- list\npicea engelmannii      2      -none- list\npicea breweriana       2      -none- list\ntsuga mertensiana      2      -none- list\npseudotsuga menziesii  2      -none- list\ntaxus brevifolia       2      -none- list\ncalocedrus decurrens   2      -none- list\njuniperus communis     2      -none- list\njuniperus occidentalis 2      -none- list\n\nmm_species_coords_list <- vector(\"list\", length(mm_species))\nnames(mm_species_coords_list) <- mm_species\n\nfor (x in mm_species) {\n  coords <- mm_all[[x]]$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n  mm_species_coords_list[[x]] <- data.frame(species = x, coords)\n}\n\n\nUsing the rbindlist() function from the data.frame package to take all of the species observations from a list to a large data.frame. The columns are the species name, the latitude and longitude coordinates, whether or not there was an observation, if there is any uncertainty about how accurate the GPS coordinate was, what platform the observation was made on, and the specific reference for the observation. Make sure you cite the references so we can keep these rich data streams coming!\n\ntree_df <- rbindlist(mm_species_coords_list, fill = T)\ndim(tree_df)\n\n[1] 6643    7\n\nhead(tree_df)\n\n             species decimalLongitude decimalLatitude occurrenceStatus\n1: Pinus balfouriana        -122.7895        41.21823          PRESENT\n2: Pinus balfouriana        -122.7896        41.21239          PRESENT\n3: Pinus balfouriana        -122.4852        41.31694          PRESENT\n4: Pinus balfouriana        -122.8140        41.20379          PRESENT\n5: Pinus balfouriana        -122.7933        41.24757          PRESENT\n6: Pinus balfouriana        -122.7887        41.21986          PRESENT\n   coordinateUncertaintyInMeters institutionCode\n1:                            11     iNaturalist\n2:                            NA     iNaturalist\n3:                            15     iNaturalist\n4:                           258     iNaturalist\n5:                             4     iNaturalist\n6:                             8     iNaturalist\n                                           references\n1: https://www.inaturalist.org/observations/120244204\n2: https://www.inaturalist.org/observations/122764637\n3: https://www.inaturalist.org/observations/123619404\n4: https://www.inaturalist.org/observations/123747109\n5: https://www.inaturalist.org/observations/124097026\n6: https://www.inaturalist.org/observations/124337645\n\n\nJust take a quick look at the raw observations plotted by latitude and longitude.\nPlot all of the species on the California map.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(tree_df[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\nPlot all of the species using ggplot in case you want to visualize the species with something a bit fancier.\n\nmm_species_plot1  <- ggplot(tree_df, aes(x=decimalLongitude, y = decimalLatitude, color = species)) +\n       geom_point() + labs(color = \"Species\", title = \"MM Zone\")\nmm_species_plot1\n\n\n\n\nThere is a lot more you can do for GBIF, but these notes should help for the purpose of mapping species occurrence. Now that the data is somewhat organized we can start doing some proper data cleaning and exploratory data analysis in a future post."
  },
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "CV",
    "section": "",
    "text": "Current Affiliation\n\nBIDS Global Environmental Change Fellow- Berkeley Institute for Data Science (BIDS) 2021-present\nData Science Communications Manager Berkeley Institute for Data Science (BIDS) 2023-present\n\n\n\nPrevious Affiliations\n\nCo-Founder and VP of Genomics - Rev Genomics 2016-20\nNSF Postdoctoral Fellow - UC Davis Department of Plant Biology 2014-17\nUC Davis Data Science Initiative 2016-17\nPostdoctoral Scholar - UC Davis Department of Plant Biology 2012-14\n\n\n\nEducation\n\nPh.D. Plant Biology, University of Illinois at Urbana-Champaign - 2012\nB.S. Integrative Biology, Minor: Chemistry, University of Illinois at Urbana-Champaign - 2007\n\n\n\n\nGrants and Awards\n\nPI: NSF- Postdoctoral Fellowships in Biology- Develop a systems level model of resource allocation and partitioning in Brassica rapa to predict growth across multiple genotypes and environments. Plant Genome Research Program ($216,000) - 2014-17\n\nPI: Physiological systems biology of secondary metabolism in Brassica rapa leaves. Amaryllis Nucleics Research Grant ($9600)- 2016\n\nPI: Developing distributed image processing pipelines for plant growth phenotyping using Docker container based NVIDIA GPU Amazon EC2 instances. Amazon Web Services Research Grant ($5600). - 2015-2016\n\nCollaborator: Genotyping by Sequencing and Detection of eQTLs in a Recombinant Inbred Line Population of Brassica rapa. TACC Lonestar4 Super Computer Cluster (260,000 Units). - 2013-14\n\nPI: National Science Foundation Graduate Research Fellowship ($135,000) - 2009-12\nCo-PI: Project Leader, ASPB Education Foundation Grant- Plants iView ($20,000) - 2011-12\nCo-PI: Project Leader, UIUC Public Engagement Grant- Plants iView ($12,500) - 2011-12\nOutstanding Teaching Award- UIUC Department of Plant Biology ($400) - 2012\nGovindjee Award for Excellence in Biological Science ($1000) - 2011\nPI: Francis M. and Harlie M. Clark Research Grant ($1,000) - 2010\nPI: Francis M. and Harlie M. Clark Research Grant ($1,000) - 2009\nDistinction- School of Integrative Biology. Thesis Title: “How will elevated [CO2] alter soil and plant water status of the C3-crop soybean and the C4-crop maize?” Published as part of Hussain et al. (2013). - 2007\nTotal Academic Awards: $402,100\n\n\n\n\nPeer Reviewed Publications\nGoogle Scholar Profile\n\nBaker RL, Leong W, Brock MT, Rubin MJ, Markelz RJC, Welch S, Maloof JN, Weinig C (2019) Integrating transcriptomic network reconstruction and QTL analyses reveals mechanistic connections between genomic architecture and Brassica rapa development. PLoS Genetics 15 (9), e1008367. paper\nMarkelz RJC 1,Covington MF 1, Devisetty UK, Brock M, Weinig C, Ma. oof JN (2017) Using RNA-Seq for genomic scaffold placement, correcting assemblies, and genetic map creation in a common Brassica rapa mapping population. G3. paper 1Equal contribution.\nBucksch A, Atta-Boateng A, Azihou AF, Battogtokh D, Baumgartner A, Binder BM, Braybrook SA, Chang C, Coneva V, DeWitt TJ, Fletcher AG, Gehan MA, Diaz -Martinez DH, Hong L, Iyer -Pascuzzi AS, Klein LL, Leiboff S, Li M, Lynch JP, Maizel A, Maloof JN, Markelz RJC, Martinez CC, Miller LA, Mio W, Palubicki W, Poorter H, Pradal C, Price CA, Puttonen E, Reese JB, Rellán-Álvarez R, Spalding EP, Sparks EE, Topp CN, Williams JH and Chitwood DH (2017) Morphological plant modeling: unleashing geometric and topological potential within the plant sciences. Frontiers in Plant Science. 8:900. doi: 10.3389/fpls.2017.00900 paper\nAn N, Welch SM, Markelz RJC, Baker RL, Palmer CM, Ta J, Maloof JN, Weinig C (2017) Using photogrammetry and plant modeling techniques to quantify 2D and 3D rossette area for time-series high-throughput phenotyping. Computers and Electronics in Agriculture. 135: 222-232 paper\nAn N, Palmer CM, Baker RL, Markelz RJC, Ta JT, Covington MF, Maloof JN, Welch SM, Weinig C (2016) Plant High-Throughput Phenotyping Using Photogrammetry and imaging Techniques to Measure Leaf Length and Rosette Area. Computers and Electronics in Agriculture. 127:376-394 paper\nBrock MT, Lucas L, Anderson N, Rubin M, Markelz RJC, Covington MF, Devisetty UK, Chapple C, Maloof JN, Weinig C (2016) Genetic architecture, biochemical underpinnings, and ecological impact of floral UV patterning. Molecular Ecology. 25:1122-1140 paper\nBaker RL, Leong WF, Brock MT, Markelz RJC, Covington MF, Devisetty UK, Maloof JN, Welch S, Weinig C (2015) Modeling development and quantitative trait mapping reveal independent genetic modules for leaf size and shape. New Phytologist. 208: 257–268. paper\nMarkelz RJC, Vosseller LN, Leakey ADB (2014) Elevated CO2 concentration induces transcriptional reprogramming of respiration and a stimulation of dark respiration as Arabidopsis thaliana leaves transition from sinks to sources. Plant, Cell, and Environment. 37:2542-2552. paper\nMarkelz RJC, Lai LX, Vosseller LN, Leakey ADB (2014) The stimulation of leaf respiration and transcriptional reprogramming by elevated CO2 concentration is diminished, but not eliminated, under limiting nitrogen supply. Plant, Cell, and Environment. 37:886-898. paper\nHussain MZ, VanLoocke A, Markelz RJC, Leakey ADB, Ort DO, Bernacchi CJ (2013) Future carbon dioxide concentration decreases canopy evapotranspiration and soil water depletion by field-grown maize. Global Change Biology. 19:1572–1584. paper\nWalters KR, Rupassara SI, Markelz RJC, Leakey ADB, Muir W, Pittendrigh B (2012) Methamphetamine causes anorexia in Drosophila melanogaster, exhausting metabolic reserves and contributing to mortality. The Journal of Toxicological Sciences. 4:773-790. paper\nGillespie KM, Xu F, Richter KT, McGrath JM, Markelz RJC, Ort DR, Leakey DB, Ainsworth EA (2012) Greater antioxidant and respiratory metabolism in field-grown soybean exposed to elevated O3 under both ambient and elevated CO2 Concentrations. Plant, Cell, and Environment. 35:164-184. paper\nMarkelz RJC, Strellner RS, Leakey ADB (2011) Impairment of C4 photosynthesis by drought is exacerbated by limiting nitrogen and ameliorated by elevated [CO2] in maize. Journal of Experimental Botany. 62:3235-3246. paper\nLeakey ADB, Ainsworth EA, Bernard SM, Markelz RJC, Ort DR, Placella S, Rogers A, Smith MD, Sudderth EA, Weston DJ, Wullschleger SD, Yuan S (2009) Gene expression profiling – opening the black box of plant ecosystem responses to global change. Global Change Biology. 15:1201-1213. paper\n\n\n\n\nInvited Talks\n\nUsing Data Science to Understand Californian Ecosystem Responses to Fire (2022) Data & AI Innovation Day - Accenture. San Francisco, CA\nThe impact of fire on California Arthropods and fire data science techniques (2022) USFS Region 5 Hydrology Meeting, Online.\nThe impact of fire on California Arthropods (2021) UC Berkeley Accenture Day. Berkeley, CA.\nFull Stack Biology: Moving freely between biological layers with databases, statistics, and network modeling (2017) Phenome 2017. Tucson, AZ.\nWhole plant systems biology: a Brassica rapa exemplar (2016). Plant Research Lab- Michigan State University. East Lansing, MI.\nConnecting genotype to phenotype in Brassica rapa using statistical and computational techniques (2015). University of Minnesota, St. Paul, MN.\nSystems biology of plant competition in Brassica rapa (2014). Plant Genome Research Program- National Science Foundation. Arlington, VA.\nAdapting crops to global climate change (2009). Darwin 200: A South American celebration. Maldonado, Uruguay.\n\n\n\nContributed Talks\n\nASPB Annual Meeting. Austin, TX. - 2016\nNorth American Arabidopsis Steering Committee Focus Group- Training the next generation of quantitative plant biologists. Phoenix, AZ. - 2016\nUC Davis Postdoctoral Research Symposium– Big Data Session. Davis, CA. - 2015\nUC Davis Plant Cell Biology Retreat. Davis, CA. - 2015\nUC Davis Plant Cell Biology Retreat. Marconi Historic Park, CA. - 2014\nUC Davis Postdoctoral Seminar Series. Davis, CA. - 2013\nUC Davis Plant Cell Biology Retreat. Asilomar, CA. - 2013\nASPB Annual Meeting. Austin, TX. - 2012\nUIUC Graduate Students in Ecology and Evolutionary Biology Symposium, Urbana, Illinois. - 2010\nProctor and Gamble Student Research Competition. Urbana, IL. - 2007\n\n\n\nContributed Posters\n\nASPB Annual Meeting. Austin, TX. - 2016\nUC Davis Postdoctoral Research Symposium. Davis, CA. - 2016\nProbabilistic Modeling in Genomics, CSHL, NY. - 2015\nNational Science Foundation, Arlington, VA. - 2015\nASPB Annual Meeting, Minneapolis, MN - 2015\nPlant Animal Genome, San Diego, CA. Poster Presentation. - 2015\nNational Science Foundation, Arlington, VA. - 2014\nASPB Annual Meeting. Portland, OR. Poster- 2014\nKeystone Symposium: Plant Abiotic Stress and Sustainable Agriculture. Taos, NM. - 2013\nASPB Annual Meeting. Austin, TX. - 2012\nWorld Crop FACE Workshop, Tsukuba, Japan. - 2012\nUniversity of Illinois Public Engagement Symposium: Transforming Our Society. Champaign, IL. - 2012\n8th Okazaki Biology Conference, Okazaki, Japan.- 2012\nUIUC Plant Biology Departmental Fall Welcome. Urbana, IL. - 2011\nInstitute for Genomic Biology Fellows Symposium. Poster Presentation. - 2011\nPlant respiration and climate change. Oxford, United Kingdom. - 2010\nASPB Annual Meeting. Honolulu, Hawaii. - 2009\nASPB Annual Meeting. Merida, Mexico. - 2008\n\n\n\n\nTeaching\n\nCritiques- Landscape Architecture Graduate Design Studio 438- University of Illinois - Experimental Design Thinking 2022\nGuest Lecturer- Landscape Architecture Graduate Design Studio 438- University of Illinois - Experimental Design Thinking 2021\nGuest Lecturer- Emerging Technologies- Kent School of Law - Biotech approaches to improving crops for a changing world 2020\nCo-instructor- PBI200C- Plant Biology Graduate Group Core, Plant Primary Productivity: Environmental Impacts on C-Fixation. Mathematical model based instruction using photosynthesis simulations. 2016\nGuest Instructor- BIS180L- Undergraduate Bioinformatics Lab. Genetic Networks 1: Clustering, Genetic Networks 2: Co-expression, 2015\nGuest Lecturer- Plant Biology 220: Plant Developmental Biology. QTL mapping with -omics scale data - 2015\nCo-instructor and Discussion Leader of General Education Class- Integrative Biology 107: Global Warming, Biofuels, and Food - 2011 List of Teachers Ranked Excellent by Their Students; Outstanding Teaching Award Department of Plant Biology\nTeaching Assistant- Integrative Biology 440: Plants and Global Change. Developed science communication module- Graduate students and undergraduates created Podcasts for primary climate change literature. - 2009\n\n\n\nShort Courses and Workshops\n\nSpecies distribution modeling with Bayesian statistics in R - 2021\nMerging Crop Models and Genetics, University of Florida - 2015\nPathway Tools for Metabolic Modeling, SRI International - 2015\nSummer Institute in Statistical Genetics, University of Washington - 2014\nComputing in the Cloud: What Every Computational Life Scientist Should Know, NIMBioS, University of Tennessee - 2014\nFrontiers and Techniques in Plant Science- Cold Spring Harbor Laboratory - 2010\n\n\n\n\nMentoring\n\nAnna Holmquist (ESPM PhD Student, UC Berkeley) - 2021-\nLakshmi Pabbisetty (Biology, UC Davis) - 2015-2017\nChristina Day (Biology, UC Davis) - 2013-2017\nAmanjot Kaur (Biotechnology, UC Davis) - 2014-2015\nNeije Mukherjee-Roy (Microbiology, UC Davis) - 2015\nJames Ta (Junior Specialist, UC Davis) - Graduate Student Biophysics UC Davis 2014-2015\nTiffany Ho (Genetics, Bioinformatics, UC Davis) - Graduate Student at Cornell University - 2014-2015\nShweta Dash (Biology, UC Davis) - 2015\nKamalpreet Sahota (Religious Studies, Biology- UC Davis) – Graduate Student at Touro University - 2013-14\nNavi Singh (Biology- UC Davis) - 2013-14\nWilliam Landel (Plant Biology- UC Davis) - 2013\nKisha Thayapran (High School Student) - UC Davis Young Scholar - 2013\nNatalia Rodriquez (High School Student - Puerto Rico) RAP2 Program 2012\nLauren Vosseller (Molecular and Cellular Biology- University of Illinois) - Co-Author, Graduate Student University of Illinois- Chicago - 2010-12\nAlexander Petit (History- University of Illinois) - James Scholar Program\nBrian Zehr (IB- University of Illinois)- India rural eye-care network - 2010-11\nRyan Boyd (IB- University of Illinois) - Graduate student at Washington State University - 2009-10\nReid Strellner (IB- University of Illinois) - Co-author, Graduate student at Northwestern University - 2008-10\nDerek Haselhorst (IB- University of Illinois) - Graduate Student at University of Illinois- Urbana - 2008\n\n\n\n\nProfessional and Volunteer Service\n\nManuscript Reviewer: eLife; American Journal of Botany; Journal of Experimental Botany; Photosynthesis Research; Plant, Cell, and Environment- 2009-\nModerator : Data Science by Design 2021\nTechnical Editor: Bioinformatics Data Skills, Vince Buffalo, O’Reilly Publishing - 2013-2015\nOrganizer and Leader of Graduate Student Grant Writing: Plants iView - Middle School Plant Science Outreach ; successfully obtained funding from ASPB and UIUC. 2011-2012\nCreator: Plant Carbon Allocation Relay Race for K-12 Science Teachers Workshop for Ecosystem Ecology - 2012\nThe Art of Science 2.0 - I collaborated with an artist to blend disciplines and create art by visualizing biological processes using confocal microscopy. - 2012\nPresenter: Microscopy Outreach Event- Mahomet Seymour Junior High School Science Club - 2012\nOrganizer: National Pollinator Week - 2010 and 2011\nChair: Plant Biology Graduate Student Association - 2010-11\nRoots and Shoots, University of Illinois Branch - 2010\nDepartmental Colloquium Coordinator: Plant Biology Graduate Student Association - 2009-10\nThreatened Species Survey, Grampians National Park, Victoria, Australia - 2008\nInternational Impact, fund raising and school building project for small Ecuadorian Indigenous communities - 2005-07\n\n\n\nUnpaid Science Consulting\n\nJustin Gillis- NY Times Science Reporter 2011 HARVEST Article\nLI-COR Environmental 2011"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Google Scholar Profile\n\nPublications\n\nBaker RL, Leong W, Brock MT, Rubin MJ, Markelz RJC, Welch S, Maloof JN, Weinig C (2019) Integrating transcriptomic network reconstruction and QTL analyses reveals mechanistic connections between genomic architecture and Brassica rapa development. PLoS Genetics 15 (9), e1008367. paper\nMarkelz RJC 1,Covington MF 1, Devisetty UK, Brock M, Weinig C, Maloof JN (2017) Using RNA-Seq for genomic scaffold placement, correcting assemblies, and genetic map creation in a common Brassica rapa mapping population. G3. paper 1Equal contribution.\nBucksch A, Atta-Boateng A, Azihou AF, Battogtokh D, Baumgartner A, Binder BM, Braybrook SA, Chang C, Coneva V, DeWitt TJ, Fletcher AG, Gehan MA, Diaz -Martinez DH, Hong L, Iyer -Pascuzzi AS, Klein LL, Leiboff S, Li M, Lynch JP, Maizel A, Maloof JN, Markelz RJC, Martinez CC, Miller LA, Mio W, Palubicki W, Poorter H, Pradal C, Price CA, Puttonen E, Reese JB, Rellán-Álvarez R, Spalding EP, Sparks EE, Topp CN, Williams JH and Chitwood DH (2017) Morphological plant modeling: unleashing geometric and topological potential within the plant sciences. Frontiers in Plant Science. 8:900. doi: 10.3389/fpls.2017.00900 paper\nFriesner J et al. (2017) The Next Generation of Training for ArabidopsisResearchers: Bioinformatics and Quantitative Biology. Plant Physiology 175: 1499-1509 paper\nAn N, Welch SM, Markelz RJC, Baker RL, Palmer CM, Ta J, Maloof JN, Weinig C (2017) Using photogrammetry and plant modeling techniques to quantify 2D and 3D rossette area for time-series high-throughput phenotyping. 135: 222-232 paper\nAn N, Palmer CM, Baker RL, Markelz RJC, Ta JT, Covington MF, Maloof JN, Welch SM, Weinig C (2016) Plant High-Throughput Phenotyping Using Photogrammetry and imaging Techniques to Measure Leaf Length and Rosette Area. Computers and Electronics in Agriculture. 127:376-394 paper\nBrock MT, Lucas L, Anderson N, Rubin M, Markelz RJC, Covington MF, Devisetty UK, Chapple C, Maloof JN, Weinig C (2016) Genetic architecture, biochemical underpinnings, and ecological impact of floral UV patterning. Molecular Ecology. 25:1122-1140 paper\nBaker RL, Leong WF, Brock MT, Markelz RJC, Covington MF, Devisetty UK, Maloof JN, Welch S, Weinig C (2015) Modeling development and quantitative trait mapping reveal independent genetic modules for leaf size and shape. New Phytologist. 208: 257–268. paper\nMarkelz RJC, Vosseller LN, Leakey ADB (2014) Elevated CO2 concentration induces transcriptional reprogramming of respiration and a stimulation of dark respiration as Arabidopsis thaliana leaves transition from sinks to sources. Plant, Cell, and Environment. 37:2542-2552. paper\nMarkelz RJC, Lai LX, Vosseller LN, Leakey ADB (2014) The stimulation of leaf respiration and transcriptional reprogramming by elevated CO2 concentration is diminished, but not eliminated, under limiting nitrogen supply. Plant, Cell, and Environment. 37:886-898. paper\nHussain MZ, VanLoocke A, Markelz RJC, Leakey ADB, Ort DO, Bernacchi CJ (2013) Future carbon dioxide concentration decreases canopy evapotranspiration and soil water depletion by field-grown maize. Global Change Biology. 19:1572–1584. paper\nWalters KR, Rupassara SI, Markelz RJC, Leakey ADB, Muir W, Pittendrigh B (2012) Methamphetamine causes anorexia in Drosophila melanogaster, exhausting metabolic reserves and contributing to mortality. The Journal of Toxicological Sciences. 4:773-790. paper\nGillespie KM, Xu F, Richter KT, McGrath JM, Markelz RJC, Ort DR, Leakey DB, Ainsworth EA (2012) Greater antioxidant and respiratory metabolism in field-grown soybean exposed to elevated O3 under both ambient and elevated CO2 Concentrations. Plant, Cell, and Environment. 35:164-184. paper\nMarkelz RJC, Strellner RS, Leakey ADB (2011) Impairment of C4 photosynthesis by drought is exacerbated by limiting nitrogen and ameliorated by elevated [CO2] in maize. Journal of Experimental Botany. 62:3235-3246. paper\nLeakey ADB, Ainsworth EA, Bernard SM, Markelz RJC, Ort DR, Placella S, Rogers A, Smith MD, Sudderth EA, Weston DJ, Wullschleger SD, Yuan S (2009) Gene expression profiling – opening the black box of plant ecosystem responses to global change. Global Change Biology. 15:1201-1213. paper"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Link Tree",
    "section": "",
    "text": "Email: rjcmarkelz {at} berkeley.edu\n\n\nArt Portfolio: codymarkelz.art\n\n\nMastodon: @codymarkelz@sunny.garden\n\n\nInstagram: codymarkelz\n\n\nGumroad: codymarkelz\n\n\nTwitter: codymarkelz\n\n\nGithub: rjcmarkelz\n\n\nlinkedin: codymarkelz"
  },
  {
    "objectID": "science.html",
    "href": "science.html",
    "title": "Science",
    "section": "",
    "text": "Currently, I am a Global Environmental Change Fellow at Berkeley Institute for Data Science (BIDS) working at the intersection between invasive species, climate change and wildfire in Californian ecosystems. My project involves developing probabilistic models that work with newly collated datasets and meta-data to work across environmental scales to understand wildfire spread and impact. I am also the Data Science Communications Manager at BIDS. My projects in this role include visual and written science communications (sci-comm) articles, websites, data visualizations and explainer illustrations of data intensive projects across the institute.\nAs an NSF Graduate Research Fellow, I studied the effects of elevated atmospheric carbon dioxide and water availability on plant growth. I then blended this knowledge of plant metabolism with computational biology to build genetically informed mathematical models of plant growth as part of an NSF postdoctoral fellowship at UC Davis. Recently, I co-founded and was the VP of Genomics at Rev Genomics, which uses genomics, statistics, molecular genetics, and tissue culture to create new strains of Cannabis for the legal market. Rev Genomics was funded by Y-Combinator and continues to innovate in the Cannabis biotech space.\n\nProjects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBerkeley Institute for Data Science\n\n\n–How does biodiversity affect fires in California ecosystems?\n\n\n\n\n\n\nMar 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSci-Comm Projects\n\n\n–Visual and Written Communications Projects\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScience Outreach\n\n\n–Broadening participation in science\n\n\n\n\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRev Genomics\n\n\n–Biotech company making new strains of Cannabis\n\n\n\nCody Markelz\n\n\nOct 13, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPostdoc\n\n\n–NSF Postdoctoral Research Fellowship Projects\n\n\n\nRJ Cody Markelz\n\n\nJun 1, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEngineering Projects\n\n\n–Scientific equipment design, builds and controlling software development\n\n\n\n\n\n\nApr 1, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching\n\n\n– Philosophy of Learning\n\n\n\n\n\n\nMar 1, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhD\n\n\n–NSF Graduate Research Fellowship Projects\n\n\n\nRJ Cody Markelz\n\n\nDec 1, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUndergraduate Research Projects\n\n\n–Senior Distinction Project and other original research\n\n\n\n\n\n\nAug 1, 2007\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "science/PhD_projects.html",
    "href": "science/PhD_projects.html",
    "title": "PhD",
    "section": "",
    "text": "PhD Dissertation Projects\nDuring graduate school I was interested in doing a mixture of field, molecular, computational, and engineering projects. Thanks in part to the freedom afforded by a NSF Graduate Research Fellowship, I designed research projects to answer open questions in the climate change literature that incorporated these four components. Here is a copy of my dissertation.\n\n\nAbstract\nThe balance between photosynthetic carbon dioxide (CO2) assimilation and respiratory CO2 release influence plant growth, crop yields, and the ability of terrestrial ecosystems to offset ~2-3 Gt CO2 yr -1 of anthropogenic emissions. Rising atmospheric CO2 concentration ([CO2]) this century will impact plant photosynthesis and respiration with consequences for plant productivity in natural and agro-ecosystems. The capacity of all plants to grow and ecosystems to store carbon in elevated [CO2] can be dependent on interactions with water, nutrients, and plant developmental processes. The purpose of this thesis is to address fundamental knowledge gaps in understanding plant responses to the interaction between elevated [CO2] with water, nitrogen (N), and leaf developmental programs: (1) determine what is the mechanistic response of maize C4 photosynthesis to a three way interaction between atmospheric [CO2], N availability and drought utilizing the unique capabilities of a Free Air CO2 Enrichment (FACE) field experiment; (2) determine the transcriptional reprogramming of leaf respiration in response to growth in elevated [CO2] and variable N supply using Arabidopsis thaliana and a custom built gas exchange system; (3) determine when in leaf development the transcriptional reprogramming of respiration occurs in response to elevated [CO2] by studying the detailed developmental timelines and molecular events of leaf growth in A. thaliana. The knowledge gaps addressed in this work will help inform crop improvement and models that predict future ecosystem function and global food supply in the face of a changing climate.\n\n\nElevated [CO2], Nitrogen Availability, and Drought in Maize\nC4 plants, like maize, make up some of the most valued crops and important keystone species in subtropical grassland ecosystems. In C4 plants, CO2 is converted into a four carbon acid and pumped from the mesophyll cells into the bundle sheath cells where it is re-released near the site of RUBISCO. This mechanism makes C4 photosynthesis an efficient way for the plants to fix carbon used in growth processes. C4 plants are theoretically not suppose to have a stimulation in photosynthetic carbon assimilation when grown in elevated [CO2] because of this CO2 concentrating mechanism. In this paper I designed a field experiment to test the interaction of elevated [CO2] and nitrogen availability on maize growth, carbon assimilation and development. I found that elevated [CO2] did not provide a benefit to carbon assimilation or growth in either nitrogen treatment early in the field season. A late season drought allowed me to test what the effects of water availability had on these interactions. By merging the field data with a model of C4 photosynthesis I showed that drought made photosynthetic capacity sensitive to elevated [CO2] and that low nitrogen availability exaggerated this difference. paper\n\n\nFIGURE 1: Photosynthetic modeling combining field and lab gas exchange data showing CO2 by nitrogen interaction only in drought conditions. Summary of A/ci response curves and CO2 supply functions for maize grown at ambient [CO2] (Panels A and C, dashed lines) and elevated [CO2] (Panels B and D, solid lines) as well as high N (black lines) and limiting N (grey lines) during non-drought conditions (panels A and B) or drought conditions (panels C and D). Stomatal limitation (SL) to carbon assimilation was also calculated for each treatment.\n\n\n\nElevated [CO2], Nitrogen Availability, and Respiration- in Arabidopsis thaliana\nPlant respiration is a very important component of plant growth and global carbon cycle, but less studied compared to photosynthesis. This is especially true for night-time dark respiration. There was a great deal of confusion in the literature about whether growth in elevated [CO2] would increase, decrease, or not change the dark respiration rates of plants. After conducting a literature review on the topic I found that various papers were not consistent in how they quantified respiration and there appeared to be evidence for an interaction between elevated [CO2] and nitrogen availability on plant respiration. I wanted to understand the molecular mechanisms of this interaction so I chose to work with Arabidopsis thaliana because of the suite of molecular and genetic tools available. The problem with using A. thaliana was that there was no standard equipment to measure leaf respiration in a plant this small so I designed a custom respiration system (see below) in order to very accurately quantify leaf respiratory CO2 efflux. This new chamber, allowed me show that the elevated [CO2] did stimulate leaf respiration regardless of nitrogen availability, but the response was dampened in the limiting nitrogen condition. This finding was supported biochemically and from gene expression micro-array data. paper\n\n\nFIGURE 2: Molecular support for biochemical and physiological increase in respiration in elevated [CO2]. This figure is a graphical summary of genes encoding components of the TCA cycle and mitochondrial electron transport chain that responded to elevated [CO2] during midnight (top) or midday (bottom) and limiting N (left) or ample N (right). Each blue (positive percentage change) and yellow (negative percentage change) represents the mean percentage change of a unique transcript that responded significantly (P < 0.05) to elevated [CO2].\n\n\n\nElevated [CO2], Leaf Development, and Respiration in Arabidopsis thaliana\nAs leaves develop they gradually transition from being a sink tissue to a source tissue. Sink tissues rely on transport of carbon and other nutrient resources from mature source tissues in order to maintain high growth rates through this developmental transition. A majority of the elevated [CO2] literature had focused on mature tissues. I was curious if the stimulation in respiration rates that I observed in mature tissues were also occurring in younger tissues. The answer to this question has important implications to how plant respiration is modeled in whole plant growth models. I found that as leaves grew and became source tissues the stimulation in leaf respiration in elevated [CO2] increased. This finding was also supported biochemically and from gene expression data. This developmental gradient in respiratory response makes sense in that the mature tissue is best able to incorporate the CO2 into sugars and that more of that carbohydrate is being respired at night to fuel the whole plant growth stimulation in elevated [CO2]. paper\n\n\nFIGURE 3: Graph showing the developmental dependency of the leaf respiration response to elevated [CO2]. Midnight dark respiration rates (R) of leaf 10 of Arabidopsis thaliana grown at ambient [CO2] (370 ppm) or elevated [CO2] (750 ppm), at 23, 24 (Expanding) or 29, 30 and 31 (Mature) days after germination. Scale bar = 1 cm."
  },
  {
    "objectID": "science/engineering.html",
    "href": "science/engineering.html",
    "title": "Engineering Projects",
    "section": "",
    "text": "Arabidopsis growth imaging system\nCo-designed and co-developed part of the software to quantify Arabidopsis 2D and 3D growth for thousands of individuals simultaneously.\nAn_2017\nAn_2016\n\n\n\nSingle leaf Arabidopsis respiration\nDesigned and built the hardware and software for accurately quantifying single leaf respiration rates.\nMarkelz_2014a\nMarkelz_2014b\n\n\n\nLICOR 6400 chamber head\nDesigned customs chamber head to accurately quantify soybean leaf dark respiration in the field.\nGillespie_2012\n\n\n\nIndividual fruitfly respiration while on methamphetamine\nModified the hardware from the single leaf chamber to accurately quantify differences in individual fruit fly respiration rates that had been treated with or without methamphetamine.\nWalters_2012"
  },
  {
    "objectID": "science/engineering.html#single-leaf-arabidopsis-respiration",
    "href": "science/engineering.html#single-leaf-arabidopsis-respiration",
    "title": "Engineering Projects",
    "section": "Single leaf Arabidopsis respiration",
    "text": "Single leaf Arabidopsis respiration\nDesigned and built the hardware and software for accurately quantifying single leaf respiration rates.\nMarkelz_2014a\nMarkelz_2014b"
  },
  {
    "objectID": "science/engineering.html#licor-6400-chamber-head",
    "href": "science/engineering.html#licor-6400-chamber-head",
    "title": "Engineering Projects",
    "section": "LICOR 6400 chamber head",
    "text": "LICOR 6400 chamber head\nDesigned customs chamber head to accurately quantify soybean leaf dark respiration in the field.\nGillespie_2012"
  },
  {
    "objectID": "science/engineering.html#individual-fruitfly-respiration-while-on-methamphetamine",
    "href": "science/engineering.html#individual-fruitfly-respiration-while-on-methamphetamine",
    "title": "Engineering Projects",
    "section": "Individual fruitfly respiration while on methamphetamine",
    "text": "Individual fruitfly respiration while on methamphetamine\nModified the hardware from the single leaf chamber to accurately quantify differences in individual fruit fly respiration rates that had been treated with or without methamphetamine.\nWalters_2012"
  },
  {
    "objectID": "science/postdoc_projects.html",
    "href": "science/postdoc_projects.html",
    "title": "Postdoc",
    "section": "",
    "text": "Physiological Systems Biology of Competition in Brassica rapa\nPlants growing in dense stands compete with one another for light resources at the top of the canopy. When plants sense neighbors through the phytochrome photoreceptor system they become apical dominant and grow upwards to maximize light capture. This response is termed shade avoidance and has very important ecological and agronomic consequences if plant resources are used for competitive growth instead of reproductive output. For example, over-seeding in an agricultural field is wasteful of seed resources if many individuals die after competing with neighbors for limited light and nutrient resources. In ecological settings, mixed plant communities are competing for resources in a similar way to agricultural settings, but without the direct human management of inputs. In order to study the agronomic and ecological consequences of competition I am worked with the emerging model species Brassica rapa. B. rapa is an ideal model for plant competition research because it has a sequenced genome, is both a crop and a weed in agricultural settings, and is a highly morphologically and physiologically diverse species. I approached this from many different angles that relied on my diverse research background and interests.\n\n\n\nresearch-overview\n\n\n\n\n1) B. rapa trait database\n\n\n\ngraph_db\n\n\nHard won biological data (especially from the field) should not just sit in a lab note book or on spread sheets scattered across various machines. Sharing phenotypic data after publication should be a priority for us as a community, just like putting sequencing data into NCBI databases (see Zamir 2013). This allows for the data to be used to ask multiple questions, for modeling, or to be analyzed using systems biology techniques. Towards all these goals I designed a graph database to house all of the published trait data, experimental meta-data, publications, gene expression data, from the B. rapa population.\nA partial realization of this work has come out of working with an undergraduate Tiffany Ho to create an interactive data visualization tool to examine co-occurrence of eQTL with physiological QTL called QTLVisR.\n\n\n2) Statistical Genetics\nIn collaboration with Mike Covington (who generated the SNPs), I created a saturated genetic map for this population (here). This new map, along with a Bayesian statistical approach and my graph database all blends together into a fun data science project. I am remapping all the published traits in the database using a multi-trait approach. This data is used directly in the next two aspects of my project.\nMarkelz et al. 2017\nBrock et al. 2016\n\n\n\ngenetic_map\n\n\n\n\n3) Multi-Scale Data Integration\nThe central dogma of molecular biology says DNA → RNA → Protein. Scaling the actions and interactions of proteins spatially across tissue or cell types is physiology. Scaling the actions of physiology across space and time is development. Updating the simple model to include physiology and development would look something like this: DNA → RNA → Protein → Metabolites → Physiology → Development. Of course there are feedbacks every step of the way, and it is hard to disentangle each of these into separate processes, but this simple conceptual model goes a long way. If there is a genomic location for these interactions explaining some of the variance observed in the physiological or developmental phenotype, then there is a QTL in that genomic location. QTL studies are conducted using genetic mapping populations where the parents of these populations are differ significantly from one another in the trait of interest. Up until recently, a majority of QTL studies have focused on traits that are the result of many proteins interacting one level of biological organization below the physiological or developmental trait. It is a large jump in biological organization to work backwards from physiology and development to DNA sequence differences. Quantifying messenger RNA (mRNA) acts as a stepping stone between the physiology and the DNA. Or to put it another way, mRNA can provide clues as to what proteins cells are planning to make given the current information from internal developmental and external environmental cues. The collection of mRNA expression is generally referred to as the gene co-expression network. I am interested in understanding the gene co-expression network and how it relates to DNA polymorphisms in one direction and physiological and developmental phenotypes in the other direction. In order to be able to do this, we not only need a good understanding of the biology, but we also need a good understanding of the ways in which these pieces of biological information fit together. I developed statistical techniques to connect these pieces of information in a probabilistic framework.\nBaker et al. 2019\nMarkelz et al. 2017\nBrock et al. 2016\nBaker et al. 2015\n\n\n4) Genetically Informed B. rapa Physiological Growth Models\nI am using this data to parameterize physiologically based models of plant growth. Coming full circle to my PhD work in metabolism and physiology. This is my favorite part of my project. It involves integrating environmental time course data, physiological QTLs, and programming mathematical models of plant growth. Based on my meta-analysis results, and preliminary physiological modeling results, I choose a subset of genotypes to grow in the field for 2014 to test model predictions. The field site I work at is home to three close collaborators at University of Wyoming: Dr. Rob Baker, Dr. Marc Brock, and Dr. Cynthia Weinig.\nBaker et al. 2019\nBaker et al. 2015\nHere is a preview of a canopy scale model output predicting peak canopy N content for four different treatments. Notice that there is a clear interaction between N availability and crowding as to when there is peak canopy N.\n\n\n\nphysiology_simulations\n\n\n\n\n5) Computer Vision Plant Quantification and 3D Reconstruction\nI developed a high-throughput 3D imaging robot and analysis pipeline to take non-destructive plant growth data for model calibration/validation of Brassica rapa. It was really enjoyable to build equipment. It pulls together many ways of thinking about biological problems. It forces the biologist to really think about what process they are trying understand and how to quantify it using some sort of sensor. These projects help biologists build intuition about measurement error, instrument limitation, methods development, materials selection, and design. These are skills that are undervalued in biology.\nBucksch et al. 2017\nFriesner et al. 2017\nI also co-designed a similar system for measuring Arabidopsis growth.\nAn et al. 2016\nAn et al. 2017\n\n\n\n3D_summary"
  },
  {
    "objectID": "science/undergraduate_projects.html",
    "href": "science/undergraduate_projects.html",
    "title": "Undergraduate Research Projects",
    "section": "",
    "text": "Senior Distinction Project\nThesis Title: How will elevated [CO2] alter soil and plant water status of the C3-crop soybean and the C4-crop maize? Advisors: Dr. Donald Ort and Dr. Andrew Leakey\nThis work was published as part of the following paper: Future carbon dioxide concentration decreases canopy evapotranspiration and soil water depletion by field-grown maize- Hussain et al. 2013\n\n\n\nSoybean nitrogen metabolism under elevated [CO2]\nElemental nitrogen analysis and microarray data visualization from soybean leaves grown at ambient or elevated [CO2]. Advisor: Dr. Andrew Leakey\n\n\n\nBehavioral Ecology of Social Insects\nThis research was focused on characterizing task interference behavior in the fungal growing ant colonies Atta cephalotes. I manipulated waste management activities within the nest of laboratory colonies to study task preference within the colonies’ divisions of labor. Advisor: Dr. Sam Beshers\n\n\n\nMicrolepedoptera of Illinois Hill Prairies\nField collection and organization of micro-lepidoptera samples from hill prairie sites along a Illinois River Basin transect. Advisors: Dr. Terry Harrison and Dr. May Berenbaum"
  },
  {
    "objectID": "science/undergraduate_projects.html#soybean-nitrogen-metabolism-under-elevated-co2",
    "href": "science/undergraduate_projects.html#soybean-nitrogen-metabolism-under-elevated-co2",
    "title": "Undergraduate Research Projects",
    "section": "Soybean nitrogen metabolism under elevated [CO2]",
    "text": "Soybean nitrogen metabolism under elevated [CO2]\nElemental nitrogen analysis and microarray data visualization from soybean leaves grown at ambient or elevated [CO2]. Advisor: Dr. Andrew Leakey"
  },
  {
    "objectID": "science/undergraduate_projects.html#behavioral-ecology-of-social-insects",
    "href": "science/undergraduate_projects.html#behavioral-ecology-of-social-insects",
    "title": "Undergraduate Research Projects",
    "section": "Behavioral Ecology of Social Insects",
    "text": "Behavioral Ecology of Social Insects\nThis research was focused on characterizing task interference behavior in the fungal growing ant colonies Atta cephalotes. I manipulated waste management activities within the nest of laboratory colonies to study task preference within the colonies’ divisions of labor. Advisor: Dr. Sam Beshers"
  },
  {
    "objectID": "science/undergraduate_projects.html#microlepedoptera-of-illinois-hill-prairies",
    "href": "science/undergraduate_projects.html#microlepedoptera-of-illinois-hill-prairies",
    "title": "Undergraduate Research Projects",
    "section": "Microlepedoptera of Illinois Hill Prairies",
    "text": "Microlepedoptera of Illinois Hill Prairies\nField collection and organization of micro-lepidoptera samples from hill prairie sites along a Illinois River Basin transect. Advisors: Dr. Terry Harrison and Dr. May Berenbaum"
  },
  {
    "objectID": "science/rev_genomics.html",
    "href": "science/rev_genomics.html",
    "title": "Rev Genomics",
    "section": "",
    "text": "Company Overview\nI was the co-founder and VP of Genomics and led the technical aspects of Rev Genomics from idea to post series-A (2015-2020). I led, designed and implemented a probabilistic framework to elucidate novel biochemical pathways in Cannabis. Under my leadership my team built a data driven Cannabis breeding pipeline using genomic prediction leading to 15+ commercial strains being developed for the legal California market. Notable investors for Rev Genomics are Y-Combinator and Gron Ventures.\n\n\nOpen Cannabis SNP Map Dataset\nAs part of my work at Rev Genomics, I analyzed and generated a dataset of 23500+ SNP and 2200+ InDel molecular markers from 1358 cultivars of Cannabis to aid in open-source breeding projects. The project contains data and tutorial on how to view and use the data using open-source tools. The data and tutorial are licensed under Creative Commons Attributions License 4.0 and can be downloaded directly here (500MB). An accompanying article was published on the Future Cannabis Project Blog.\nRev Genomics continues in innovate in the Cannabis biotechnology space."
  },
  {
    "objectID": "science/science_communications.html",
    "href": "science/science_communications.html",
    "title": "Sci-Comm Projects",
    "section": "",
    "text": "Academic Data Science Alliance (ADSA) Career Workshop Sketchnote\nThis project consists of managing content creation for the Berkeley Institute for Data Science (BIDS) through social media, email newsletters, and annual reports. This project extends my research at Environmental Change Fellowship research at BIDS through the creation of a series of long-form articles that include infographics, data visualizations and illustrations aimed at a general scientific audience. Additionally, I am collaborating with BIDS affiliated scientists to make research summaries in the form of sketchnotes, visual abstracts and short articles aimed at a general science audience to help fulfill broader impacts goals of grants. Additionally, attending professional data science meetings and doing live sketchnotes like the one pictured above.\nAs part of this role I am co-hosting a series of workshops for graduate students and post-docs on the use of Quarto on static document publishing and reproducible data analysis for environmental and data journalism projects."
  },
  {
    "objectID": "science/biodiversity_fire.html",
    "href": "science/biodiversity_fire.html",
    "title": "Berkeley Institute for Data Science",
    "section": "",
    "text": "As we enter an era of unprecedented amounts of data, we also face the defining challenge of our age - global environmental change. From automated environmental sensors to satellite imaging to emerging DNA technologies, the data that describes the world around us will aid us in how we approach the many challenges of a changing climate. By harnessing this data we can develop data science tools that allow us to predict, and further define how we as a society can respond and mitigate the effects of climate change.\nMy main project is developing a multi-level modeling framework that incorporates environmental variables, satellite data, historical species observations, and environmental DNA (eDNA) data across fire regimes in Californian ecosystems. The collated data sets and resulting modeling framework will enable researchers to better understand the impact of historical and recent fire on arthropod communities in sites across the University of California Natural Reserve System. We hope that this framework will be able to be applied to other open questions regarding fire and biodiversity. This is a unique project that is rooted in basic research but provides a framework for interoperability between different data types. The project outcomes will be disseminated through a research blog and tutorials, open-source code, and regular open publications.\nThis project is part of a two year fellowship in Global Change Research at the Berkeley Institute of Data Science (BIDS).\n\n\n\n\nCiera Martinez, Biodiversity and Environmental Sciences Lead, BIDS\nDavid Ackerly, Dean, College of Natural Resource\nRosemary Gillespie, Professor, Environmental Science, Policy, and Management\nKarthik Ram, Senior Research Data Scientist, BIDS\nAccenture Applied Intelligence, to fully harness the data landscape and expertise available. Through independent fellowships, Accenture supports BID’s research and educational objectives in data science with current foci on environment and energy, ethical AI, and social justice."
  },
  {
    "objectID": "science/teaching.html",
    "href": "science/teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "In an age of information abundance, the university is now a place where students come to learn active strategies for navigating this sea of information in a scientifically literate way. Through my experience I have found that one of the best ways for students to achieve this goal is to have a safe environment centered around projects where asking questions and thinking critically are encouraged. Scientific discovery is not achieved in a vacuum. Science is a social activity based on communicating ideas and structuring arguments supported by evidence. However, science is often not taught in an interactive way, but in a passive way. Biology is a particularly bad offender of teaching material as a long string of facts to be memorized. As a graduate student and a postdoc, I have used and refined many project-based learning strategies to engage students of different age groups, skill levels, and class sizes. I consider teaching and mentoring to be successful when students become more scientifically literate and/or gain the tools necessary to pursue their chosen careers in science or related fields.\nMentoring students on independent research projects is the most rewarding teaching experience because the project can be designed and individualized for the learning and career goals of the student. My approach is to ask for a one-year minimum commitment, allowing time for mentorship and for skill development. Students first learn the big picture view of science that includes how to read a scientific paper and perform a small literature review. At the same time, I help students design a short experiment to answer a simple question and collect a small dataset. This dataset is used to start teaching programming and data analysis as soon as possible because it takes the longest for students to learn. During weekly meetings students use a white board to explain their project and progress to myself and the other undergraduates that I mentor. This exercise has the students teaching one another about their projects and prepares the students to present a talk or poster at the undergraduate research conference. This research year takes students through the scientific process from question to experimental design to data analysis and interpretation to writing and presentation. After the first year, students are usually interested in staying for longer and then we write up their preliminary results as part of an undergraduate research fellowship to NSF or ASPB. This approach has successfully trained seven undergraduates and technicians that have gone on to scientific graduate programs.\nThrough my teaching and mentoring I have found that programming, data analysis, and data visualization are all necessary skills missing from most biology curriculum. An intro class on this topic is challenging to teach because in addition to learning new biological topics, students must also learn a new programming language. At UC Davis, I developed part of an open-source genomics lab class that teaches undergraduate biology students these skills. The course was taught using Linux virtual machines that ran off of portable USB drives allowing students to make mistakes and explore data sets without fear of crashing servers. Students also learned how to use Git for version control and www.github.com for collaboration and turning in assignments. The module that I created was on genetic networks. After a brief intro lecture each day, the students worked through an interactive online tutorial that taught the basics of network and graph theory. The students were then challenged to apply what they learned towards analyzing, visualizing and interpreting a large RNA-seq data set. This module emphasized the usefulness of applying mathematical abstractions and concepts towards understanding biological systems. Setting small programming goals designed to answer increasingly complex biological questions on real data sets is an effective way to teach computer science and bioinformatics in the same course. For example, a student in the class used her new skills to analyze a large sequencing dataset as part of her senior research project.\nI was a teaching assistant for the undergraduate-level general education class, Global Warming, Biofuels, and Food, which had 75 students at University of Illinois. Halfway through the semester, the instructor could no longer continue, so I stepped up to take over lecturing. This offered a unique opportunity for me to create and deliver lectures for a large lecture hall, and receive feedback on the student’s conceptual understanding during small-group discussion sections. For this course, I made the university wide “List of Teachers Ranked Excellent” based on student evaluations and received the Outstanding Teaching Award from the Department of Plant Biology. This opportunity sharpened my lecture preparation and delivery to focus on the important concepts by providing examples from the scientific literature or popular science articles.\nAs a teaching assistant for the graduate level class at University of Illinois, Plants and Global Change, I led or participated in two unique project-based learning approaches which engaged students and taught them course material in innovative ways: podcast development and formal debates. The podcast assignment aimed to teach science communication skills and to improve students’ knowledge of the topic area. Small student groups chose recent high-impact papers in the climate change literature as a focus of their podcast, and conducted literature reviews. I created tutorials on podcast recording and editing using the open-source audio editing software, Audacity. The students used this tutorial to record in-person or Skype interviews with the author, and add intro music and background information. This mixed media approach was a favorite with the students because they learned how media, other than writing, can be used to communicate important scientific ideas. These types of creative projects will be incorporated as part of future teaching opportunities that actively engage students beyond textbooks. This early content and methods were used as the precursor to the Audible Ecoscience podcast database project.\nAnother successful project-based teaching method used in this graduate-level course was a formal, parliamentary-style debate for scientifically contentious issues. After learning related material in lectures, teams of students were assigned to formalize arguments for or against a scientific proposition under the guidance of debate coaches, who were experts in the field. Debate topics included the role of human activity in climate change, and the potential for cellulosic biofuels to mitigate environmental impacts of fossil fuel use. I moderated the debates as a gavel-wielding judge in a powdered wig, preventing the debate from going over time or off topic. Students were personally invested, and so became well-versed, in their side of the debate, and they enjoyed the theatrics. These debates became so popular that students, postdocs, and professors who were not enrolled in or teaching the class would attend the debates and pose questions to the teams. The podcast and the debate were active learning exercises that engaged the students to work in teams, communicate science to a general audience, and make scientific arguments based on the literature. It is not only the volume of material that can be fit into a semester course, but also the quality of critical thinking and student engagement that determines their ability to comprehend the subject matter."
  },
  {
    "objectID": "science/science_outreach.html",
    "href": "science/science_outreach.html",
    "title": "Science Outreach",
    "section": "",
    "text": "Dr. Sharon B. Gray Memorial Foundation\n“I feel that when the human race acquired the technology and evolved the intelligence necessary to build an industrial society, it also acquired the moral obligation to understand and monitor its impact on the rest of the world.” -Dr. Sharon B. Gray\nDr. Sharon Gray was a bright human being with a passion for science and mentoring women. This foundation has set up endowments for financially supporting women in science at UC Davis, University of Illinois Urbana-Champaign, American Society of Plant Biology, and the Ethiopian Agricultural Research Center (EIAR). To date, 37 scientists have received research or travel funding through the foundation. Read more about the projects here.\n\n\nPlants iView High-Throughput Phenotyping, Raspberry Pi, Computer Vision\nA new module for Plants iView emphasizing quantitative biology and experimental design for 7th graders. Students set up Raspberry Pi Camera rigs to take time-lapse photos of Arabidopsis plants growing in control or drought conditions. Learning the basics of computer vision and plotting students were able to interpret the plant growth data to see if their hypotheses were supported. It was great working with Jennifer Quebedeaux on this module.\n\nQuantitative biology by 7th graders at Champaign, IL Unit 4 School District\n\n\n\n\nPlants iView\nI led a group of Illinois Plant Biology graduate students in creating middle school plant science curriculum to fit into an afterschool program at Urbana Middle School. As a group we wrote two successful grants to secure funding from the ASPB Educational Foundation Grant and the Illinois Public Engagement Grant for this project. This platform is still in use as a major outreach project for the Illinois Department of Plant Biology. All of the course materials, teacher discussion forum, and student blogs can be accessed through the Plants iView website. We made sure that the lessons met national and Illinois specific educational standards for grades 6-8. The graduate students then taught all the lessons for the program.\n\nTeaching a lesson at the Pollinatarium\n\n\n\n\nNational Pollinator Week\nFor 2010 and 2011, I co-organized this community event with Dr. Michelle Duennes, A.K.A the Polly Nator! For the month leading up to National Pollinator Week Michelle and I worked a booth at the Urbana Farmers Market discussing the importance of pollinators for food production.\n\nShowing off my bumble bee tattoo. Mural by Glen C. Davies.\n\nAt the end of National Pollinator Week we hosted all day events that included:\n\nNature walks led by The Prairie Monk\nInsect photography workshop by Scientific American Blogger Alex Wild\nHoney Tastings\nNurturing native bee workshop\nNative bee identification workshop\nLive concert by Duke of Uke and His Novelty Orchestra\n\n\n\n\nThreatened Species Survey\nVolunteered for field trip to find, identify, and catalog rare orchids and other plant species in Grampians National Park, Victoria, Australia.\n\n\nUIUC International Impact\nFundraising and service project in Ecuador building a school for a small indigenous village North of the capital city, Quito\n\n\nCamp Healing Heart\nI was a counselor at a nature based overnight camp to help children who recently lost parents deal with grief in a natural setting. This camp was sponsored by a local hospice chapter that my family used for at home care of my dad’s battle with cancer."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 15, 2021\n\n\nIntroduction to Obsidian\n\n\nRJ Cody Markelz\n\n\n\n\nJun 17, 2021\n\n\nMiracle Mile Conifer Species\n\n\nRJ Cody Markelz\n\n\n\n\nMar 1, 2023\n\n\nPost With Code\n\n\nHarlow Malloc\n\n\n\n\nFeb 26, 2023\n\n\nWelcome To My Blog\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMar 1, 2023\n\n\nPost With Code\n\n\nHarlow Malloc\n\n\n\n\nFeb 26, 2023\n\n\nWelcome To My Blog\n\n\nTristan O’Malley\n\n\n\n\nDec 15, 2021\n\n\nIntroduction to Obsidian\n\n\nRJ Cody Markelz\n\n\n\n\nJun 17, 2021\n\n\nMiracle Mile Conifer Species\n\n\nRJ Cody Markelz\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "outreach.html",
    "href": "outreach.html",
    "title": "Outreach",
    "section": "",
    "text": "Dr. Sharon B. Gray Memorial Foundation\n“I feel that when the human race acquired the technology and evolved the intelligence necessary to build an industrial society, it also acquired the moral obligation to understand and monitor its impact on the rest of the world.” -Dr. Sharon B. Gray\nDr. Sharon Gray was a bright human being with a passion for science and mentoring women. This foundation has set up endowments for financially supporting women in science at UC Davis, University of Illinois Urbana-Champaign, American Society of Plant Biology, and the Ethiopian Agricultural Research Center (EIAR). To date, 39 scientists have received research or travel funding through the foundation. Read more about the projects here.\nTo donate directly to support mentoring women in science: UC Davis Sharon Gray Memorial Fund.\n\n\n\nPlants iView High-Throughput Phenotyping, Raspberry Pi, Computer Vision\nA new module for Plants iView emphasizing quantitative biology and experimental design for 7th graders. Students set up Raspberry Pi Camera rigs to take time-lapse photos of Arabidopsis plants growing in control or drought conditions. Learning the basics of computer vision and plotting students were able to interpret the plant growth data to see if their hypotheses were supported. It was great working with Jennifer Quebedeaux on this module.\n\n\n\n\nQuantitative biology by 7th graders at Champaign, IL Unit 4 School District\n\n\n\n\nPlants iView\nI led a group of Illinois Plant Biology graduate students in creating middle school plant science curriculum to fit into an afterschool program at Urbana Middle School. As a group we wrote two successful grants to secure funding from the ASPB Educational Foundation Grant and the Illinois Public Engagement Grant for this project. This platform is still in use as a major outreach project for the Illinois Department of Plant Biology. All of the course materials, teacher discussion forum, and student blogs can be accessed through the Plants iView website. We made sure that the lessons met national and Illinois specific educational standards for grades 6-8. The graduate students then taught all the lessons for the program.\n\n\n\nTeaching a lesson at the Pollinatarium\n\n\n\nNational Pollinator Week\nFor 2010 and 2011, I co-organized this community event with Dr. Michelle Duennes, A.K.A the Polly Nator! For the month leading up to National Pollinator Week Michelle and I worked a booth at the Urbana Farmers Market discussing the importance of pollinators for food production.\n\n\n\nShowing off my bumble bee tattoo. Pollinator mural by Glen C. Davies.\n\nAt the end of National Pollinator Week we hosted all day events that included:\n\nNature walks led by The Prairie Monk\nInsect photography workshop by Scientific American Blogger Alex Wild\nHoney Tastings\nNurturing native bee workshop\nNative bee identification workshop\nLive concert by Duke of Uke and His Novelty Orchestra\n\n\n\n\n\nThreatened Species Survey\nVolunteered for field trip to find, identify, and catalog rare orchids and other plant species in Grampians National Park, Victoria, Australia.\n\n\n\nUIUC International Impact\nFundraising and service project in Ecuador building a school for a small indigenous village North of the capital city, Quito\n\n\n\nCamp Healing Heart\nI was a counselor at a nature based overnight camp to help children who recently lost parents deal with grief in a natural setting. This camp was sponsored by a local hospice chapter that my family used for at home care of my dad’s battle with cancer."
  },
  {
    "objectID": "art.html",
    "href": "art.html",
    "title": "Art",
    "section": "",
    "text": "Making things and drawing has been a part of my life since I was a child. The techniques have (hopefully) gotten better, but my childlike curiosity of filtering what I see remains a deep part of my experience as a human. Below are a few examples of my work, but checkout my Portfolio Website for more.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesign\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSketchnotes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "adventure.html",
    "href": "adventure.html",
    "title": "Adventure",
    "section": "",
    "text": "One of the best aspects to living in Northern California is the access to incredible wilderness and diverse forests. My partner and I spend most of our free time exploring these areas on foot, bicycle, skis or kayak/SUP.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBike\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFish\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHike\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNature Journal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRun\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSki\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "art/illustration.html",
    "href": "art/illustration.html",
    "title": "Illustration",
    "section": "",
    "text": "Pinus lambertiana (sugar pine) cone\n\n\n\n\nMy brother on a buffalo\n\n\n\n\nYosemite backcountry skiing in a windstorm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG.I. Joe comic book coloring example (Line art by Robert Atkins and Clayton Brown, IDW Publishing)"
  },
  {
    "objectID": "art/design.html",
    "href": "art/design.html",
    "title": "Design",
    "section": "",
    "text": "ArtScienceHack Design Summary"
  },
  {
    "objectID": "posts/2021-05-15-mlk-cycling-nature/index.html",
    "href": "posts/2021-05-15-mlk-cycling-nature/index.html",
    "title": "MLK Shoreline iNaturalist data",
    "section": "",
    "text": "MLK Shoreline and iNaturalist Observations\nFor the last few years I commuted to work most days by bicycle along the Martin Luther King Jr. Regional Shoreline Park in Oakland, CA. This will be a series of data science posts exploring personal data collected by my smart watch and publicly available weather, nature and biodiversity data collected in this park. It is my hope that this will show into the brain of how a data scientist thinks, learns, asks questions, creates models, and visualizes data from right in their back yard through a series of posts. This is an intro post pulling in the data and doing some basic data exploration and visualizations.\nWe can start by loading a few libraries to make data manipulation and visualization easier.\n\nlibrary(tidyverse)\nlibrary(rinat)\nlibrary(lubridate)\nlibrary(leaflet)\n\nSet a bounding box around the park and subset some of the observations from the database that are “research” grade. Fortunately, this area is located in the San Francisco Bay Area with many professional and advanced amateur biologists around making observations. This park is also a popular spot for bird watching.\n\nbounds <- c(37.72794, -122.23864,37.767032, -122.196754)\nmlk_bio <- get_inat_obs(bounds = bounds, maxresults = 1000, quality = \"research\")\n\nInspect the data structure. At time of writing there are 5395 observations and 36 columns of data. We can see that there are various pieces of data that we would want to start taking a deeper look including: Scientific Name, the datatime of the observation, the latitude and longitude coordinates of the observation, associated image (image_url), and whether the observation is licensed as a CC for creative commons, to name a few. We also have a column of “user_login” data so we can see how many observations are contributed by different users.\n\ndim(mlk_bio)\n\n[1] 1000   37\n\nnames(mlk_bio)\n\n [1] \"scientific_name\"                  \"datetime\"                        \n [3] \"description\"                      \"place_guess\"                     \n [5] \"latitude\"                         \"longitude\"                       \n [7] \"tag_list\"                         \"common_name\"                     \n [9] \"url\"                              \"image_url\"                       \n[11] \"user_login\"                       \"id\"                              \n[13] \"species_guess\"                    \"iconic_taxon_name\"               \n[15] \"taxon_id\"                         \"num_identification_agreements\"   \n[17] \"num_identification_disagreements\" \"observed_on_string\"              \n[19] \"observed_on\"                      \"time_observed_at\"                \n[21] \"time_zone\"                        \"positional_accuracy\"             \n[23] \"public_positional_accuracy\"       \"geoprivacy\"                      \n[25] \"taxon_geoprivacy\"                 \"coordinates_obscured\"            \n[27] \"positioning_method\"               \"positioning_device\"              \n[29] \"user_id\"                          \"user_name\"                       \n[31] \"created_at\"                       \"updated_at\"                      \n[33] \"quality_grade\"                    \"license\"                         \n[35] \"sound_url\"                        \"oauth_application_id\"            \n[37] \"captive_cultivated\"              \n\n\nThere are photos included with a majority of the observations. Let’s take a look. \n\n\n\nBarn Swallow\n\n\n\n\n\nNorthern Mockingbird\n\n\nMake a quick plot of the data without a map overlay just to see what it looks like colored by large taxonomic groupings.\n\nmlk_bio_P1  <- ggplot(mlk_bio, aes(x=longitude, y = latitude, color = iconic_taxon_name)) +\n       geom_point() + labs(color = \"Taxon\", title = \"MLK Shoreline iNaturalist Observations\")\nmlk_bio_P1\n\n\n\n\nThis is a popular birding spot, so one might expect there to be an over representation of bird (Aves) observations. Just how overrepresented are the Aves? A quick plot to take a look. Wow!\n\nmlk_bio_P2  <- ggplot(mlk_bio, aes(x = iconic_taxon_name)) + stat_count() +\n                    scale_x_discrete(guide = guide_axis(angle = 45))\nmlk_bio_P2\n\n\n\n\nTake a look at the data with the Open Maps overlay to see the outline of the water front and the various roads and bridges where observers might be located.\n\nmlk_bio %>% leaflet() %>% addTiles() %>%\naddMarkers(~longitude, ~latitude)\n\n\n\n\n\nDefinitely over plotted, but will deal with that in another post. Until then!"
  },
  {
    "objectID": "posts/2022-01-15-scraping-weather-data/index.html",
    "href": "posts/2022-01-15-scraping-weather-data/index.html",
    "title": "Scraping Weather Data",
    "section": "",
    "text": "A quick post showing how to extract data from a website and make a few plots. I chose the Mount Shasta Avalanche Center data because I monitor this everyday throughout the season to see how the avalanche forecast changes and how the snowpack is developing.\n\nR vest\nThere is a great website scraping package that is part of the tidyverse called Rvest. Check out the Documentation.\n\nlibrary(rvest)\nlibrary(tidyverse)\nlibrary(lubridate)\n\n\nhtml <- read_html(\"https://www.shastaavalanche.org/page/seasonal-weather-history-mount-shasta\")\n\n# right click on the page to see the table\nhtml %>%\n    html_element(\".msac-wx-history-table\") %>%\n    html_table()\n\n# A tibble: 13 × 2\n   `Weather History Summary from Oct 1, 2022 to Mar 29, 2023` Weather History …¹\n   <chr>                                                                   <dbl>\n 1 Temp Max (°F)                                                            49  \n 2 Temp Min (°F)                                                             3  \n 3 Temp Avg (°F)                                                            24  \n 4 Wind Max (mi/hr)                                                         68.5\n 5 Wind Min (mi/hr)                                                          0  \n 6 Wind Avg (mi/hr)                                                         12  \n 7 Wind Gust Max (mi/hr)                                                   110. \n 8 Total Snowfall (in)                                                     327. \n 9 Total Accumulated Precipitation (Water Equivalent) (in)                  28.4\n10 Max Snowfall in 24 Hrs (in)                                              36.2\n11 Snow Depth Max (in)                                                     212. \n12 Snow Depth Min (in)                                                      31.9\n13 Snow Depth Avg (in)                                                     124  \n# … with abbreviated variable name\n#   ¹​`Weather History Summary from Oct 1, 2022 to Mar 29, 2023`\n\n\n\n# Right click on the page and get the xpath to a specific table\nxpath <- \"/html/body/div[2]/main/div/article/div/table[2]\"\nweather <- html_nodes(html, xpath = xpath)\nhtml_table(weather)\n\n[[1]]\n# A tibble: 131 × 21\n   Observed an…¹ Obser…² Obser…³ Obser…⁴ Obser…⁵ Obser…⁶ Obser…⁷ Obser…⁸ Obser…⁹\n   <chr>         <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 \"\"            Ob Tem… Ob Tem… Ob Tem… Ob Win… Ob Win… Ob Win… Ob Win… Ob Win…\n 2 \"Date\"        Min     Max     Avg     Min     Max     Avg     Gust    Dir    \n 3 \"2023 03/28\"  16.5    23.5    18      5.5     20      9.5     42.93   SSE    \n 4 \"2023 03/27\"  16.5    23.5    18      5.5     20      11.5    42.93   SSE    \n 5 \"2023 03/26\"  4       28      15.5    1       10.5    5.5     24.54   SE     \n 6 \"2023 03/25\"  6.5     22      15      5.5     33.5    16.5    67.47   NW     \n 7 \"2023 03/24\"  5       24      14.5    4.5     39      22      61.34   NW     \n 8 \"2023 03/23\"  12.5    29      19.5    8.5     39      20      67.47   WNW    \n 9 \"2023 03/22\"  19      28.5    23.5    7       11.5    10      30.66   WNW    \n10 \"2023 03/21\"  19      28.5    23.5    4.5     37      25.5    67.47   E      \n# … with 121 more rows, 12 more variables:\n#   `Observed and Forecast Weather by Day` <chr>,\n#   `Observed and Forecast Weather by Day` <chr>,\n#   `Observed and Forecast Weather by Day` <chr>,\n#   `Observed and Forecast Weather by Day` <chr>,\n#   `Observed and Forecast Weather by Day` <chr>,\n#   `Observed and Forecast Weather by Day` <chr>, …\n\n\n\n# make a data.frame with the table\nweather2 <- as.data.frame(html_table(weather, fill=TRUE))\n\n# rename columns\nnames(weather2) <- paste(weather2[1,], weather2[2,])\nnames(weather2)\n\n [1] \" Date\"                       \"Ob Temp (°F) Min\"           \n [3] \"Ob Temp (°F) Max\"            \"Ob Temp (°F) Avg\"           \n [5] \"Ob Wind (mi/hr) Min\"         \"Ob Wind (mi/hr) Max\"        \n [7] \"Ob Wind (mi/hr) Avg\"         \"Ob Wind (mi/hr) Gust\"       \n [9] \"Ob Wind (mi/hr) Dir\"         \"Ob Snow (in) HS\"            \n[11] \"Ob Snow (in) HN24\"           \"Ob Snow (in) SWE\"           \n[13] \"Ob Snow (in) Total Snowfall\" \"Fx Temp (°F) Min\"           \n[15] \"Fx Temp (°F) Max\"            \"Fx Wind (mi/hr) Min\"        \n[17] \"Fx Wind (mi/hr) Max\"         \"Fx Snow (in) Min\"           \n[19] \"Fx Snow (in) Max\"            \"Fx Snow (in) SWE\"           \n[21] \"Fx Rating \"                 \n\nnames(weather2)[1] <- paste(\"date\")\n\n# remove rows that are now column names\nweather2 <- weather2[-c(1,2),]\n\n# take a look\nglimpse(weather2)\n\nRows: 129\nColumns: 21\n$ date                          <chr> \"2023 03/28\", \"2023 03/27\", \"2023 03/26\"…\n$ `Ob Temp (°F) Min`            <chr> \"16.5\", \"16.5\", \"4\", \"6.5\", \"5\", \"12.5\",…\n$ `Ob Temp (°F) Max`            <chr> \"23.5\", \"23.5\", \"28\", \"22\", \"24\", \"29\", …\n$ `Ob Temp (°F) Avg`            <chr> \"18\", \"18\", \"15.5\", \"15\", \"14.5\", \"19.5\"…\n$ `Ob Wind (mi/hr) Min`         <chr> \"5.5\", \"5.5\", \"1\", \"5.5\", \"4.5\", \"8.5\", …\n$ `Ob Wind (mi/hr) Max`         <chr> \"20\", \"20\", \"10.5\", \"33.5\", \"39\", \"39\", …\n$ `Ob Wind (mi/hr) Avg`         <chr> \"9.5\", \"11.5\", \"5.5\", \"16.5\", \"22\", \"20\"…\n$ `Ob Wind (mi/hr) Gust`        <chr> \"42.93\", \"42.93\", \"24.54\", \"67.47\", \"61.…\n$ `Ob Wind (mi/hr) Dir`         <chr> \"SSE\", \"SSE\", \"SE\", \"NW\", \"NW\", \"WNW\", \"…\n$ `Ob Snow (in) HS`             <chr> \"212.3\", \"211.1\", \"188.6\", \"190.9\", \"190…\n$ `Ob Snow (in) HN24`           <chr> \"9.5\", \"18.5\", \"0\", \"0.1\", \"0\", \"0\", \"0\"…\n$ `Ob Snow (in) SWE`            <chr> \"0\", \"0\", \"0.01\", \"0\", \"0.05\", \"0.16\", \"…\n$ `Ob Snow (in) Total Snowfall` <chr> \"310.8\", \"301.3\", \"282.8\", \"282.8\", \"282…\n$ `Fx Temp (°F) Min`            <chr> \"17\", \"18\", \"12\", \"11\", \"11\", \"14\", \"23\"…\n$ `Fx Temp (°F) Max`            <chr> \"30\", \"27\", \"27\", \"21\", \"22\", \"26\", \"33\"…\n$ `Fx Wind (mi/hr) Min`         <chr> \"15\", \"30\", \"25\", \"25\", \"30\", \"25\", \"10\"…\n$ `Fx Wind (mi/hr) Max`         <chr> \"25\", \"40\", \"35\", \"35\", \"40\", \"45\", \"20\"…\n$ `Fx Snow (in) Min`            <chr> \"5\", \"12\", \"0\", \"0\", \"2\", \"3\", \"2\", \"0\",…\n$ `Fx Snow (in) Max`            <chr> \"9.5\", \"18.5\", \"1.5\", \"1.5\", \"5\", \"7\", \"…\n$ `Fx Snow (in) SWE`            <chr> \"0.42\", \"1.01\", \"0.01\", \"0.03\", \"0.05\", …\n$ `Fx Rating `                  <chr> \"CON\", \"MOD\", \"MOD\", \"MOD\", \"LOW\", \"LOW\"…\n\n# columns that are numeric should be converted back to such. They were coerced into character vectors because of the first two rows were characters.\nweather2 <- weather2 %>%\nmutate_at(c(2:8), as.numeric)\n\nweather2 <- weather2 %>%\nmutate_at(c(10:20), as.numeric)\n\n# coerce date column\nweather2 <- weather2 %>%\nmutate_at(1, as_date)\n\n# take a quick look\nhead(weather2)\n\n        date Ob Temp (°F) Min Ob Temp (°F) Max Ob Temp (°F) Avg\n3 2023-03-28             16.5             23.5             18.0\n4 2023-03-27             16.5             23.5             18.0\n5 2023-03-26              4.0             28.0             15.5\n6 2023-03-25              6.5             22.0             15.0\n7 2023-03-24              5.0             24.0             14.5\n8 2023-03-23             12.5             29.0             19.5\n  Ob Wind (mi/hr) Min Ob Wind (mi/hr) Max Ob Wind (mi/hr) Avg\n3                 5.5                20.0                 9.5\n4                 5.5                20.0                11.5\n5                 1.0                10.5                 5.5\n6                 5.5                33.5                16.5\n7                 4.5                39.0                22.0\n8                 8.5                39.0                20.0\n  Ob Wind (mi/hr) Gust Ob Wind (mi/hr) Dir Ob Snow (in) HS Ob Snow (in) HN24\n3                42.93                 SSE           212.3               9.5\n4                42.93                 SSE           211.1              18.5\n5                24.54                  SE           188.6               0.0\n6                67.47                  NW           190.9               0.1\n7                61.34                  NW           190.7               0.0\n8                67.47                 WNW           192.9               0.0\n  Ob Snow (in) SWE Ob Snow (in) Total Snowfall Fx Temp (°F) Min\n3             0.00                       310.8               17\n4             0.00                       301.3               18\n5             0.01                       282.8               12\n6             0.00                       282.8               11\n7             0.05                       282.7               11\n8             0.16                       282.7               14\n  Fx Temp (°F) Max Fx Wind (mi/hr) Min Fx Wind (mi/hr) Max Fx Snow (in) Min\n3               30                  15                  25                5\n4               27                  30                  40               12\n5               27                  25                  35                0\n6               21                  25                  35                0\n7               22                  30                  40                2\n8               26                  25                  45                3\n  Fx Snow (in) Max Fx Snow (in) SWE Fx Rating \n3              9.5             0.42        CON\n4             18.5             1.01        MOD\n5              1.5             0.01        MOD\n6              1.5             0.03        MOD\n7              5.0             0.05        LOW\n8              7.0             0.06        LOW\n\nglimpse(weather2)\n\nRows: 129\nColumns: 21\n$ date                          <date> 2023-03-28, 2023-03-27, 2023-03-26, 202…\n$ `Ob Temp (°F) Min`            <dbl> 16.5, 16.5, 4.0, 6.5, 5.0, 12.5, 19.0, 1…\n$ `Ob Temp (°F) Max`            <dbl> 23.5, 23.5, 28.0, 22.0, 24.0, 29.0, 28.5…\n$ `Ob Temp (°F) Avg`            <dbl> 18.0, 18.0, 15.5, 15.0, 14.5, 19.5, 23.5…\n$ `Ob Wind (mi/hr) Min`         <dbl> 5.5, 5.5, 1.0, 5.5, 4.5, 8.5, 7.0, 4.5, …\n$ `Ob Wind (mi/hr) Max`         <dbl> 20.0, 20.0, 10.5, 33.5, 39.0, 39.0, 11.5…\n$ `Ob Wind (mi/hr) Avg`         <dbl> 9.5, 11.5, 5.5, 16.5, 22.0, 20.0, 10.0, …\n$ `Ob Wind (mi/hr) Gust`        <dbl> 42.93, 42.93, 24.54, 67.47, 61.34, 67.47…\n$ `Ob Wind (mi/hr) Dir`         <chr> \"SSE\", \"SSE\", \"SE\", \"NW\", \"NW\", \"WNW\", \"…\n$ `Ob Snow (in) HS`             <dbl> 212.3, 211.1, 188.6, 190.9, 190.7, 192.9…\n$ `Ob Snow (in) HN24`           <dbl> 9.5, 18.5, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0,…\n$ `Ob Snow (in) SWE`            <dbl> 0.00, 0.00, 0.01, 0.00, 0.05, 0.16, 0.00…\n$ `Ob Snow (in) Total Snowfall` <dbl> 310.8, 301.3, 282.8, 282.8, 282.7, 282.7…\n$ `Fx Temp (°F) Min`            <dbl> 17, 18, 12, 11, 11, 14, 23, 22, 18, 23, …\n$ `Fx Temp (°F) Max`            <dbl> 30, 27, 27, 21, 22, 26, 33, 36, 30, 32, …\n$ `Fx Wind (mi/hr) Min`         <dbl> 15, 30, 25, 25, 30, 25, 10, 20, 25, 45, …\n$ `Fx Wind (mi/hr) Max`         <dbl> 25, 40, 35, 35, 40, 45, 20, 30, 35, 55, …\n$ `Fx Snow (in) Min`            <dbl> 5, 12, 0, 0, 2, 3, 2, 0, 0, 7, 3, 0, 0, …\n$ `Fx Snow (in) Max`            <dbl> 9.5, 18.5, 1.5, 1.5, 5.0, 7.0, 4.0, 3.0,…\n$ `Fx Snow (in) SWE`            <dbl> 0.42, 1.01, 0.01, 0.03, 0.05, 0.06, 0.25…\n$ `Fx Rating `                  <chr> \"CON\", \"MOD\", \"MOD\", \"MOD\", \"LOW\", \"LOW\"…\n\n# Quick few plots to make sure everything looks reasonable\nweather_plot <- ggplot(weather2, aes(x=date, y=`Fx Snow (in) Min`)) +\n  geom_point()\nweather_plot\n\n\n\nweather_plot2 <- ggplot(weather2, aes(x=date, y=`Fx Wind (mi/hr) Max`)) +\n  geom_point()\nweather_plot2\n\n\n\nggsave(\"~/DATA/images/weather-scraping-plot.png\")\n\nUp next: Making sure the data is cleaned up after the scrape and coercion."
  },
  {
    "objectID": "posts/2022-02-01-uc-reserve-data-1/index.html",
    "href": "posts/2022-02-01-uc-reserve-data-1/index.html",
    "title": "UC Reserve System Environmental Data",
    "section": "",
    "text": "A short post on keeping small datasets in a data directory on my site, infiling the data, and then manipulating it.\nThe UC Reserve System has a many data sources including species lists. For this post I used the Plant Species List Excel File compiled by Brian P. Haggerty and Susan J. Mazer of UC Santa Barbara. I did a little data cleaning on this multi-tabbed spreadsheet.\n\nlibrary(tidyverse)\neco_data <- read.csv(\"~/DATA/data/reserve-eco-data.csv\")\n\nTake a quick look at how the data is structured.\n\nglimpse(eco_data)\n\nRows: 36\nColumns: 11\n$ UC.Natural.Reserve                        <chr> \"Año Nuevo Island Reserve (s…\n$ X..Unique.Species..excluding.ssp....var.. <int> 0, 42, 55, 87, 150, 159, 170…\n$ X..Taxa.including.ssp....var.             <int> 0, 45, 72, 88, 151, 162, 173…\n$ Reserve.Size..ha.                         <int> 10, 18624, 8, 11, 69, 22, 24…\n$ Elevation.Low..m.                         <int> 0, 0, 0, 0, 0, 1250, 21, 0, …\n$ Elevation.High..m.                        <int> 13, 742, 2, 15, 12, 4012, 58…\n$ Elevation.Range..m.                       <int> 13, 742, 2, 15, 12, 2762, 37…\n$ Precipitation..cm.                        <int> 50, 50, 22, 62, 77, 32, 46, …\n$ Temperature.Low...C.                      <chr> \"4\", \"10\", \"9\", \"12\", \"6\", \"…\n$ Temperature.High...C.                     <chr> \"24\", \"22\", \"25\", \"15\", \"24\"…\n$ X                                         <chr> \"24\", \"22\", \"25\", \"15\", \"24\"…\n\n\nData clean up and header labeling.\n\neco_data <- eco_data[1:10]\nnames(eco_data)[1:10] <- paste(c(\"reserve\", \"unique\", \"taxa\", \"size\", \"elevation_low\", \"elevation_high\", \"elevation_range\",\"precip\", \"temp_low\", \"temp_high\"))\nnames(eco_data)\n\n [1] \"reserve\"         \"unique\"          \"taxa\"            \"size\"           \n [5] \"elevation_low\"   \"elevation_high\"  \"elevation_range\" \"precip\"         \n [9] \"temp_low\"        \"temp_high\"      \n\neco_data$temp_high <- as.numeric(eco_data$temp_high)\n\nThe classic precipitation vs. temperature ecological plot.\n\nclassic <- ggplot(eco_data, aes(x=temp_high, y = precip)) +\ngeom_point() +\nscale_x_continuous(name=\"High Temp (C)\") +\nscale_y_continuous(name=\"Precipitation (mm)\")\nclassic\n\n\n\n\nAnother quick plot.\n\nelevation_plot1 <- ggplot(eco_data, aes(x=elevation_range, y = unique)) +\ngeom_point() +\nscale_x_continuous(name=\"Elevation Range (m)\") +\nscale_y_continuous(name=\"Number of Unique Species\")\nelevation_plot1\n\n\n\nggsave(\"~/DATA/images/post_thumbnails/reserve_elevation_species.png\")"
  },
  {
    "objectID": "posts/2022-02-15-ski-touring-data/index.html",
    "href": "posts/2022-02-15-ski-touring-data/index.html",
    "title": "Ski Touring Movement Data",
    "section": "",
    "text": "When thinking about how to combine datasets to ask more complex questions it is important to determine where the overlaps in the datasets might be. As an example, The Mount Shasta Avalanche Center keeps records of seasonal weather and avalanche forecast data that I discussed in a previous post. I just made a small movement dataset from some of the ski tours I have done in the Mount Shasta area. Here are just a few summary views of the dataset below. In the next series of posts we will overlap the avalanche forecast data, weather data, and the ski touring movement data based on date, time, elevations, and aspects.\n\nlibrary(tidyverse)\nski_data <- read.csv(\"~/DATA/data/SkiTouring.csv\")\n\nThe data set has a number of interesting variables including my movement as I skied, some speed data, some altitude data, and some biometric heart rate data. All of the tours were in the 2019-2020 or the 2020-2021 ski season on the lower slopes of Mount Shasta, Ca.\nTake a quick look.\n\nglimpse(ski_data)\n\nRows: 13,491\nColumns: 17\n$ timestamp      <chr> \"2020-01-18 18:33:31\", \"2020-01-18 18:33:58\", \"2020-01-…\n$ position_lat   <dbl> 41.35011, 41.35010, 41.35012, 41.35014, 41.35016, 41.35…\n$ position_long  <dbl> -122.2793, -122.2793, -122.2793, -122.2792, -122.2792, …\n$ altitude       <dbl> NA, 1504.2, 1504.8, 1504.8, 1505.0, 1505.2, 1505.6, 150…\n$ heart_rate     <int> NA, 55, 62, 62, 64, 64, 69, 66, 67, 76, 74, 73, 72, 70,…\n$ cadence        <int> NA, 64, 48, 52, 49, 46, 46, 43, 43, 0, 48, 72, 75, 75, …\n$ temperature    <int> NA, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,…\n$ distance       <int> NA, NA, NA, NA, 7, 9, NA, 15, NA, NA, NA, 24, 26, 29, 3…\n$ speed          <dbl> NA, NA, NA, NA, 0.5, 0.8, 1.1, 1.1, 0.7, 0.0, 0.0, 1.0,…\n$ vertical_speed <dbl> NA, 0.00, 0.02, 0.00, 0.00, 0.00, 0.00, 0.00, 0.04, 0.0…\n$ File_Path      <chr> \"Move_2020_01_18_10_33_29_Ski_touring.fit\", \"Move_2020_…\n$ activity       <chr> \"SkiTouring\", \"SkiTouring\", \"SkiTouring\", \"SkiTouring\",…\n$ HRzone         <chr> NA, \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"…\n$ datetime       <chr> \"2020-01-18 18:33:31\", \"2020-01-18 18:33:58\", \"2020-01-…\n$ year           <int> 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2…\n$ date           <chr> \"2020-01-18\", \"2020-01-18\", \"2020-01-18\", \"2020-01-18\",…\n$ seconds        <chr> \"18:33:31\", \"18:33:58\", \"18:34:42\", \"18:34:45\", \"18:34:…\n\nsummary(ski_data)\n\n  timestamp          position_lat   position_long       altitude   \n Length:13491       Min.   :41.35   Min.   :-122.3   Min.   :1504  \n Class :character   1st Qu.:41.36   1st Qu.:-122.2   1st Qu.:1827  \n Mode  :character   Median :41.36   Median :-122.2   Median :2052  \n                    Mean   :41.36   Mean   :-122.2   Mean   :2031  \n                    3rd Qu.:41.36   3rd Qu.:-122.2   3rd Qu.:2262  \n                    Max.   :41.37   Max.   :-122.2   Max.   :2532  \n                                                     NA's   :8908  \n   heart_rate        cadence        temperature       distance    \n Min.   : 42.00   Min.   :  0.00   Min.   :12.00   Min.   :   7   \n 1st Qu.: 55.00   1st Qu.: 37.00   1st Qu.:19.00   1st Qu.:1640   \n Median : 71.00   Median : 48.00   Median :20.00   Median :3144   \n Mean   : 76.91   Mean   : 49.95   Mean   :20.83   Mean   :3309   \n 3rd Qu.: 98.00   3rd Qu.: 69.00   3rd Qu.:22.00   3rd Qu.:4668   \n Max.   :148.00   Max.   :114.00   Max.   :31.00   Max.   :9317   \n NA's   :361      NA's   :8908     NA's   :8908    NA's   :10905  \n     speed      vertical_speed    File_Path           activity        \n Min.   :0.00   Min.   :-1.180   Length:13491       Length:13491      \n 1st Qu.:0.80   1st Qu.:-0.020   Class :character   Class :character  \n Median :1.00   Median : 0.040   Mode  :character   Mode  :character  \n Mean   :1.48   Mean   :-0.021                                        \n 3rd Qu.:1.40   3rd Qu.: 0.100                                        \n Max.   :8.40   Max.   : 0.240                                        \n NA's   :8912   NA's   :8908                                          \n    HRzone            datetime              year          date          \n Length:13491       Length:13491       Min.   :2020   Length:13491      \n Class :character   Class :character   1st Qu.:2020   Class :character  \n Mode  :character   Mode  :character   Median :2020   Mode  :character  \n                                       Mean   :2020                     \n                                       3rd Qu.:2020                     \n                                       Max.   :2021                     \n                                                                        \n   seconds         \n Length:13491      \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\nMake a quick plot using the latitude and longitude coordinates and color by the date of the tour.\n\nski_plot1 <- ggplot(ski_data, \n                    aes(x = position_long, y = position_lat, color = date)) +\n                    coord_quickmap() + geom_point() +\n                    ylab(\"Latitude\") + xlab(\"Longitude\")\n  \nski_plot1"
  },
  {
    "objectID": "posts/2022-03-01-trout-data/index.html",
    "href": "posts/2022-03-01-trout-data/index.html",
    "title": "Trout and Food Species",
    "section": "",
    "text": "In this post we will look at some spatial data of Rainbow Trout (Oncorhynchus mykiss) and one of their food sources Blue Winged Olives (Baetis tricaudatus). We will take a look using publicly available observation data from the GBIF database. See previous posts here and here for other examples of species occurrence data.\nLoad the necessary R libraries.\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(maps)\nlibrary(leaflet)\n\nPull in the species observation data from GBIF.\n\nrb_trout <- occ_data(scientificName = \"Oncorhynchus mykiss\", hasCoordinate = TRUE, limit = 1000)\nbw_olive <- occ_data(scientificName = \"Baetis tricaudatus\", hasCoordinate = TRUE, limit = 1000)\n\nSubset these datasets for only a few pieces of data.\n\nrb_trout_coords <- rb_trout$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n\"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"references\")]\nbw_olive_coords <- bw_olive$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n\"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"references\")]\n\nPlot on a map of California. Rainbow trout in red and Blue winged Olives in blue.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(rb_trout_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\npoints(bw_olive_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\nSubset our search to only Northern California and combine the query for both species.\n\nnorcal_geometry <- paste('POLYGON((-124.4323 42.0021, -120 42.0021, -120 40.194, -124.4323 40.194, -124.4323 42.0021))')\nspecies <- c(\"Oncorhynchus mykiss\", \"Baetis tricaudatus\")\n\nspecies_data <- occ_data(scientificName = species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = norcal_geometry)\nsummary(species_data)\n\n                    Length Class  Mode\nOncorhynchus mykiss 2      -none- list\nBaetis tricaudatus  2      -none- list\n\n\nName the individual lists within the species_data object and pull out the relevant data for plotting.\n\nspecies_data_coords_list <- vector(\"list\", length(species_data))\nnames(species_data_coords_list) <- species\nnames(species_data_coords_list)\n\n[1] \"Oncorhynchus mykiss\" \"Baetis tricaudatus\" \n\nfor (x in species) {\n  coords <- species_data[[x]]$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n  species_data_coords_list[[x]] <- data.frame(species = x, coords)\n}\n\nCombine into single long dataframe for easier plotting.\n\ntrout_df <- rbindlist(species_data_coords_list, fill = T)\n\nThere are only a few observations of the Blue Winged Olives that overlap the Rainbow Trout in this range.\n\nspecies_plot1 <- ggplot(trout_df, aes(x=decimalLongitude, y = decimalLatitude,\n                        color = species)) +\n                        geom_point() +  \n                        scale_color_manual(values = \n                           c(\"Oncorhynchus mykiss\" = \"red\",\n                           \"Baetis tricaudatus\" = \"blue\")) + \n                        labs(color = \"Species\", \n                             title = \"Northern California Rainbow Trout \n                             and Blue Winged Olive\") +\n                        ylab(\"Latitude\") + xlab(\"Longitude\")\nspecies_plot1\n\n\n\n\nPlot the data on an actual map. The overlapping data points for Blue Winged Olives and Rainbow Trout are on the Trinity River, the McCloud River, and Rush Creek in the North Eastern part of the state in Modoc county.\n\npalette <- colorFactor(c(\"blue\", \"red\"), domain = c(\"Oncorhynchus mykiss\", \"Baetis tricaudatus\"))\n\nleaflet(trout_df) %>% addTiles() %>%\n  addCircleMarkers(~decimalLongitude, ~decimalLatitude,\n    color = ~palette(species),\n    stroke = FALSE, fillOpacity = 0.5\n  )\n\n\n\n\n\nNext up for this dataset is taking a look at dates of observations and overlapping those with weather and stream flow data from those river systems."
  },
  {
    "objectID": "posts/2022-03-15-pacificyewtrailrun/index.html",
    "href": "posts/2022-03-15-pacificyewtrailrun/index.html",
    "title": "Miracle Mile Species 1",
    "section": "",
    "text": "I have started checking off all the conifer species that occur in the Miracle Mile. I recently found some Pacific Yew (Taxus brevifolia) on a trail run with a friend. This was also my first post to iNaturalist. A good time to take a look at the data.\nLoad the libraries.\n\nlibrary(rinat)\nlibrary(tidyverse)\n\nLoad the data.\n\nTrailRun1 <- read.csv(\"~/DATA/data/TrailRun_PacYew.csv\")\nglimpse(TrailRun1)\n\nRows: 7,077\nColumns: 10\n$ X              <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ timestamp      <chr> \"2022-02-27 16:41:35\", \"2022-02-27 16:41:43\", \"2022-02-…\n$ position_lat   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ position_long  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ distance       <int> 0, 21, 24, 28, 32, 36, 41, 41, 51, 55, 59, 64, 68, 72, …\n$ altitude       <dbl> NA, 791.2, 790.8, 790.6, 790.4, 790.4, 790.0, 789.6, 78…\n$ cadence        <int> NA, 87, 86, 85, 84, 84, 85, 87, 87, 87, 87, 85, 85, 84,…\n$ speed          <dbl> NA, 2.58, 2.58, 2.92, 2.92, 3.34, 3.34, 3.78, 3.78, 4.0…\n$ temperature    <int> NA, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 24, 24, 24,…\n$ vertical_speed <dbl> NA, -0.02, -0.04, -0.06, -0.06, -0.08, -0.10, -0.10, -0…\n\n\nMake a Northern California polygon for iNaturalist, pull in the data and take look.\n\nbounds <- c(40.194, -124.4323, 42.0021, -120)\nspecies <- c(\"taxus brevifolia\")\npacyew_iNat <- get_inat_obs(query = species, bounds = bounds, maxresults = 1000, quality = \"research\")\ndim(pacyew_iNat)\n\n[1] 223  37\n\n\nI had one of the newest observations of this species in the data set. My username is rjcmarkelz.\n\nglimpse(pacyew_iNat)\n\nRows: 223\nColumns: 37\n$ scientific_name                  <chr> \"Taxus brevifolia\", \"Taxus brevifolia…\n$ datetime                         <chr> \"2023-02-18 14:18:08 -0800\", \"2016-06…\n$ description                      <chr> \"\", \"\", \"\", \"\", \"\", \"In small riparia…\n$ place_guess                      <chr> \"Shasta-Trinity National Forest, Trin…\n$ latitude                         <dbl> 40.88129, 41.24290, 40.59970, 40.6035…\n$ longitude                        <dbl> -122.9248, -122.0182, -123.6968, -123…\n$ tag_list                         <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ common_name                      <chr> \"Pacific yew\", \"Pacific yew\", \"Pacifi…\n$ url                              <chr> \"https://www.inaturalist.org/observat…\n$ image_url                        <chr> \"https://inaturalist-open-data.s3.ama…\n$ user_login                       <chr> \"cloudya\", \"outnabout---\", \"anneliese…\n$ id                               <int> 149104203, 147115748, 144714197, 1447…\n$ species_guess                    <chr> \"Pacific yew\", \"Pacific yew\", \"Pacifi…\n$ iconic_taxon_name                <chr> \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ taxon_id                         <int> 55209, 55209, 55209, 55209, 55209, 55…\n$ num_identification_agreements    <int> 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1…\n$ num_identification_disagreements <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ observed_on_string               <chr> \"2023-02-18 14:18:08-08:00\", \"Sat Jun…\n$ observed_on                      <chr> \"2023-02-18\", \"2016-06-04\", \"2022-05-…\n$ time_observed_at                 <chr> \"2023-02-18 22:18:08 UTC\", \"2016-06-0…\n$ time_zone                        <chr> \"Pacific Time (US & Canada)\", \"Pacifi…\n$ positional_accuracy              <int> 24, 5, 5, 28, 353, NA, 968, 10, 150, …\n$ public_positional_accuracy       <int> 24, 5, 5, 28, 353, NA, 968, 10, 150, …\n$ geoprivacy                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ taxon_geoprivacy                 <chr> \"open\", \"open\", \"open\", \"open\", \"open…\n$ coordinates_obscured             <chr> \"false\", \"false\", \"false\", \"false\", \"…\n$ positioning_method               <chr> \"\", \"\", \"\", \"\", \"\", \"gps\", \"\", \"\", \"\"…\n$ positioning_device               <chr> \"\", \"\", \"\", \"\", \"\", \"gps\", \"\", \"\", \"\"…\n$ user_id                          <int> 379379, 1106562, 1441336, 1441336, 14…\n$ user_name                        <chr> \"\", \"Mark Pollock\", \"Anneliese Wilson…\n$ created_at                       <chr> \"2023-02-19 04:22:43 UTC\", \"2023-01-2…\n$ updated_at                       <chr> \"2023-02-19 17:59:58 UTC\", \"2023-01-2…\n$ quality_grade                    <chr> \"research\", \"research\", \"research\", \"…\n$ license                          <chr> \"CC-BY-NC\", \"\", \"CC-BY-NC\", \"CC-BY-NC…\n$ sound_url                        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ oauth_application_id             <int> 3, 3, 3, 3, NA, 2, NA, NA, 3, 3, 3, N…\n$ captive_cultivated               <chr> \"false\", \"false\", \"false\", \"false\", \"…\n\nhead(pacyew_iNat$user_login, 10)\n\n [1] \"cloudya\"         \"outnabout---\"    \"anneliesewilson\" \"anneliesewilson\"\n [5] \"anneliesewilson\" \"luca_hickey\"     \"marcus_t\"        \"marcus_t\"       \n [9] \"chrisophylla\"    \"rsarhsu\"        \n\n\nHere is my image that I uploaded. I had a species confirmation from the community within 12 hours.\n\nQuick map to show all the observations.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(TrailRun1[ , c(\"position_long\", \"position_lat\")], pch = \".\", col = \"red\", cex = 3)\npoints(pacyew_iNat[ , c(\"longitude\", \"latitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\nMake a quick plot to show the overlay of the run data and the coordinates of the image I took shown as a red dot.\n\ntr_plot1 <- ggplot(TrailRun1, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point() +\n                    ylab(\"Latitude\") + xlab(\"Longitude\") + \n                 geom_point(aes(x=-122.1683, y=41.120),color=\"red\", size = 5)\ntr_plot1"
  },
  {
    "objectID": "posts/2022-04-01-foxtailpinetrailrun/index.html",
    "href": "posts/2022-04-01-foxtailpinetrailrun/index.html",
    "title": "Miracle Mile Species 2 and 3",
    "section": "",
    "text": "Foxtail Pine\n\n\n\nWestern White Pine\nContinuing to check off the conifer species that occur in the Miracle Mile so I can make a visit and try to ID all of them. Last summer I found some Foxtail Pine (Pinus balfouriana) and (Pinus monticola) near Mount Eddy in the Klammath Range (among others).\nLoad the libraries.\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(maps)\n\nLoad the data.\n\nski_data <- read.csv(\"~/DATA/data/SkiTouring.csv\")\nTrailRun1 <- read.csv(\"~/DATA/data/TrailRun_FoxtailPine.csv\")\n\nMake a quick plot using the latitude and longitude coordinates and color by the date of the tour.\n\nrun1 <- ggplot(TrailRun1, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point()\nrun1\n\n\n\n\nMake a general area polygon for GBIF and query the database to see if there are public observations of our two species of interest in the general region I ran in.\n\nnorcal_geometry <- paste('POLYGON((-122.6 41.35, -122.35 41.35, -122.35 41.25, -122.4 41.25, -122.6 41.25, -122.6 41.35))')\n\nmm_species <- c(\"pinus balfouriana\", \"pinus monticola\")\n\nfoxtail_data <- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = norcal_geometry)\n\nfoxtail_coords <- foxtail_data$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nmm_all <- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = norcal_geometry)\nmm_species_coords_list <- vector(\"list\", length(mm_species))\nnames(mm_species_coords_list) <- mm_species\nhead(mm_species_coords_list)\n\n$`pinus balfouriana`\nNULL\n\n$`pinus monticola`\nNULL\n\n\nLoop through and make a dataframe from the lists.\n\nfor (x in mm_species) {\n  coords <- mm_all[[x]]$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n  mm_species_coords_list[[x]] <- data.frame(species = x, coords)\n}\n\ntree_df <- rbindlist(mm_species_coords_list, fill = T)\n\nJust take a quick look at the raw observations plotted by latitude and longitude. Plot the species on the California map to see the limited polygon sampled.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(tree_df[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\nPlot all of the species using ggplot for the zoomed in area.\n\nrun_plot1  <- ggplot(tree_df, aes(x=decimalLongitude, y = decimalLatitude, color = species)) +\n                             geom_point() + labs(color = \"Species\", title = \"MM Zone\")\nrun_plot1\n\n\n\n\nCombine trail running and species occurrence observations.\n\nrun_plot2 <- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = position_long, y = position_lat), color = 'black') +\n          geom_point(data=tree_df, aes(x = decimalLongitude, y = decimalLatitude, color = factor(species))) +\n          xlab(\"Longitude\") + ylab(\"Latitude\") + labs(color='Species')\nrun_plot2"
  },
  {
    "objectID": "posts/2022-04-15-sugar-pine-trail-run/index.html",
    "href": "posts/2022-04-15-sugar-pine-trail-run/index.html",
    "title": "Sugar Pine (Pinus lambertiana)",
    "section": "",
    "text": "Another species found! I am attempting to ID all the conifer species that occur in the Miracle Mile while out on runs so I can make a visit to the Miracle Mile and ID all of them in one go.\n\n\n\nThese sugar pine cones are huge! I have a few in my pinecone collection that are greater than 35 cm! Sugar pines (Pinus lambertiana) are fairly common species and I see them on trail runs often. For this post I first pulled the observations from GBIF, plotted them, and then looked where I had recently ran that would overlap with the species observation data. In this case, it was on a section of the Pacific Crest Trail (PCT) that I did an out and back run on.\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(maps)\n\nSubset our search to only Northern California\n\nmm_geometry <- paste('POLYGON((-124.4323 42.0021, -121.5045 42.0021, -121.5045 40.194, -124.4323 40.194, -124.4323 42.0021))')\n\nPull in the publicly available data and make a few quick plots.\n\npinus_lambertiana_NC <- occ_data(scientificName = \"Pinus lambertiana\", hasCoordinate = TRUE, limit = 10000,\n                     geometry = mm_geometry )\nhead(pinus_lambertiana_NC)\n\n$meta\n$meta$offset\n[1] 300\n\n$meta$limit\n[1] 2\n\n$meta$endOfRecords\n[1] TRUE\n\n$meta$count\n[1] 302\n\n\n$data\n# A tibble: 302 × 120\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n   <chr>  <chr>     <dbl>   <dbl> <chr>  <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 40463… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 2 40463… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 3 34993… Pinus …    41.9   -124. cdc    50c950… 28eb1a… 997448… US      DWC_AR…\n 4 37057… Pinus …    41.5   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 5 37053… Pinus …    41.2   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 6 37472… Pinus …    40.9   -124. cdc    50c950… 28eb1a… 997448… US      DWC_AR…\n 7 37598… Pinus …    41.8   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 8 39613… Pinus …    40.4   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 9 37642… Pinus …    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n10 37603… Pinus …    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n# … with 292 more rows, 110 more variables: lastCrawled <chr>,\n#   lastParsed <chr>, crawlId <int>, hostingOrganizationKey <chr>,\n#   basisOfRecord <chr>, occurrenceStatus <chr>, taxonKey <int>,\n#   kingdomKey <int>, phylumKey <int>, classKey <int>, orderKey <int>,\n#   familyKey <int>, genusKey <int>, speciesKey <int>, acceptedTaxonKey <int>,\n#   acceptedScientificName <chr>, kingdom <chr>, phylum <chr>, order <chr>,\n#   family <chr>, genus <chr>, species <chr>, genericName <chr>, …\n\npinus_lambertiana_coords <- pinus_lambertiana_NC$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n\nmaps::map(database = \"state\", region = \"california\")\npoints(pinus_lambertiana_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\nPull in my run data.\n\nTrailRun1  <- read.csv(\"~/DATA/data/TrailRun_SugarPine.csv\")\n\nMake a quick plot.\n\nTrailRun_plot <- ggplot(TrailRun1, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point() +\n                    xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot\n\n\n\n\nSubset the larger California dataset to only include a zoomed in portion where I ran based on the maximum and minimum coordinates from the run plot above.\n\npinus_lamb_coords_sub <- subset(pinus_lambertiana_coords, decimalLatitude > 41.1525 & decimalLatitude < 41.1650 & decimalLongitude > -122.295 & decimalLongitude < -122.265 )\n\nOverlay the plots!\n\nTrailRun_plot2 <- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = position_long, y = position_lat), color = 'black') +\n          geom_point(data=pinus_lamb_coords_sub, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot2"
  },
  {
    "objectID": "posts/2022-05-01-jefferypinetrailrun/index.html",
    "href": "posts/2022-05-01-jefferypinetrailrun/index.html",
    "title": "Miracle Mile Species 5 and 6",
    "section": "",
    "text": "I am continueing on my quest of checking off all the conifer species that occur in the Miracle Mile. I recently found some Jeffrey’s Pine (Pinus jeffreyi) on a trail run while on vacation in the San Bernadino mountains East of Los Angeles. This is in an area where there is also Ponderosa Pine (Pinus Ponderosa). Sometimes the species are confused with one another and can even form hybrids making identification difficult. In general the Ponderosa’s are larger trees, but have smaller cones with the pointy end (umbos) of the individual seeds facing outward. The Jeffery’s pine has larger cones with the umbos facing down or inward making them easier to handle without poking yourself. The following are some quick data queries, manipulation and plotting.\nLoad the libraries.\n\nlibrary(rinat)\nlibrary(tidyverse)\n\nLoad the trail run data and take a look at the data frame.\n\nTrailRun1 <- read.csv(\"~/DATA/data/TrailRun_JefferyPine.csv\")\nglimpse(TrailRun1)\n\nRows: 2,194\nColumns: 9\n$ timestamp      <chr> \"2022-04-19 18:45:05\", \"2022-04-19 18:45:13\", \"2022-04-…\n$ position_lat   <dbl> NA, NA, NA, NA, 34.23880, 34.23873, 34.23869, 34.23868,…\n$ position_long  <dbl> NA, NA, NA, NA, -116.8687, -116.8686, -116.8686, -116.8…\n$ distance       <int> 0, 67, 72, 74, 76, 76, 80, 84, 87, 89, 91, 94, 98, 100,…\n$ altitude       <dbl> NA, 2112.4, 2112.6, 2112.8, 2113.0, 2113.2, 2114.0, 211…\n$ cadence        <int> NA, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83,…\n$ speed          <dbl> NA, 1.74, 1.74, 2.04, 2.04, 2.24, 2.24, 2.44, 2.44, 2.5…\n$ temperature    <int> NA, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,…\n$ vertical_speed <dbl> NA, 0.00, 0.00, -0.02, -0.02, -0.02, -0.02, -0.04, -0.0…\n\n\nMake a quick plot for the run.\n\nTrailRun_plot <- ggplot(TrailRun1, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point() +\n                    xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot\n\n\n\n\nUse the run data plot to bound the query to iNaturalist.\n\nbounds <- c(34.2, -116.9, 34.25, -116.85)\npineJeff_iNat <- get_inat_obs(query = \"Pinus jeffreyi\", bounds = bounds, maxresults = 1000)\npinePond_iNat <- get_inat_obs(query = \"Pinus ponderosa\", bounds = bounds, maxresults = 1000)\n\nTake a quick look at the iNaturalist data frames.\n\nglimpse(pineJeff_iNat)\n\nRows: 22\nColumns: 37\n$ scientific_name                  <chr> \"Pinus jeffreyi\", \"Pinus jeffreyi\", \"…\n$ datetime                         <chr> \"2023-02-05 13:24:29 -0800\", \"2023-01…\n$ description                      <chr> \"\", \"\", \"\", \"Found on the ground. Lar…\n$ place_guess                      <chr> \"San Bernardino National Forest, Big …\n$ latitude                         <dbl> 34.22255, 34.21582, 34.23545, 34.2377…\n$ longitude                        <dbl> -116.8954, -116.8600, -116.8962, -116…\n$ tag_list                         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ common_name                      <chr> \"Jeffrey pine\", \"Jeffrey pine\", \"Jeff…\n$ url                              <chr> \"https://www.inaturalist.org/observat…\n$ image_url                        <chr> \"https://inaturalist-open-data.s3.ama…\n$ user_login                       <chr> \"ekoberle\", \"happyg\", \"orionsmcc\", \"m…\n$ id                               <int> 148162933, 145894058, 143681542, 1284…\n$ species_guess                    <chr> \"Jeffrey pine\", \"\", \"Jeffrey pine\", \"…\n$ iconic_taxon_name                <chr> \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ taxon_id                         <int> 48463, 48463, 48463, 48463, 48463, 48…\n$ num_identification_agreements    <int> 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0…\n$ num_identification_disagreements <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ observed_on_string               <chr> \"2023-02-05 13:24:29-08:00\", \"2023-01…\n$ observed_on                      <chr> \"2023-02-05\", \"2023-01-04\", \"2022-12-…\n$ time_observed_at                 <chr> \"2023-02-05 21:24:29 UTC\", \"2023-01-0…\n$ time_zone                        <chr> \"Pacific Time (US & Canada)\", \"Pacifi…\n$ positional_accuracy              <int> 3, 13, 357, 347, 217, 4, 4, 9, 8, 31,…\n$ public_positional_accuracy       <int> 3, 13, 357, 347, 217, 4, 4, 9, 8, 31,…\n$ geoprivacy                       <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ taxon_geoprivacy                 <chr> \"open\", \"open\", \"open\", \"open\", \"open…\n$ coordinates_obscured             <chr> \"false\", \"false\", \"false\", \"false\", \"…\n$ positioning_method               <chr> \"\", \"\", \"\", \"\", \"gps\", \"\", \"\", \"\", \"\"…\n$ positioning_device               <chr> \"\", \"\", \"\", \"\", \"gps\", \"\", \"\", \"\", \"\"…\n$ user_id                          <int> 172086, 4930790, 144477, 5660178, 426…\n$ user_name                        <chr> \"Eric Koberle\", \"Ethan Gilmore\", \"\", …\n$ created_at                       <chr> \"2023-02-06 05:56:44 UTC\", \"2023-01-0…\n$ updated_at                       <chr> \"2023-02-10 02:50:33 UTC\", \"2023-01-0…\n$ quality_grade                    <chr> \"research\", \"needs_id\", \"needs_id\", \"…\n$ license                          <chr> \"CC-BY-NC\", \"CC-BY-NC\", \"CC-BY-NC\", \"…\n$ sound_url                        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ oauth_application_id             <int> 3, 3, 3, 333, 2, 3, 3, 2, 2, 3, 3, 3,…\n$ captive_cultivated               <chr> \"false\", \"false\", \"false\", \"false\", \"…\n\nglimpse(pinePond_iNat)\n\nRows: 8\nColumns: 37\n$ scientific_name                  <chr> \"Pinus ponderosa\", \"Pinus ponderosa\",…\n$ datetime                         <chr> \"2022-08-09 18:00:33 -0700\", \"2020-07…\n$ description                      <lgl> NA, NA, NA, NA, NA, NA, NA, NA\n$ place_guess                      <chr> \"San Bernardino National Forest, Big …\n$ latitude                         <dbl> 34.22839, 34.23914, 34.21212, 34.2251…\n$ longitude                        <dbl> -116.8549, -116.8876, -116.8729, -116…\n$ tag_list                         <lgl> NA, NA, NA, NA, NA, NA, NA, NA\n$ common_name                      <chr> \"Ponderosa Pine\", \"Ponderosa Pine\", \"…\n$ url                              <chr> \"https://www.inaturalist.org/observat…\n$ image_url                        <chr> \"https://inaturalist-open-data.s3.ama…\n$ user_login                       <chr> \"jcarrk\", \"jiggajantastic\", \"josue79\"…\n$ id                               <int> 130186380, 52182504, 34645641, 332225…\n$ species_guess                    <chr> \"\", \"ponderosa pine\", \"ponderosa pine…\n$ iconic_taxon_name                <chr> \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ taxon_id                         <int> 48461, 48461, 48461, 48461, 48461, 48…\n$ num_identification_agreements    <int> 0, 1, 2, 0, 0, 0, 0, 0\n$ num_identification_disagreements <int> 0, 0, 0, 0, 0, 0, 0, 0\n$ observed_on_string               <chr> \"2022-08-09 18:00:33-07:00\", \"Mon Jul…\n$ observed_on                      <chr> \"2022-08-09\", \"2020-07-06\", \"2019-10-…\n$ time_observed_at                 <chr> \"2022-08-10 01:00:33 UTC\", \"2020-07-0…\n$ time_zone                        <chr> \"Pacific Time (US & Canada)\", \"Pacifi…\n$ positional_accuracy              <int> 6, 53, 5, NA, 3, 5, 5, 10\n$ public_positional_accuracy       <int> 6, 53, 5, NA, 3, 5, 5, 10\n$ geoprivacy                       <lgl> NA, NA, NA, NA, NA, NA, NA, NA\n$ taxon_geoprivacy                 <chr> \"open\", \"open\", \"open\", \"open\", \"open…\n$ coordinates_obscured             <chr> \"false\", \"false\", \"false\", \"false\", \"…\n$ positioning_method               <chr> \"\", \"\", \"\", \"gps\", \"\", \"\", \"\", \"\"\n$ positioning_device               <chr> \"\", \"\", \"\", \"gps\", \"\", \"\", \"\", \"\"\n$ user_id                          <int> 5960713, 3241047, 2173678, 105431, 10…\n$ user_name                        <chr> \"\", \"\", \"Josue Sandoval\", \"Shaun M. M…\n$ created_at                       <chr> \"2022-08-10 01:00:43 UTC\", \"2020-07-0…\n$ updated_at                       <chr> \"2022-08-10 01:00:53 UTC\", \"2021-05-3…\n$ quality_grade                    <chr> \"needs_id\", \"research\", \"research\", \"…\n$ license                          <chr> \"CC-BY-NC\", \"CC-BY-NC\", \"\", \"CC-BY-NC…\n$ sound_url                        <lgl> NA, NA, NA, NA, NA, NA, NA, NA\n$ oauth_application_id             <int> 3, 3, 3, 2, 2, 3, 3, 3\n$ captive_cultivated               <chr> \"false\", \"false\", \"false\", \"false\", \"…\n\n\nPlot all the data on a California map to orient geographically where it is and to check for overlap.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(pineJeff_iNat[ , c(\"longitude\", \"latitude\")], pch = \".\", col = \"blue\", cex = 3)\npoints(pinePond_iNat[ , c(\"longitude\", \"latitude\")], pch = \".\", col = \"red\", cex = 3)\npoints(TrailRun1[ , c(\"position_long\", \"position_lat\")], pch = \".\", col = \"black\", cex = 3)\n\n\n\n\nOverlay the plots and add research grade symbols (triangle) and needs_id (circle). By default ggplot will have zoomed in on the data given the bounds. We can see that both species occur in the same general area, but there are not any direct overlaps in the research grade observations and my trial running route.\n\nrun_plot2 <- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = position_long, y = position_lat), color = 'black') +\n          geom_point(data=pinePond_iNat, aes(x = longitude, y = latitude, shape = quality_grade), color = 'red', size = 5) +\n          geom_point(data=pineJeff_iNat, aes(x = longitude, y = latitude, shape = quality_grade), color = 'blue', size = 5) +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nrun_plot2\n\n\n\n\nWe have many more Ponderosa pines near Mount Shasta including one I found on another run. For this iNaturalist observation I also took a photo of the cone. If you take a look at the Ponderosa pine observations you can find mine via my username (rjcmarkelz).\n\nbounds2 <- c(40.194, -124.4323, 42.0021, -120) # Northern California Bounds\nPondPineNor_iNat <- get_inat_obs(query = \"Pinus ponderosa\", bounds = bounds2, maxresults = 100)\nPondPineNor_iNat$user_login # Look for rjcmarkelz\n\n  [1] \"carexobnupta\"     \"carexobnupta\"     \"jim22lawrence\"   \n  [4] \"dgrimmphd\"        \"dgrimmphd\"        \"john_virzi_hort\" \n  [7] \"danielkennedy\"    \"ekgrijalva\"       \"danielkennedy\"   \n [10] \"brendanswift\"     \"greenfieldlouis\"  \"luca_hickey\"     \n [13] \"hkibak\"           \"gentilcore\"       \"gentilcore\"      \n [16] \"tallianna\"        \"chris_earle\"      \"liuelliot2187\"   \n [19] \"brennanpopovic\"   \"pikabombadier\"    \"frankdaluddung\"  \n [22] \"dgrimmphd\"        \"dgrimmphd\"        \"dgrimmphd\"       \n [25] \"drew_meyer\"       \"gcwarbler\"        \"k-bot\"           \n [28] \"luca_hickey\"      \"luca_hickey\"      \"sirhikesalot\"    \n [31] \"drew_meyer\"       \"justin426\"        \"luca_hickey\"     \n [34] \"luca_hickey\"      \"luca_hickey\"      \"luca_hickey\"     \n [37] \"samuel_monteon\"   \"lydia_365\"        \"drew_meyer\"      \n [40] \"hchrish200\"       \"shaunmichael\"     \"shaunmichael\"    \n [43] \"shaunmichael\"     \"megan1545\"        \"tyannasb\"        \n [46] \"mrsjburgin\"       \"pinus_taeda\"      \"samuel_monteon\"  \n [49] \"pronghornranch67\" \"drew_meyer\"       \"drew_meyer\"      \n [52] \"chilipossum\"      \"sunnyjo\"          \"chilipossum\"     \n [55] \"chilipossum\"      \"gentilcore\"       \"tadamcochran\"    \n [58] \"gentilcore\"       \"mirri360\"         \"fish_narc\"       \n [61] \"maggiebrownie3\"   \"nelruzam\"         \"geodani\"         \n [64] \"linuslancaster\"   \"justinaceae\"      \"aestas\"          \n [67] \"aestas\"           \"aestas\"           \"pgeorgakakos\"    \n [70] \"susanfawcett\"     \"danspada\"         \"kathawk\"         \n [73] \"lorri-gong\"       \"panadora\"         \"gilbertj\"        \n [76] \"nickstein\"        \"gnomewardbound\"   \"gentilcore\"      \n [79] \"wildgifts\"        \"gentilcore\"       \"gentilcore\"      \n [82] \"gentilcore\"       \"jackjohnsonn\"     \"avocat\"          \n [85] \"brak\"             \"harry_walters\"    \"elena936\"        \n [88] \"drew_meyer\"       \"drew_meyer\"       \"jkell12\"         \n [91] \"drew_meyer\"       \"valsa\"            \"luca_hickey\"     \n [94] \"luca_hickey\"      \"luca_hickey\"      \"luca_hickey\"     \n [97] \"luca_hickey\"      \"luca_hickey\"      \"luca_hickey\"     \n[100] \"luca_hickey\"     \n\n\nFilter and select the image_url so we can compare the size and physical attributes of the cones.\n\nPondPineNor_iNat %>% filter(user_login == \"rjcmarkelz\") %>% select(image_url)\n\n[1] image_url\n<0 rows> (or 0-length row.names)\n\npineJeff_iNat %>% filter(user_login == \"rjcmarkelz\") %>% select(image_url)\n\n[1] image_url\n<0 rows> (or 0-length row.names)\n\n\nJeffery’s Pine with the larger (hand for scale) cone with the umbos pointed in: \nPonderosa Pine with the smaller (hand for scale) cone with the umbos pointed out:"
  },
  {
    "objectID": "posts/2022-05-15-bayareainsects/index.html",
    "href": "posts/2022-05-15-bayareainsects/index.html",
    "title": "Bay Area Insects",
    "section": "",
    "text": "I am working on a project using data collected at some of the UC Reserves. I needed to see what observations of insects were available in GBIF.\nI found this drawing tool for bounding boxes. Make sure to export it as OGC WKT and then you can create a POLYGON to use as your query area.\n\nreserve_geometry <- paste('POLYGON((-121.383275382 35.7567710044, -121.9875234289 36.3607073262, -122.525853507 37.2841110386, -123.1520742101 38.0753438834, -123.7123769445 38.8153202525, -123.8332265539 39.0972469563, -123.4596913976 39.2930774901, -122.0644277258 39.2250244313, -121.7568105383 38.0320888877, -121.4052480383 37.2578829342, -121.119603507 36.7402099684, -120.9987538976 36.1303379589, -121.383275382 35.7567710044))')\n\nLoad the libraries.\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(maps)\n\nQuery the greater Bay Area for insects using the classKey for Insecta using the above geometry. Make a new dataframe with only the data from the query for plotting and data manipulation.\n\ninsect <- occ_data(classKey = 216, hasCoordinate = TRUE, limit = 1000, geometry = reserve_geometry)\ninsect_coords <- insect$data\nhead(insect_coords)\n\n# A tibble: 6 × 78\n  key     scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n  <chr>   <chr>     <dbl>   <dbl> <chr>  <chr>   <chr>   <chr>   <chr>   <chr>  \n1 401151… Dishol…    37.5   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n2 401150… Dishol…    37.5   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n3 401170… Forfic…    37.5   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n4 401164… Danaus…    37.5   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n5 401182… Aphis …    37.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n6 401189… Vaness…    37.0   -122. cdc    50c950… 28eb1a… 997448… US      DWC_AR…\n# … with 68 more variables: lastCrawled <chr>, lastParsed <chr>, crawlId <int>,\n#   hostingOrganizationKey <chr>, basisOfRecord <chr>, occurrenceStatus <chr>,\n#   taxonKey <int>, kingdomKey <int>, phylumKey <int>, classKey <int>,\n#   orderKey <int>, familyKey <int>, genusKey <int>, speciesKey <int>,\n#   acceptedTaxonKey <int>, acceptedScientificName <chr>, kingdom <chr>,\n#   phylum <chr>, order <chr>, family <chr>, genus <chr>, species <chr>,\n#   genericName <chr>, specificEpithet <chr>, taxonRank <chr>, …\n\n\nVisualize the data for the state of California.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(insect_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\nRandomly subset the coordinates dataframe and plot species by color. If you have a large screen, you can make a larger plotting window with many more species than 25.\n\nset.seed(25344)\ninsect_coords_25 <- sample_n(insect_coords, 25)\nspecies_plot1  <- ggplot(insect_coords_25, aes(x=decimalLongitude, y = decimalLatitude, color =acceptedScientificName)) +\n       geom_point() + labs(x = \"Longitude\", y = \"Latitude\", color = \"Species\", title = \"Bay Area Insect Distributions\")\nspecies_plot1\n\n\n\nggsave(\"~/DATA/images/bay_area_insects.png\")"
  },
  {
    "objectID": "posts/2022-06-01-edward-stuhl-wildflowers/index.html",
    "href": "posts/2022-06-01-edward-stuhl-wildflowers/index.html",
    "title": "Edward Stuhl Wildflowers",
    "section": "",
    "text": "I have been working on identifying and painting various local wildflowers from the book Mount Shasta Wild Flowers A Field Guide featuring the water color paintings of Edward Stuhl. Stuhl was an artist and mountaineer that gradually painted 189 plants over a 50 year career exploring the greater Mount Shasta area. All of his paintings are available to view online at CSU Chico here. I was interested in what sort of publicly available observation data there was for some of the more rare species. I downloaded the original list here, and made a few quick formatting edits to get it ready to pull into R.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rgbif)\nlibrary(data.table)\n\nPull in the data, take a quick look, and make a character vector of the species names for the GBIF query.\n\nshasta_plants <- read_excel(\"~/DATA/data/mount.shasta.plant.list.edit.xlsx\")\n\nhead(shasta_plants)\n\n# A tibble: 6 × 5\n  ID           Family           Genus       species    `subspecies or variety`\n  <chr>        <chr>            <chr>       <chr>      <chr>                  \n1 Ferns_Allies Dennstaedtiaceae Pteridium   aquilinum  var. pubescens         \n2 Ferns_Allies Dryopteridaceae  Polystichum scopulinum <NA>                   \n3 Ferns_Allies Equisetaceae     Equisetum   arvense    <NA>                   \n4 Ferns_Allies Equisetaceae     Equisetum   hyemale    ssp. affine            \n5 Ferns_Allies Ophioglossaceae  Botrychium  pinnatum   <NA>                   \n6 Ferns_Allies Ophioglossaceae  Botrychium  pumicola   <NA>                   \n\ndim(shasta_plants)\n\n[1] 482   5\n\nshasta_plants$query <- as.character(paste(shasta_plants$Genus, shasta_plants$species))\nshasta_species <- shasta_plants$query\nhead(shasta_species)\n\n[1] \"Pteridium aquilinum\"    \"Polystichum scopulinum\" \"Equisetum arvense\"     \n[4] \"Equisetum hyemale\"      \"Botrychium pinnatum\"    \"Botrychium pumicola\"   \n\n\nMake a polygon to query from within and run a GBIF query iterating through the shasta_species character vector. The query takes a while for building this webpage, so I am going to just load the result instead to list the objects. If you want to run the query uncomment the following few lines.\n\nmt_shasta_geometry <- paste('POLYGON((-122.600528 41.551515, -122.001773 41.551515, -122.001773 41.252791, -122.600528 41.252791, -122.600528 41.551515))')\n\n# shasta_all <- occ_data(scientificName = shasta_species, hasCoordinate = TRUE, limit = 100,\n#                   geometry = mt_shasta_geometry)\n\nload(\"~/DATA/data/Stuhl_Shasta_species_GBIF.RData\")\nls()\n\n[1] \"mt_shasta_geometry\" \"shasta_all\"         \"shasta_plants\"     \n[4] \"shasta_species\"    \n\n\nIterate through the GBIF query list and pull out the latitude and longitude of each observation and bind them all together.\n\nshasta_species_coords_list <- vector(\"list\", length(shasta_species))\nnames(shasta_species_coords_list) <- shasta_species\n\nfor (x in shasta_species) {\n  coords <- shasta_all[[x]]$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\")]\n  shasta_species_coords_list[[x]] <- data.frame(cbind(species = x, coords))\n}\n\nspecies_coord_df <- rbindlist(shasta_species_coords_list, fill = T)\nhead(species_coord_df)\n\n               species decimalLongitude decimalLatitude occurrenceStatus\n1: Pteridium aquilinum        -122.3233        41.28727          PRESENT\n2: Pteridium aquilinum        -122.3304        41.31041          PRESENT\n3: Pteridium aquilinum        -122.0664        41.27251          PRESENT\n4: Pteridium aquilinum        -122.0780        41.28300          PRESENT\n5: Pteridium aquilinum        -122.3066        41.27987          PRESENT\n6: Pteridium aquilinum        -122.4471        41.44342          PRESENT\n\n\nMake a quick plot of the data removing the legend or it will overwhelm the plot with the large number of species.\n\nspecies_p1  <- ggplot(species_coord_df, aes(x=decimalLongitude, y = decimalLatitude, color = species)) +\n                geom_point() +\n                labs(x = \"Longitude\", y = \"Latitude\", title = \"Mount Shasta Plant Species Observations\") + theme(legend.position=\"none\")\nspecies_p1\n\n\n\nggsave(\"~/DATA/images/stuhl_species.png\")\n\nA lifetime of exploration just in my general area! I hope to share more paintings of the same species as I am out and about around Mount Shasta."
  },
  {
    "objectID": "posts/2022-06-15-cobralily/index.html",
    "href": "posts/2022-06-15-cobralily/index.html",
    "title": "California Pitcher Plant",
    "section": "",
    "text": "Spring is in full swing in the higher elevations around Mount Shasta and the surrounding ranges. I am always struck by the large patches of Cobra Lilies that grow along nutrient poor seeps in alpine meadows. I nearly always stop to take some photos and take in all the cool colors and shapes when out on training runs or hikes. I have made many observations of these over the past few years, but here is a quick post to pull out observations from GBIF.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(rgbif)\nlibrary(gpx)\n\nMake the large Northern California polygon to look for observations in GBIF.\n\nnorcal_geometry <- paste('POLYGON((-124.4323 42.0021, -121.5045 42.0021, -121.5045 40.194, -124.4323 40.194, -124.4323 42.0021))')\n\ncobra_lily <- occ_data(scientificName = \"darlingtonia californica\", hasCoordinate = TRUE, limit = 1000,\n                   geometry = norcal_geometry)\nhead(cobra_lily)\n\n$meta\n$meta$offset\n[1] 900\n\n$meta$limit\n[1] 100\n\n$meta$endOfRecords\n[1] FALSE\n\n$meta$count\n[1] 1319\n\n\n$data\n# A tibble: 1,000 × 126\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n   <chr>  <chr>     <dbl>   <dbl> <chr>  <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 40286… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 2 40347… Darlin…    40.7   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 3 40394… Darlin…    41.6   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 4 40629… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 5 40673… Darlin…    42.0   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 6 40672… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 7 40672… Darlin…    42.0   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 8 34996… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 9 34993… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n10 34996… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n# … with 990 more rows, 116 more variables: lastCrawled <chr>,\n#   lastParsed <chr>, crawlId <int>, hostingOrganizationKey <chr>,\n#   basisOfRecord <chr>, occurrenceStatus <chr>, taxonKey <int>,\n#   kingdomKey <int>, phylumKey <int>, classKey <int>, orderKey <int>,\n#   familyKey <int>, genusKey <int>, speciesKey <int>, acceptedTaxonKey <int>,\n#   acceptedScientificName <chr>, kingdom <chr>, phylum <chr>, order <chr>,\n#   family <chr>, genus <chr>, species <chr>, genericName <chr>, …\n\n\nQuick map of observations.\n\ncobra_lily_coords <- cobra_lily$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n\nmaps::map(database = \"state\", region = \"california\")\npoints(cobra_lily_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\nPull in my run data using the gpx R library and subset the route to make plotting easier.\n\nrun <-  read_gpx('~/DATA/data/cobra_lily_run.gpx')\nTrailRun1 <- as.data.frame(run$routes)\n\nMake a quick run plot.\n\nTrailRun_plot <- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black') +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot\n\n\n\n\nSubset the larger California dataset to only include a zoomed in portion where I ran based on the maximum and minimum coordinates from the run plot above.\n\ncobra_lily_coords_sub <- subset(cobra_lily_coords, decimalLatitude > 41.3 & decimalLatitude < 41.365 & decimalLongitude > -122.6 & decimalLongitude < -122.5 )\n\nOverlay the plots and add a triangle for the seep where I observed some Cobra Lilies next to the trail.\n\nTrailRun_plot2 <- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black') +\n          geom_point(data=cobra_lily_coords_sub, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n          geom_point(aes(x = -122.55, y = 41.325), pch=25, size= 12, colour=\"purple\") +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot2\n\n\n\n\nIn a follow-up post we will import some additional environmental data to make a multi-layered map."
  },
  {
    "objectID": "posts/2022-07-01-headwaters/index.html",
    "href": "posts/2022-07-01-headwaters/index.html",
    "title": "Headwaters Race",
    "section": "",
    "text": "Last month I ran the Headwaters Ultra here in Mount Shasta, CA. The race starts at Lake Siskiyou, heads up the steep trails on Rainbow Ridge and then heads over into the Eddy Range in the Klamath Mountains. The course meets up with the Sisson-Callahan Trail to go up and over the saddle (~8000 ft) just below the summit trail to the top of Mount Eddy (9,037 ft; 2,754 m). After the last aid station at Deadfall Meadows, the course goes back up and over the saddle followed by 12 miles of fast, quad-busting descent all the way down the Sisson-Callahan trial. It was really fun overall. It rained and snowed the night before, so the race went through a few inches of fresh snow at the higher elevations above ~6500 ft. The moody dark clouds at higher elevations were interrupted by moments of bright sunshine poking through reflecting off the snow and illuminating the Foxtail Pine Grove. I finished the race 8th overall with a time of 6:44:15. A great day out!\nTake a quick look at some of the course data collected by my exercise watch.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(gpx)\nlibrary(rayshader)\n\nPull in my run data using the gpx R library and subset the route to make plotting easier. Add a Time column for seconds elapsed for plotting purposes.\n\nrun <-  read_gpx('~/DATA/data/headwaters-2022-06-18.gpx')\nsummary(run)\n\n          Length Class  Mode\nroutes    1      -none- list\ntracks    1      -none- list\nwaypoints 1      -none- list\n\nTrailRun1 <- as.data.frame(run$routes)\nTrailRun1$Time <- as.numeric(row.names(TrailRun1))\n\nQuick plot.\n\nTR_p1 <- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black', size = 2) +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTR_p1\n\n\n\n\nTake a look at the elevation profile in meters.\n\nTR_p2 <- ggplot() +\n          geom_line(data = TrailRun1, aes(x = Time, y = Elevation), color = 'black', size = 2) +\n          xlab(\"Time (seconds)\") + ylab(\"Elevation (m)\")\nTR_p2\n\n\n\n\nMake a new factor column to see what parts of the race had snow on them.\n\nTrailRun1$snow <-  as.factor(if_else(TrailRun1$Elevation > 1980, \"Yes\", \"No\"))\nTR_p3 <- ggplot() +\n          geom_line(data = TrailRun1, aes(x = Time, y = Elevation, color = snow), size = 2) +\n          xlab(\"Time (seconds)\") + ylab(\"Elevation (m)\")\nTR_p3\n\n\n\n\nThe rayshader package is really cool. You can take ggplot2 figures and make them 3D with this package. The code for doing so is below, but is not run to keep the website rendering time short. It takes a few minutes to render the snapshot view on my Macbook Pro using a few available cores.\n\nTR_p4 <- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude, color = Elevation), size = 2) +\n          scale_color_continuous(limits=c(800,2800))\nTR_p4\n\n\n\n# Not run for website rendering purposes, but you should!\n# plot_gg(TR_p4, width = 15, height = 15, multicore = TRUE, scale = 1000,\n#         zoom = .7, theta = 10, phi = 20, windowsize = c(3000, 3000))\n# Sys.sleep(0.2)\n# render_snapshot(filename = \"run-elevation-plot3.png\", clear = TRUE)"
  },
  {
    "objectID": "posts/2022-07-15-ucreservefires/index.html",
    "href": "posts/2022-07-15-ucreservefires/index.html",
    "title": "UC Reserve Fire Data",
    "section": "",
    "text": "A short post overlaying a few different GIS layers on one another for a project we are working on. The databases used are large so I just show the code here with one final image instead of including them in the website repository. I needed to subset the fire perimeters from the Cal Fire database and overlap them with the UC Reserve perimeters. I also needed to in-file some GPS coordinates of post fire sampling sites. I share the code below, but not the data as this project is still in progress. However, the raw data is available:\nCal Fire Data\nUC Reserve Perimeter Data\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(rgdal)\n\nsetwd(\"~/DATA/data/calfire.nosync/\")\nfire <- st_read(\"fire20_1.gdb\")\nreserves <- st_read(\"UC_NRS.gdb\")\n\n# subset fire data for 2020\nfire2020 <- fire[fire$YEAR_ == \"2020\",]\nplot(fire2020$Shape)\nplot(reserves$Shape)\nstr(fire2020)\nstr(reserves)\n\nIntersect the reserves and 2020 fires.\n\noverlaps2020 <-  lengths(st_intersects(fire2020, reserves)) > 0\nfire_reserves2020 <- fire2020[overlaps2020,]\nplot(fire_reserves2020$Shape, col=\"orange\")\nplot(reserves$Shape, col=\"blue\", add = TRUE)\n\nTake a look at the names of the fires that overlap and then specifically subset them for later processing.\n\nfire_reserves2020$FIRE_NAME\nriver_fire <- subset(fire2020, FIRE_NAME == \"RIVER\")\nscu_complex_fire <- subset(fire2020, FIRE_NAME == \"SCU COMPLEX\")\nhennessey_fire <- subset(fire2020, FIRE_NAME == \"HENNESSEY\")\ndolan_fire <- subset(fire2020, FIRE_NAME == \"DOLAN\")\nsnow_fire <- subset(fire2020, FIRE_NAME == \"SNOW\") # did not collect field data here\n\nInfile the arthropod sampling locations and make a coordinates dataframe.\n\nsetwd(\"~/DATA/data/\")\narthro_data <- read_csv(\"Post-FireMonitoring_Arthropod_SamplingLocations.csv\")\narthro_coords <- data.frame(x = arthro_data$LONGITUDE, y = arthro_data$LATITUDE)\n\nI converted the data frame to a spatial object with the appropriate map projection information. This then allowed me to convert Lat/Long coordinates to the same projection that the Cal Fire and UC Reserve System perimeters data are projected in (California Albers- EPSG:3310).\n\n# make spatial dataframe with lat long coords using the RGDAL package functions\ncoordinates(arthro_coords) <- ~x+y\nproj4string(arthro_coords) <- CRS(\"+proj=longlat +datum=WGS84\")\nstr(arthro_coords)\n\narthro_3310 <- spTransform(df, CRS(\"+init=epsg:3310\"))\narthro_3310\nstr(arthro_3310)\n\n# double check with plot\nplot(reserves$Shape, col=\"blue\")\nplot(arthro_3310, , col = \"red\", add = TRUE)\n\nConvert the object to and sf object for quick plotting. Calculate the overlays between the fire sampling site and the control sampling sites. Overlay the fire perimeter, the reserve perimeters, and the sampling sites. To make it more clear I chose the Hennessey Fire which burned across two reserve boundaries in 2020.\n\n# convert to sf package object\nfire_pts2 <- st_as_sf(arthro_3310)\nstr(fire_pts2)\n\n# overlay points and fire shapes\nfire_yes = lengths(st_intersects(fire_pts2, hennessey_fire)) > 0\nfire_yes\n\n# layer all the plots\nplot(hennessey_fire$Shape) # fire shape\nplot(reserves$Shape, col=\"orange\", add=TRUE) # local reserves shape\nplot(fire_pts2, pch=19, col=\"blue\", add=TRUE); # all samples\nplot(fire_pts2[fire_yes,], pch=19, col=\"red\", add=TRUE); # samples in fire\n\nIt is over-plotted in this view, but this demonstrates the idea. The Hennessey fire perimeter is shown in black, reserves in orange, reserve sampling sites within the fire perimeter in red, and sampling sites within the reserve, but outside the fire perimeter in blue."
  },
  {
    "objectID": "posts/2022-07-21-artventuregear/index.html",
    "href": "posts/2022-07-21-artventuregear/index.html",
    "title": "Art-venture Kit and Sketches",
    "section": "",
    "text": "A quick digital illustration of my small and medium sized travel/adventure art sketch kits. The top row is the small kit that fits into a Patagonia Black Hole fanny pack. The middle/bottom rows make up my medium kit. My small kit technically fits inside also, but it is its own kit. I always have some form of sketchbook with me when out and about. #dailysketching\n\nSmall Kit Contents\n\nruler\nfine and medium Pentel aqua-water brush\nfine water brush with 30% india ink diluted\nfine water brush with 70% india ink diluted\nCopic brush pen for large dark areas\nTWSBI Eco refillable fountain pen with extra-fine nib filled with Platinum Carbon Black ink\n0.3 Copic multiliner\n0.3 Micron fineliner\nUni-ball KuruToga mechanical pencil with 4b lead (I like to punch in darks in my pencil sketches)\nDIY watercolor kit in old mint tin\nStillman and Birn 3.5” by 5.5” 150 GSM Epsilon series multi-media sketchbook (can take a few watercolor washes)\nShop paper towel for washing out brushes before switching colors\nPatagonia Black Hole Fanny Pack\n\n\n\nMedium Kit Contents\n\nKavu Grizzly Kit Bag with climbing rated carabiners and climbing webbing strap\nKindle paper white with all my art books (for practice or inspiration)\nMoleskine 5” by 8.5” sketchbook\nMoleskine 5” by 8.5” landscape watercolor sketchbook (friend art journal)\nruler\nCopic 0.3 and 0.5 seppia toned fineliners\nUni-ball KuruToga mechanical pencil 0.7 mm with 4b lead\nFine retractable eraser\nold 4b pencil (pencil extender not drawn)\nZebra Brush pen\nUni-ball KuruToga mechanical pencil 0.5 mm with 4b lead\nballpoint pen 1\nballpoint pen 2\nCopic large brush pen\nSteadtler 2 mm lead mechanical pencil 4B, 2H, 2B\nwater soluble black pen\nfine and medium Pentel aqua-water brush\n4b 0.7 leads\nink container\n2 mm lead sharpener\nstandard pencil sharpener\ngum eraser\nLarge watercolor palette\nShop paper towel for washing out brushes before switching colors\n\n\n\nSmall Kit Examples\nSketch at local park.\n\n\n\nSketch at local concert venue.\n\n\n\nSketch of aloe plant and pinyon pine cones.\n\n\n\nSketch crawl at local watering hole.\n\n\n\n\n\nMedium Kit Examples\nSepia toned pages of dog toys and living room objects at a friend’s house.\n\n\n\nLarger watercolor of headphones.\n\n\n\nWater color landscape Moab Utah."
  },
  {
    "objectID": "posts/2022-08-01-drseussplant/index.html",
    "href": "posts/2022-08-01-drseussplant/index.html",
    "title": "Mount Shasta Wilderness Wildflowers",
    "section": "",
    "text": "I went on a quick overnight to a spring fed creek above 8000 feet on Mount Shasta. I noticed these interesting flowers that I have never seen before. They reminded me of something that Dr. Seuss would have illustrated in his various children’s books. After searching the internet with no luck I finally needed rely on some California Botany experts to help with the ID: Anemone occidentalis. The hair-like calyx tissue on top of each ovary are what give this plant it’s unique look once reproductively mature. These are similar structures to white dandelion heads and aid in seed dispersal via wind.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(rgbif)\nlibrary(gpx)\n\nMake the large Northern California polygon to look for observations in GBIF.\n\nnorcal_geometry <- paste('POLYGON((-124.4323 42.0021, -121.5045 42.0021, -121.5045 40.194, -124.4323 40.194, -124.4323 42.0021))')\n\ndr_seuss <- occ_data(scientificName = \"Anemone occidentalis\", hasCoordinate = TRUE, limit = 1000,\n                   geometry = norcal_geometry)\n# length(dr_seuss)\nhead(dr_seuss)\n\n$meta\n$meta$offset\n[1] 0\n\n$meta$limit\n[1] 300\n\n$meta$endOfRecords\n[1] TRUE\n\n$meta$count\n[1] 44\n\n\n$data\n# A tibble: 44 × 114\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n   <chr>  <chr>     <dbl>   <dbl> <chr>  <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 40229… Anemon…    41.4   -122. cdc    b05154… a8a2b5… cb27a4… US      DWC_AR…\n 2 40229… Anemon…    41.4   -122. cdc    b05154… a8a2b5… cb27a4… US      DWC_AR…\n 3 40229… Anemon…    41.4   -122. cdc    b05154… a8a2b5… cb27a4… US      DWC_AR…\n 4 89974… Anemon…    41.6   -123. cdc,c… 7a2660… 0674ae… 6038e5… DE      BIOCASE\n 5 24179… Anemon…    40.5   -122. cdc,a… ae33dc… c6e100… cb27a4… US      DWC_AR…\n 6 29820… Anemon…    41.2   -123. cdc,c… 695862… c10e9f… cb27a4… US      DWC_AR…\n 7 33207… Anemon…    41.5   -122. cdc,g… 677aec… 314e47… cb27a4… US      DWC_AR…\n 8 33207… Anemon…    41.2   -123. cdc,g… 677aec… 314e47… cb27a4… US      DWC_AR…\n 9 33207… Anemon…    41.5   -123. cdc,g… 677aec… 314e47… cb27a4… US      DWC_AR…\n10 29820… Anemon…    41.6   -123. cdc,g… 695862… c10e9f… cb27a4… US      DWC_AR…\n# … with 34 more rows, 104 more variables: lastCrawled <chr>, lastParsed <chr>,\n#   crawlId <int>, hostingOrganizationKey <chr>, basisOfRecord <chr>,\n#   occurrenceStatus <chr>, taxonKey <int>, kingdomKey <int>, phylumKey <int>,\n#   classKey <int>, orderKey <int>, familyKey <int>, genusKey <int>,\n#   speciesKey <int>, acceptedTaxonKey <int>, acceptedScientificName <chr>,\n#   kingdom <chr>, phylum <chr>, order <chr>, family <chr>, genus <chr>,\n#   species <chr>, genericName <chr>, specificEpithet <chr>, taxonRank <chr>, …\n\n\nQuick map of observations in Northern California. There are a few observations across the general bioregion I live near, but none on the hike I went on.\n\ndr_seuss_coords <- dr_seuss$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n\nmaps::map(database = \"state\", region = \"california\")\npoints(dr_seuss_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\nPull in my hike data using the gpx R library and subset the route to make plotting easier.\n\nhike <-  read_gpx('~/DATA/data/mount_shasta_hiking.gpx')\nhike1 <- as.data.frame(hike$routes)\n\nOverlay the hiking data and the image/observation coordinates as a triangle.\n\nhike_plot2 <- ggplot() +\n          coord_quickmap() +\n          geom_point(data = hike1, aes(x = Longitude, y = Latitude), color = 'black') +\n          geom_point(aes(x = -122.19, y = 41.36325), pch=25, size= 5, colour=\"purple\") +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nhike_plot2"
  },
  {
    "objectID": "posts/2022-08-15-trailrunningtrainingdata/index.html",
    "href": "posts/2022-08-15-trailrunningtrainingdata/index.html",
    "title": "Heart Rate Data Analysis",
    "section": "",
    "text": "This analysis is based on a my personal exercise data so it is just a description to make the plots without the actual data existing in the website repository. I will do another post on how to make this dataset from exercise watch data at another time.\n\nTrail Running Data\nWe will be using the tidyverse and lubridate packages today to explore this dataset. Load the packages.\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\nLoad the combined dataset into the R session.\n\nload(\"MergedFitnessAug2022.RData\")\n\nThe exercise watch I use has the ability to detect heart rate and it works fairly well. Here I create a new column of data that breaks up the heart rate information into different zones roughly corresponding to different physiological states. These zones are defined by physiological testing outlined by The Uphill Athlete.\n\nmerged_fitness$HRzone <- cut(merged_fitness$heart_rate,c(0,120,155,163,174, 188, 200))\nlevels(merged_fitness$HRzone) <- c(\"R\",\"Z1\",\"Z2\",\"Z3\",\"Z4\",\"Z5\")\n\nConvert the dataframe into a tibble which is a tidyverse dataframe that has some additional properties to make it easier to examine what is going on.\n\nmerged_fitness <- as_tibble(merged_fitness)\n\nSubset the large exercise dataframe to just include Trail Running as an activity. Make a quick plot of the heart rate zone data.\n\nTrailRun1 <- subset(merged_fitness, activity == \"TrailRunning\")\np1 <- ggplot(TrailRun1, aes(x=heart_rate, fill = HRzone)) +\n    geom_histogram()\np1\n\n\nI trained very seriously for the Headwaters Trail Ultra starting in early 2022. To take a look at how much time I spent in each heart rate zone and what altitude I trained at, I made a data subset for the training period. You can see that I spent most of my time either in Z1 or Z2/Z3 for training as outlined in the Uphill Athlete training plans. A bulk of my cardiovascular training is spent below 155 beats per minute (Zone 1 Threshold), with some harder workouts in higher heart rate zones (Zone 2/3) and occasionally in Zone 4. A bulk of my recovery workouts were hiking or easy mountain biking so they are not captured in this view of my exercise data. You can also see that a majority of my exercise is at ~1225-1250 m, or around the elevation that I live.\n\ntrailRun_2022 <- TrailRun1 %>% filter(timestamp > ymd_hms(\"2022-01-01 01:28:14\") & timestamp < ymd_hms(\"2022-06-20 01:28:14\"))\np2 <- ggplot(trailRun_2022, aes(x=heart_rate, fill = HRzone)) +\n       geom_histogram() +\n       scale_x_continuous(name=\"Heart Rate (Beats Per Minute)\", limits=c(0, 200)) +\n       scale_y_continuous(name=\"Count\", limits=c(0, 62000))\np2\n\n\n\np3 <- ggplot(trailRun_2022, aes(x=altitude)) +\n       geom_histogram() +\n       scale_x_continuous(name=\"Altitude (m)\", limits=c(0, 2500)) +\n       scale_y_continuous(name=\"Count\", limits=c(0, 75000))\np3\n\n\nTo show a few different types of work outs, I make some additional data subsets to make quick plots. Here I subset specific Zone 1, Zone 1/2/3, and a long hard Zone 3 efforts.\n\ntrailRun_Z1 <- trailRun_2022 %>%\nfilter(timestamp > ymd_hms(\"2022-06-05 01:28:14\") & timestamp < ymd_hms(\"2022-06-06 01:28:14\"))\n\ntrailRun_Z2 <- trailRun_2022 %>%\nfilter(timestamp > ymd_hms(\"2022-03-01 01:28:14\") & timestamp < ymd_hms(\"2022-03-02 01:28:14\"))\n\ntrailRun_Z3 <- trailRun_2022 %>%\nfilter(timestamp > ymd_hms(\"2022-07-08 01:28:14\") & timestamp < ymd_hms(\"2022-07-10 01:28:14\"))\n\nThe Zone 1 workout was a long workout in the Klamath Mountains descending down into the Trinity River Headwaters Basin and then back out to meet up with the PCT. This is also the run where we found some large patches of Cobra Lilies. I am also making a vector of colors so that they will remain consistent across the following plots and match the original colors in the Heart Rate Histogram above.\n\ncols3 <- c(\"R\" = \"#F8766D\",  \"Z1\" = \"#B79F00\", \"Z2\" = \"#00BA38\", \"Z3\" = \"#00BFC4\", \"Z4\"= \"#619CFF\", \"Z5\" = \"#F564E3\", \"NA\" = \"grey50\")\n\ntrailRun_Z1$seconds <- as.numeric(rownames(trailRun_Z1))\np4 <- ggplot(trailRun_Z1, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Heart Rate (Beats Per Minute)\") +\n      scale_color_manual(values = cols3)\np4\n\n\n\np5 <- ggplot(trailRun_Z1, aes(x=seconds,  y=altitude, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Altitude (m)\") +\n      scale_color_manual(values = cols3)\np5\n\n\nThe following run is mix of heart rate zones. I have a long warm up followed by a fast climb. I recover on the way down from the climb and then have a fairly steady Zone 2 workout back up the road to the start of the run.\n\ntrailRun_Z2$seconds <- as.numeric(rownames(trailRun_Z2))\np6 <- ggplot(trailRun_Z2, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Heart Rate (Beats Per Minute)\") +\n      scale_color_manual(values = cols3)\np6\n\n\n\np7 <- ggplot(trailRun_Z2, aes(x=seconds,  y=altitude, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Altitude (m)\") +\n      scale_color_manual(values = cols3)\np7\n\n\nThis final workout was a hard one! The run was 28.87 km (~18 miles) with 1306 m (4285 feet) of gain/loss. I averaged 166 beats per minute for over 3 hours. I was mostly in heart rate zone 3 with some time in zone 2 and zone 4. On the way down I was feeling very uncomfortable, but kept up the intensity to make sure I set a personal record on this route and would not have to retry it this season. This was my final hard training run before tapering for the Headwaters Trail Ultra. I knew I was ready for the race after this run!\n\ntrailRun_Z3$seconds <- as.numeric(rownames(trailRun_Z3))\np8 <- ggplot(trailRun_Z3, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Heart Rate (Beats Per Minute)\") +\n      scale_color_manual(values = cols3)\np8\n\n\n\np9 <- ggplot(trailRun_Z3, aes(x=seconds,  y=altitude, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Altitude (m)\") +\n      scale_color_manual(values = cols3)\np9"
  },
  {
    "objectID": "posts/2022-09-01-shastasketchersdrinkanddraw/index.html",
    "href": "posts/2022-09-01-shastasketchersdrinkanddraw/index.html",
    "title": "Shasta Sketchers",
    "section": "",
    "text": "I have been meeting up with Dustin Bonivert at least once a week to do some live sketching, chat about art process, and taste some micro-brews. We decided to make our meet-ups a community event once a month hosted at a few businesses in town that sell craft beer. To find out more about upcoming events please visit our group at Shasta Sketchers.\nIf you like my sketches you can check out the sketchbook section of my art portfolio website or follow me on instagram codymarkelz.\nI put together a flier based on some of the live sketches I did at these businesses.\n\n\n\nHere are some other sketches I made on-sight at Deadwood Supply Co.."
  },
  {
    "objectID": "posts/2022-09-15-shastasketchersnaturejournal/index.html",
    "href": "posts/2022-09-15-shastasketchersnaturejournal/index.html",
    "title": "Shasta Sketchers",
    "section": "",
    "text": "Our first Drink and Draw event was a success! We are going to continue this once a month. Additionally, there was some interest in a Nature Journaling Club Meet-up. To find out more about upcoming events please visit our website at Shasta Sketchers. We will start hosting outdoor sketching meet-ups in the spring of 2023.\n\n\n\nIf you like my sketches you can check out the sketchbook section of my art portfolio website or follow me on instagram codymarkelz."
  },
  {
    "objectID": "posts/2022-10-01-slacmethodforcomics/index.html",
    "href": "posts/2022-10-01-slacmethodforcomics/index.html",
    "title": "SLAC Method for Comics Creation",
    "section": "",
    "text": "I have been listening to the Making Comics podcast for the last few years. The creators are diehard indie comic book creators that are inspiring in how they meet deadlines for their art projects while also holding down full time jobs, going to comic conventions, and spending an absurd amount of time discussing basketball stats. Fortunately, they moved the non-comics stuff to the end of the show so it is easily skipped.\nOne of the co-creators of the show Scott Lost developed a method for comics creation he calls the SLAC method. It stands for the Scott Lost Advanced Cartooning Method. It works really well as a digital comics creation workflow. The idea is to take a comic script and thumbnail out the entire issue in one go including panels on an 8 page thumbnail sheet. I made a template example below. You can download a free .psd file version from my Gumroad Page. If you want to set up your own sheet the dimensions are 300 dpi, 5100 pixels long by 3300 pixels wide. This is a standard comic art page size (11 x 17 inches) turned on its side. I added in the blue line page guides for all 8 pages including the bleed and trim areas. After the thumbnails are completed you can finish the panel layouts and start working on the rough pencils stage on another layer. The pencils layer can then be copied over and appropriately scaled into a final inks/line work file. The final step is finishing the comic coloring and lettering.\n\n\n\nThe magic of the method though is that by doing all of the layouts ahead of time, you can work on whatever you feel motivated to work on each day knowing that the main story elements are already taken care of. This helps break out of the funks of only making sequential art… well… sequentially. Do not feel like working on backgrounds? No problem work on characters. Really digging working on your character’s expression? Only work on that today. It allows you to hop around the entire issue and work on like category drawings always keeping the stoke high and potentially staying more consistent in the art across the issue.\nAn example of the method in action from my upcoming Cartographer exploration and adventure book (stay tuned!)."
  },
  {
    "objectID": "posts/2022-10-15-pyrodiversityklamathnatgeo/index.html",
    "href": "posts/2022-10-15-pyrodiversityklamathnatgeo/index.html",
    "title": "Pyrodiversity",
    "section": "",
    "text": "I am currently writing a general science article about pyrodiversity in Californian ecosystems as part of my fellowship at Berkeley Institute for Data Science . I decided to extend the idea to write a small grant to the National Geographic Society for funding a field component in the Klamath Mountain range in Northern California and Southern Oregon. The grant opportunity combines many of my current skills to tell a pyrodiversity story. The idea would be to explore areas of high, medium, and low pyrodiversity by human power starting from my house in Mount Shasta, CA and ending in Crescent City, CA. I have a few potential routes mapped out, but the one displayed below starts with a bikepacking route between Mount Shasta and Junction City, CA. The route then transitions to backpacking and takes a slightly modified version of the Bigfoot Trail. Fingers crossed for next year!\n\n\n\nFigure 1A - Project overview with four major steps. The project will take my current diverse skill set and exploration theme (1) and allow me to be mentored and learn from the National Geographic Explorer Community (2) to produce the proposed deliverables (3). I will then give back to the Explorer community by becoming a mentor and applying my open-source data science skills to collaborate with the technical teams at National Geographic (4).\nFigure 1B - A graphic representation of pyrodiversity concepts. Burn areas (orange) are represented within land areas. Overlapping fires occur over years (left to right). Examples of low pyrodiversity (few fires) to high pyrodiversity (many overlapping fires) are illustrated top to bottom.\n\n\n\nFigure 2- Inlay- Map of California (gray) with approximate outline of Klamath Mountains (black) and proposed backcountry route (blue). Zoomed in map of Klamath Mountains (black) of Northern California (gray) with proposed backcountry route (blue). Overlayed in transparent orange are the fire perimeters of the last 100 years. The deeper the orange color, the greater the number of fires for a given area. The proposed route will explore areas of high, medium and low pyrodiversity."
  },
  {
    "objectID": "posts/2022-11-01-trailrunzine/index.html",
    "href": "posts/2022-11-01-trailrunzine/index.html",
    "title": "Adventure Zines",
    "section": "",
    "text": "I have been making zines, or content for zines, while out and about. Here are a few recent examples for a trail run zine. I carry either a mechanical pencil and a blank zine made on rite-in-the-rain paper for rainy/snowy days or a regular piece of printer paper with a good technical pen. I cut out a piece of hard plastic coated cardboard that came as packaging for my running poles. I use this as a hard back to write on and attach the zine paper to it with a small clip. These go into my running vest until I find something on the trail I would like to capture. When I return home, I fill in some color with other pens or details based on photo references.\nIf you are interested in folding some of your own printer paper zines check out this helpful youtube tutorial.\nHere is how one of the trail running zines looks like unfolded.\n\n\n\n\nWater-proof paper vs. #20 printer paper\n\nRite-in-the-rain paper\nI had a grand plan to make zines out of Rite-in-the-rain paper. I have some of their notebooks and have used them extensively for field work. They are excellent for written notes and journaling, but much less so for art in my opinion. Rite paper is more expensive per sheet and I had to special order it. The paper works in most conditions, but the need for a pencil can be limiting as it is difficult to keep it from smearing the exposed sides of the zine while running. Using harder lead was one option, but it still smears. I have tried various technical pens and brushes with this paper, but do not like the results. The ink of the pens tend to sit on top of the paper without soaking in. This makes them more prone to smudging even after ample time to dry. Overall the feel of the paper is just not that good for this application and my large list of favorite drawing tools.\n\n\nRegular # 20 printer paper for the win!\nCheap and available at most drug or box stores, 20 pound (or greater), printer paper is a good option for a lightweight carry while out on runs. I just place the pre-folded zine, backing, and writing implement inside plastic bag when not in use. This paper is fine for 90% of conditions I plan to be out in and works with more pens.\nRite-in-the-rain paper (blue) vs. #20 printer paper (green) smudge comparison after 1 minute.\n\n\n\nHappy trails running and/or making adventure Zines!"
  },
  {
    "objectID": "posts/2022-12-01-baja-species/index.html",
    "href": "posts/2022-12-01-baja-species/index.html",
    "title": "Baja Species - 1",
    "section": "",
    "text": "Introduction\nI saw these beautiful birds while out train running in Baja Sur, Mexico. I had never even heard of them until now, but Crested Caracaras are really interesting birds! They are technically falcons, but act more like buzzards. This might explain why they were looking over me while I exercised in the desert. I saw the distribution map on the wikipedia link, but I wanted to see how many entries in GBIF there were in the general region I was visiting.\n\nLoad the libraries\n\nlibrary(rgbif)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\nSubset our search to only Southern Baja Sur. I used this website to make a quick bounding box which I convert into a polygon as an input to the GBIF search function. I search the general area and then clean up the output for easier plotting.\n\nbaja_geometry <- paste('POLYGON((-112.632285206 22.4136232805, -109.1001807138 22.4136232805, -109.1001807138 25.4259663625, -112.632285206 25.4259663625, -112.632285206 22.4136232805))')\n\ncaracara <- occ_data(scientificName = \"Caracara plancus\", hasCoordinate = TRUE, limit = 10000,\n                     geometry = baja_geometry )\n\ncaracara_coords <- caracara$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nThe standard maps packages I use did not have a good map of the Mexican states for quick plotting and that also integrate with the sf package well. rnaturalearth and rnaturalearthdata are good resources for plotting specific regions in various countries using the maps stored as sf objects. I subset the larger dataset to just zoom in on Mexico and plot the appoximate location where my observation was.\n\ncaracara_obs <- data.frame(decimalLongitude = c(-110.18917658541324), decimalLatitude = c(23.369598786877447))\n\nworld_maps <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nmexico <- subset(world_maps, name == \"Mexico\")\n\nggplot(data = mexico) +\n                geom_sf() +\n                geom_point(data = caracara_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red')\n\n\n\n\nZoom into the Baja penninsula and plot all the points. There have been many observations of the Crested Caracara all over the general region I visited.\n\ntheme_set(theme_bw())\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue') +\n        geom_point(data = caracara_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red')\n\n\n\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue') +\n        geom_point(data = caracara_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n        coord_sf(xlim = c(-115, -109), ylim = c(22.5, 27), expand = TRUE) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")"
  },
  {
    "objectID": "posts/2022-12-07-baja-species-2/index.html",
    "href": "posts/2022-12-07-baja-species-2/index.html",
    "title": "Baja Species 2",
    "section": "",
    "text": "Introduction\nThe Crested caracara’s I talked about in my last post are sitting on top of a Giant Cardon Cacti (Pachycereus pringlei). I wanted to take a look to see if the cacti were as widely distributed in the area as the Caracaras.\n\nLoad the libraries\n\nlibrary(rgbif)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\nSubset our search to only Southern Baja Sur.\n\nbaja_geometry <- paste('POLYGON((-112.632285206 22.4136232805, -109.1001807138 22.4136232805, -109.1001807138 25.4259663625, -112.632285206 25.4259663625, -112.632285206 22.4136232805))')\n\ncacti <- occ_data(scientificName = \"Pachycereus pringlei\", hasCoordinate = TRUE, limit = 10000,\n                     geometry = baja_geometry )\n\ncacti_coords <- cacti$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nI subset the larger dataset to just zoom in on Mexico and plot the appoximate location where my observation was.\n\ncacti_obs <- data.frame(decimalLongitude = c(-110.18917658541324), decimalLatitude = c(23.369598786877447))\n\nworld_maps <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nmexico <- subset(world_maps, name == \"Mexico\")\n\nggplot(data = mexico) +\n                geom_sf() +\n                geom_point(data = cacti_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red')\n\n\n\n\nZoom into the Baja penninsula and plot all the points. There have been many observations of both the Giant Cardon Cacti and the Crested caracara all over the general region I visited.\n\ntheme_set(theme_bw())\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = cacti_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue') +\n        geom_point(data = cacti_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red')\n\n\n\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = cacti_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue') +\n        geom_point(data = cacti_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n        coord_sf(xlim = c(-115, -109), ylim = c(22.5, 27), expand = TRUE) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")\n\n\n\nggsave(\"~/DATA/images/cardon-cacti-map.png\")"
  },
  {
    "objectID": "posts/2022-12-15-baja-species-3/index.html",
    "href": "posts/2022-12-15-baja-species-3/index.html",
    "title": "Baja Species 3",
    "section": "",
    "text": "Introduction\nI hiked in the Sierra de la Laguna National Park in Baja California Sur. The region is a biodiversity hotspot as very old mountains rise out of the sea above 6000’ elevation. There are a number of endemic species in this range. My previous posts were about the Caracara and the Cardon cacti. Below is a quick data visualization of the out and back hike we did along with some publicly available species observations.\n\nLoad the libraries\n\nlibrary(rgbif)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\nInfile the hiking data and make a plot.\n\nhike_data <- read.csv(\"~/DATA/data/baja-hike.csv\")\n\nhike_plot1 <- ggplot(hike_data, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point()\nhike_plot1\n\n\n\n\nBy taking the Latitude and Longitude limits of the hike, we can create a polygon to filter observations only falling within that shape.\n\nbaja_geometry <- paste('POLYGON((-110.1 23.45, -110.00 23.45, -110.00 23.55, -110.1 23.55, -110.1 23.45))')\n\nPull in some observations of our new Caracara friends.\n\ncaracara <- occ_data(scientificName = \"Caracara plancus\", hasCoordinate = TRUE, limit = 10000,\n                     geometry = baja_geometry )\n\ncaracara_coords <- caracara$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nSubset world maps for Mexico. Plot the hiking data and publically available Caracara observations.\n\nworld_maps <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nmexico <- subset(world_maps, name == \"Mexico\")\n\ntheme_set(theme_bw())\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = hike_data, aes(x = position_long, y = position_lat), color = 'black') +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue')\n\n\n\n\nZoom into the hiking region by changing the coordinate limits in the coord_sf() arguments.\n\n# zoom in\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = hike_data, aes(x = position_long, y = position_lat), color = 'black', shape = 3) +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red', shape = 4) +\n        coord_sf(xlim = c(-110.1, -110.0), ylim = c(23.45, 23.56), expand = TRUE) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")\n\n\n\n\nBeautiful!\nNow to see a random sampling of what other species are also in the area of the hike.\n\nspecies <- occ_data(hasCoordinate = TRUE, limit = 1000,\n                       geometry = baja_geometry )\n\nspecies_coords <- species$data[ , c(\"scientificName\",\"phylum\", \"order\", \"family\", \"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nPlot the hike data, Caracara data, and other species data on the same map. I changed the size of the hiking and Caracara points so they are easier to see. I also just plotted things by Phylum as to not overload the plot.\n\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = hike_data, aes(x = position_long, y = position_lat), color = 'black', size = 5, shape = 3) +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red', size = 6, shape = 4) +\n        geom_point(data = species_coords, aes(x = decimalLongitude, y = decimalLatitude, color = phylum)) +\n        coord_sf(xlim = c(-110.1, -110.0), ylim = c(23.45, 23.56), expand = TRUE) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")\n\n\n\n\nYou can see that there are various species to explore representing Arthropods (Insects, Spiders etc.), Cordates (Animals), Bisidomycota (fungi), and Tracheophyta (vascular plants). Also, a majority of the observations are on the trail itself. This shows one of the main limitations of this publicly available data, that it is not randomly collected. That is of course not to say it is not useful! It is still very useful. A lot to explore in another post!"
  },
  {
    "objectID": "posts/2023-01-01-mount-eddy-trail-run/index.html",
    "href": "posts/2023-01-01-mount-eddy-trail-run/index.html",
    "title": "Mount Eddy Trail Run",
    "section": "",
    "text": "Foxtail Pine Cone Illustration\n\nIntroduction\nMy partner and I recently revisited one the conifer species that occur in the Miracle Mile, but by trail running up to the top of Mount Eddy (9,037 ft; 2,754 m) in the Klamath Range. The final sub-alpine zone near the top of the mountain is a large grove of Foxtail Pine (Pinus balfouriana). I paid another visit to that same grove in another recent post, but did not go up to the higher elevations above 8000 ft.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(gpx)\nlibrary(rayshader)\nlibrary(rgbif)\nlibrary(data.table)\nlibrary(maps)\n\nIn-file the trail run gps data and make a data frame to use for plotting.\n\nrun <-  read_gpx('~/DATA/data/mount_eddy_trail_run.gpx')\nsummary(run)\n\n          Length Class  Mode\nroutes    1      -none- list\ntracks    1      -none- list\nwaypoints 1      -none- list\n\nTrailRun1 <- as.data.frame(run$routes)\nTrailRun1$Time <- as.numeric(row.names(TrailRun1))\n\nMake a quick plot using the latitude and longitude coordinates.\n\nTR_p1 <- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black', size = 2) +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTR_p1\n\n\n\n\nTake a look at the elevation profile of the run.\n\nTR_p2 <- ggplot() +\n          geom_line(data = TrailRun1, aes(x = Time, y = Elevation), color = 'black', size = 2) +\n          xlab(\"Time (seconds)\") + ylab(\"Elevation (m)\")\nTR_p2\n\n\n\n\nWe can also plot the run and false color it based on the elevation. We can pass this plot to the plot_gg() function in the rayshader package to make a 3D plot of the run. The code for that is not run on the website because it takes too long to render, so I am showing the rendered snapshot as an external image instead.\n\nTR_p3 <- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude, color = Elevation), size = 2) +\n          scale_color_continuous(limits=c(800,2800))\nTR_p3\n\n\n\n# Not run for website rendering purposes, but you should!\n# plot_gg(TR_p3, width = 15, height = 15, multicore = TRUE, scale = 1000,\n#         zoom = .7, theta = 10, phi = 20, windowsize = c(3000, 3000))\n# Sys.sleep(0.2)\n# render_snapshot(filename = \"mt-eddy-run-elevation-plot3.png\", clear = TRUE)\n\n\nUsing the Latitude and Longitude coordinates of the area we can make a general area polygon to be used for a GBIF species observation query to the public database.\n\nnorcal_geometry <- paste('POLYGON((-122.6 41.35, -122.35 41.35, -122.35 41.25, -122.4 41.25, -122.6 41.25, -122.6 41.35))')\n\nmm_species <- c(\"pinus balfouriana\") # can add multiple species here for larger query\n\nfoxtail_data <- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = norcal_geometry)\nfoxtail_data\n\nRecords found [51] \nRecords returned [51] \nArgs [hasCoordinate=TRUE, occurrenceStatus=PRESENT, limit=10000, offset=0,\n     scientificName=pinus balfouriana, geometry=POLYGON((-122.6 41.35, -122.35\n     41.35, -122.35 41.25, -122.4 41.25, -122.6 41.25, -122.6 41.35))] \n# A tibble: 51 × 119\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n   <chr>  <chr>     <dbl>   <dbl> <chr>  <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 39472… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 2 40548… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 3 39471… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 4 39474… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 5 39612… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 6 39612… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 7 39475… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 8 39857… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 9 38922… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n10 39610… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n# … with 41 more rows, 109 more variables: lastCrawled <chr>, lastParsed <chr>,\n#   crawlId <int>, hostingOrganizationKey <chr>, basisOfRecord <chr>,\n#   occurrenceStatus <chr>, taxonKey <int>, kingdomKey <int>, phylumKey <int>,\n#   classKey <int>, orderKey <int>, familyKey <int>, genusKey <int>,\n#   speciesKey <int>, acceptedTaxonKey <int>, acceptedScientificName <chr>,\n#   kingdom <chr>, phylum <chr>, order <chr>, family <chr>, genus <chr>,\n#   species <chr>, genericName <chr>, specificEpithet <chr>, taxonRank <chr>, …\n\nfoxtail_coords <- foxtail_data$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nPlot the observations on the California map to see the limited polygon sampled.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(foxtail_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\nPlot all of the observations using ggplot for the zoomed in area.\n\nfoxtail_plot1  <- ggplot(foxtail_coords, aes(x=decimalLongitude, y = decimalLatitude)) +\n                             geom_point(color='red') + labs(title = \"MM Zone\")\nfoxtail_plot1\n\n\n\n\nCombine trail running and foxtail pine occurrence observations.\n\nrun_plot2 <- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black') +\n          geom_point(data=foxtail_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nrun_plot2"
  },
  {
    "objectID": "posts/2023-01-07-trinity-alps-trail-run/index.html",
    "href": "posts/2023-01-07-trinity-alps-trail-run/index.html",
    "title": "Trinity Alps Trail Run",
    "section": "",
    "text": "Western White Pine Cone Illustration\n\nIntroduction\nI recently revisited one the conifer species that occur in the Miracle Mile, but by trail running in the Trinity Alps Wilderness area in the Klamath range of Northern California. I found a number of cool species, but one recognizable one was the Western White Pine (Pinus monticola). Pinus monticola is found in many of the cool trail running spots I frequent. Here is another post about another trail run with Pinus monticola.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(gpx)\nlibrary(rgbif)\n\nIn-file the trail run gps data and make a data frame to use for plotting.\n\nrun <-  read_gpx('~/DATA/data/Trinity-Alps-TrailRunning-2022-10-08-route.gpx')\nsummary(run)\n\n          Length Class  Mode\nroutes    1      -none- list\ntracks    1      -none- list\nwaypoints 1      -none- list\n\nTrailRun1 <- as.data.frame(run$routes)\nTrailRun1$Time <- as.numeric(row.names(TrailRun1))\n\nMake a quick plot using the latitude and longitude coordinates.\n\nTR_p1 <- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black', size = 2) +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTR_p1\n\n\n\n\nTake a look at the elevation profile of the run.\n\nTR_p2 <- ggplot() +\n          geom_line(data = TrailRun1, aes(x = Time, y = Elevation), color = 'black', size = 2) +\n          xlab(\"Time (seconds)\") + ylab(\"Elevation (m)\")\nTR_p2\n\n\n\n\nWe can also plot the run and false color it based on the elevation.\n\nTR_p3 <- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude, color = Elevation), size = 2) +\n          scale_color_continuous(limits=c(800,2800))\nTR_p3\n\n\n\n\nUsing the Latitude and Longitude coordinates of the area we can make a general area polygon to be used for a GBIF species observation query to the public database.\n\ntrinity_geometry <- paste('POLYGON((-122.91 40.88, -122.87 40.88, -122.87 40.96, -122.91 40.96, -122.91 40.88))')\n\nmm_species <- c(\"pinus monticola\") # can add multiple species here for larger query\n\nwhitepine_data <- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = trinity_geometry)\nwhitepine_data\n\nRecords found [5] \nRecords returned [5] \nArgs [hasCoordinate=TRUE, occurrenceStatus=PRESENT, limit=10000, offset=0,\n     scientificName=pinus monticola, geometry=POLYGON((-122.91 40.88, -122.87\n     40.88, -122.87 40.96, -122.91 40.96, -122.91 40.88))] \n# A tibble: 5 × 73\n  key     scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n  <chr>   <chr>     <dbl>   <dbl> <chr>  <chr>   <chr>   <chr>   <chr>   <chr>  \n1 396113… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n2 396097… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n3 338409… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n4 239748… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n5 254089… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n# … with 63 more variables: lastCrawled <chr>, lastParsed <chr>, crawlId <int>,\n#   hostingOrganizationKey <chr>, basisOfRecord <chr>, occurrenceStatus <chr>,\n#   taxonKey <int>, kingdomKey <int>, phylumKey <int>, classKey <int>,\n#   orderKey <int>, familyKey <int>, genusKey <int>, speciesKey <int>,\n#   acceptedTaxonKey <int>, acceptedScientificName <chr>, kingdom <chr>,\n#   phylum <chr>, order <chr>, family <chr>, genus <chr>, species <chr>,\n#   genericName <chr>, specificEpithet <chr>, taxonRank <chr>, …\n\nwhitepine_coords <- whitepine_data$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nPlot the observations on the California map to see the limited polygon sampled.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(whitepine_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\nPlot all of the observations using ggplot for the zoomed in area.\n\nwhitepine_plot1  <- ggplot(whitepine_coords, aes(x=decimalLongitude, y = decimalLatitude)) +\n                             geom_point(color='red') + labs(title = \"MM Zone\")\nwhitepine_plot1\n\n\n\n\nCombine trail running and Western White Pine occurrence observations.\n\nrun_plot2 <- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black') +\n          geom_point(data = whitepine_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nrun_plot2\n\n\n\n\nNow to see a random sampling of what other species are also in the area of the trail run.\n\ntrinity_species <- occ_data(hasCoordinate = TRUE, limit = 5000,\n                         geometry = trinity_geometry)\n\ntrinity_species_coords <- trinity_species$data[ , c(\"scientificName\",\"phylum\", \"order\", \"family\", \"decimalLongitude\", \"decimalLatitude\",\"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\"institutionCode\", \"references\")]  \n\nPlot the run data, White Pine data, and other species data on the same map. I changed the size of the trail running and White Pine points so they are easier to see. I also just plotted things by Phylum as to not overload the plot by doing all the species!\n\nrun_phylum_plot <- ggplot() +\n        geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black', size = .75) +\n        geom_point(data = trinity_species_coords, aes(x = decimalLongitude, y = decimalLatitude, color = phylum)) +\n        geom_point(data = whitepine_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red', size = 5, shape = 19) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")\nrun_phylum_plot\n\n\n\n\nYou can see that there are various species to explore representing Arthropods (Insects, Spiders etc.), Cordates (Animals), Bisidomycota (fungi), and Tracheophyta (vascular plants)."
  },
  {
    "objectID": "posts/2021-08-25-ComicBookColoring.html",
    "href": "posts/2021-08-25-ComicBookColoring.html",
    "title": "Digital Comic Book Coloring Process",
    "section": "",
    "text": "Comics Coloring Class\nI recently finished a comic book coloring class taught by Chris Sotomayer with special guest instructor/critic Marissa Louise through Comics Experience. Soto is not only a top working talent, but is also a great no non-sense teacher. The class came with a large selection of donated line art from all the major publishers to color “test pages” or entire books.\nThis post is really only touching some of the major points discussed in the course. I learned through improving my page over the course, but learned a great deal more listening to the critiques of other student work. Many of the students were fairly advanced and chose pages with multiple light sources, colored lights from laser blasts, moonlight scenes, and shots from hell (literally). This class was amazing to say the least.\nI was a new user of Clip Studio Paint (CSP) when I started this class. Getting comfortable with CSP added to the learning curve. I made many simple errors due to my ignorance of the details of this program that compounded, but I figured it all out for the final image through multiple rounds of critiques. I am happy with the final page. Enjoy the process!\n\n\n\nImage Choice\n\nLine art by Robert Atkins and Clayton Brown - IDW G.I. JOE 105\nI chose this image to color because it most closely fit with the type of outdoor adventure art that I wanted to continue making. I liked that the page was center line composition of two characters running through a desert landscape towards a military base that included two long shots and two medium shots. This page represents simple visual storytelling and I wanted to see how color could enhance a simple story.\n\n\n\nSet-up Clip Studio Paint\nWhen working digitally I had three layers. The inks were on their own layer over the top of a color layer that was on top of a white background. I set the ink layer opacity to about 60% to be able to follow/trace the lines when doing the flats. Also, setting all the tools that you will be working with to no anti-aliasing. This setting will ensure no blending of pixels, just stark pixel color transitions for a finished flat that is set up for the next steps. I made a mistake with one of tools as you will see below.  \n\n\n\nPanels\nTo start digital coloring you first define the panels with a solid color. You will gradually cut this solid panel shape into the smaller color shapes in the flatting process. By having the panel background a different color from the background of the page (white in this case), you can do shape or color selection in the flatting stage more easily and track your progress as the panel color gradually gets smaller with each new defined shape. \n\n\n\nFlats\nThe point of flatting is to get all the major objects that will be different colors in the final image separated from one another and the background. Flatting takes a long time and double that for me because I needed to re-flat (see below). Flatting starts with the large shapes in the foreground and then moves to background (or visa-versa) depending on the panel. After the page is flatted, the process becomes easy to select by color and make large changes all at once. \nThere should just be simple colors and stark color transitions when you zoom in on a properly flatted page. In the following image, there are blended pixels on the edges between colors. This is a huge problem if you want to select entire color sections for the down stream processes because these blended pixels will not get selected. I could not figure out what was going wrong with my page, until I did a test area to reproduce my process and found it was the fill bucket tool. \nOpps! I also forgot uncheck the anti-aliasing on the fill bucket tool! \nI ended up re-flatting the entire page as that was easier than fixing. Lesson learned. Much better. \n\nFinished flat\nI was unsure at this point if I wanted the two characters to be in the same base camouflage color scheme so I flatted them as separate colors. This image also shows that as long as the colors for each of the flatted shapes are different it does not matter too much what they are. I am sure if you are drawing similar characters in similar environments over multiple pages, you could save yourself some time by flatting in the colors trying to match more closely what the final panel will look like. \n\n\n\n\nColor Studies\nOnce the flatting is done properly it is easier to do color and value studies by selecting the shapes and filling with the paint bucket. The paint bucket was especially helpful when doing the camouflage uniforms, the backpacks of the soldiers, the large shapes of the sky, and the rock background. By focusing only on the large shapes you could do even more quick color studies.\nI wanted the base colors to reflect commonly seen camouflage patterns and somewhat natural landscape colors even if these two things were not aligned for the purpose of camouflage (matching the environment perfectly). I tried a split-complementary three color scheme and a tetrad (double compliment) four color scheme. I also experimented with different values and atmospheric effect in the sky. I will have a follow-up post on the color theory behind these choices and other options.\n\nSplit Complementary Color Scheme\n\n\n\nimage\n\n\n\n\nTetrad Color Scheme\n\n\n\nimage\n\n\n\n\n\n\nValue Study\nNext was a pure value study with a range of values from 20-80% leaving the white (0%) for the page backgrounds and the black (100%) for the inks. At this stage there is a lot of zooming way out from the image or squinting to blur all the detail and make sure that the characters and environment shapes “read” as separate just based on their value. \n\n\n\nCombination of Value and Color First Attempt\nWhen completing the value study, I accidentally made the white background not white! I could not see this on my digital screen. It was white as far as I was concerned because locally it was the whitest value. All colors are relative!\nDuring the critique for this week the background pinks were a little too pink making this have a “Valentines Day Card” vibe. G.I. JOE Valentines day cards were a thing when I was a kid, but this was not my color intention, so I needed to fix it. It was also pointed out that “STAT BG” in the second panel meant static background. This was a note to the inker to copy the background from panel one, but in this version it did not get completed. \n\n\n\nRefinement\nI muted the pink hues and warmer colors in general and figured out how to cut and duplicate the background from the inks. I also adjusted the character colors/values to increase the contrast with the background (using a lot of the squinting technique). \nNext I made some adjustments to the black line art in the background to further increase the contrast. The background line art was shifted from black to a very dark version of the base color of the object. This reduces the local contrast of the line art and the object (e.g. mesas). This line art adjustment also helps the background fade more because the details are less visible simulating atmospheric interference when looking at a real landscape. However, after this line art adjustment it became less clear what the viewer should be focusing on in the first two panels. The combination of the background dropping away and the middle ground and foreground being approximately the same values made it confusing for the eye. I think this is a fascinating effect. Balanced images can be thrown off by small tweeks with unintended consequences. \n\n\n\nFinal Polish\nI darkened the foreground rocks and it instantly gives the first two panels a frame around the characters and a clear foreground, middle ground and background. This effect is just the reverse of the atmospheric interference I was trying to achieve by lightening the the inks in the background. At the same time the darker pink/purple in foreground further reduces the “Valentines Day Card Vibe”. Next I lightened the areas around the boots with some “dust” to add to the effect. Finally, I cleaned up the dark edge of the page on the right that was left over from scanning the inks and removed the artists names. Finished page.\n\n\n\nimage"
  },
  {
    "objectID": "posts/2021-03-15-tidy-data-intro.html",
    "href": "posts/2021-03-15-tidy-data-intro.html",
    "title": "Cycling Commuting Data 1",
    "section": "",
    "text": "Cycle Commuting Data\nFor the last few years I commuted to work most days by bicycle along the Martin Luther King Jr. Regional Shoreline Park park in Oakland, CA. This will be a series of data science posts exploring personal data collected by my smart watch and publicly available weather, nature and biodiversity data. It is my hope that this will show into the brain of how a data scientist thinks, learns, asks questions, creates models, and visualizes data from right in their back yard.\nWe will be using the tidyverse package today to explore this dataset. Load the package.\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(leaflet)\nI will do another post on how to make this dataset from exercise watch data at another time.\nHere is the base dataset we will be working with.\nload(\"MLK-park-commute.RData\")\nTo do some exploratory data analysis, let’s visualize some of the dataframe columns to get a feel for what the data represents. First I like to take a look at the data structure and get a feel for the variables.\nls()\nhead(commute)\ndim(commute)\nsummary(commute)\nConvert the dataframe into a tibble which is a tidyverse dataframe that has some additional properties to make it easier to examine what is going on.\ncommute <- as_tibble(commute)\nhead(commute)\nPassing data around and filtering instead of creating new dataframes for everything is one of the features of tidyverse that I like the best. It is a different way of thinking that becomes more intuitive over time. Below I take the commute tibble pass it to filter to grab a specific single date. filter() then passes the filtered data to leaflet which plots the latitude and longitude data on an Openmaps popup in the browser.\ncommute %>% filter(date(commute$datetime) == \"2018-08-29\") %>%\nleaflet() %>% addTiles() %>%\naddPolylines(~lon, ~lat, color = 'blue', opacity = 1, weight = 10)\n\n\n\nMLK-shoreline-commute\n\n\nspeed_plot <- ggplot(commute, aes(x=speed.kmh)) +\n  geom_histogram()\nspeed_plot\nggsave(\"speed-commute-plot.png\")\n\nThe watch that I have has the ability to detect heart rate and it works fairly well if your wrist is not moving around compared to the much more accurate heart rate strap. Here I create a new column of data that breaks up the heart rate information into different zones roughly corresponding to different physiological states. These zones are defined by\ncommute$HRzone <- cut(commute$hr.bpm,c(0, 105, 150, 160, 174, 188, 200))\nlevels(commute$HRzone) = c(\"R\",\"Z1\",\"Z2\",\"Z3\",\"Z4\",\"Z5\")\nLet’s take a look at the heart rate data. First plotting a histogram.\nbpm_plot <- ggplot(commute, aes(x=hr.bpm)) +\n  geom_histogram()\nbpm_plot\nggsave(\"heart-rate-commute-bpm_plot.png\")\n\nLet’s add the heart rate zone information as color and then do some axis labeling and clean up.\nbpm_plot2 <- ggplot(commute, aes(x=hr.bpm, fill = HRzone)) +\n       geom_histogram() +\n       scale_x_continuous(name=\"Heart Rate (Beats Per Minute)\", limits=c(0, 200)) +\n       scale_y_continuous(name=\"Count\", limits=c(0, 80000))\nbpm_plot2\nggsave(\"heart-rate-commute-bpm_plot2.png\")\n\nYou can see in the figure above that I spent most of my commuting time in low Z1 or the recovery heart rate zone. It was harder to do Z1-Z3 workouts on the commuting bike because I often had to go directly into meetings after a quick shower. This was frustrating at first, but I grew to love the slower pace and over the few years got to observe some amazing tidal changes, bird migrations, wildflower blooms, sunrises and sunsets along the MLK shoreline. More on the natural history of the area in the subsequent posts."
  },
  {
    "objectID": "posts/2023-02-23-BIDS-welcome.html",
    "href": "posts/2023-02-23-BIDS-welcome.html",
    "title": "BIDS Illustration",
    "section": "",
    "text": "SDH Hall Sketch\nBerkeley Institute for Data Science (BIDS) finally moved into our new space in Sutardja Dai Hall on the UC Berkeley campus. I designed this flier for our welcome event featuring an illustration of SDH. I knew immediately that I wanted to sketch this great building, but did not know it would become part of a flier!\nThe welcome event was great. I met a lot of really interesting people and struck up some collaborations to visualize some research through illustrations and sketchnotes! I am really excited about this new opportunity to apply my love for learning, illustration and data visualization towards science communications of the cool projects that are going on at BIDS."
  },
  {
    "objectID": "posts/2015-01-01-ArtScienceHack.html",
    "href": "posts/2015-01-01-ArtScienceHack.html",
    "title": "Art Science Hackathon",
    "section": "",
    "text": "I have two really good friends that are both professional designers/artists living in Chicago. Every year over the holiday break we would discuss how fun it would be to do a collaborative project, but never got around to doing one because of our busy schedules. This year we planned a few months in advance to have a hackathon style four day work session between Christmas and New Years. We wanted to move as quickly as possible and make as many ideas happen as possible in our short time frame. We discussed all of the different data sets that I had as part of various research projects and the ones that turned out to be most appealing were the high-throughput plant imaging data sets."
  },
  {
    "objectID": "posts/2015-01-01-ArtScienceHack.html#examples",
    "href": "posts/2015-01-01-ArtScienceHack.html#examples",
    "title": "Art Science Hackathon",
    "section": "Examples",
    "text": "Examples\n\nArabidopsis thaliana architectural forms\nI just learned Rhino about four hours earlier so this was a successful visualization of an Arabidopsis growth time series. This is a mosaic of the steps in constructing this city. As part of another project in the lab I have thousands of Arabidopsis timelapse images. I quickly modified some other code for a quick python script to binerize the plant relative to the background and then quantified plant area in each successive image. The height of the buildings correspond to the difference in rosette size from the previous timepoint. Then I got to really have fun and make a skyline and city in the shape of one of the plant outlines. Moving around the city that I had just made was really trippy especially when doing it from a 6 foot tall person perspective. The upper right is a view from the skydeck of a building. Johnny helped me make the surface transparent to give it a glass coffeetable feel. I think overall this project might help me pass Architecture 101.\n\nArabidopsis City visualization using rosette growth data:\n\n\n\n\nBrassica rapa architectural forms\nFor another lab project I am doing some 3D reconstructions of Brassica rapa. I have loads of this kind of data, but thought it would be nice to see what an artist’s perspective might use the data for. First things first, it was much too dense to load into memory so we randomly sampled the point cloud and made some wire frames by nearest neighbor searches. The renderings are simple and elegant. Then Johnny took it to the next level with a Rhino plugin called Grasshopper to produce the metaball renderings and octree representations of the data. A free plugin that might make the cost of Rhino worth it.\n\nBrassica rapa sparse proximity structure:\n\n\n\nBrassica rapa metaball space structure:"
  },
  {
    "objectID": "posts/2015-11-18-Trello.html",
    "href": "posts/2015-11-18-Trello.html",
    "title": "Introduction to Trello for Project Management",
    "section": "",
    "text": "Motivation\nThis quick post is an example of my scientific and collaboration work flow using the free features of Trello. I have tried many different ways of organizing ideas and implementing GTD. Email is NOT a good way to organize projects, especially long term ones. Elaborate tag systems can help, but I found that it is more hassle than it is worth when there are other tools available. For a while I used The Secret Weapon. Even if you do not use TSW system you should still take a look at these videos to get into that mindset. However, I was spending a lot of time sending emails to people instead of creating new things. Trello is a much better option because it adds a great collaboration component along with a visual way to organize projects. It is browser based and I recommend that you use Chrome because it has some nice Add-ons. Here is a rapid introduction to my work flow with ideas taken from GTD and TSW.\n ##### FIGURE 1: Trello data has a hierarchy going Organizations –> Boards –> Lists –> Cards. Figure 1 is looking at a board I made for this tutorial.\n\nHere is where all the boards you are associated with are located.\nSearch board for specific items or data.\nOpen-source Trello time tracking app Plus\nAlerts. Will turn red when someone messages you or there is a change is made to a project you are “watching”. More on watching later.\nBoards are organized into Lists.\nIndividual Cards are attached to Lists and can be moved around between Lists.\nCards can have many things associated with them including due dates, people working on them, attachments etc. More on this in Figure 2.\nMy general work flow is to have Lists consisting of GOALS, TO DO, DOING, DONE, and ONGOING. Cards move from right to left for each day. If it is a one off task then it gets moved to DONE and eventually archived. If it is part of a larger project then it gets moved to ONGOING when completed because the card might be used again for the same project. Cards only go into DOING if you actively working on them. This helps me focus and use the time tracking for this task. It is also a good time to block incoming email and other distractions so you can single-task.\n\n ##### FIGURE 2: When you click on a card it flips it over for more details on the “back” of the card.\n\nMembers associated with the card. Excellent for collaboration and responsibility for to-do items on the card.\nColor labels to help visually orient you in boards with many cards.\nDue dates. These can sink with google calendar.\nCard description. Usually I keep this sparse.\nChecklists. Shows progress for each item. Cards can have multiple checklists.\nPlus time tracking for each card. Click this to start timer working on this card.\nComments. Update progress post working on the tasks associated with this card. I generally include what I did and what should be done the next hour of work on this project. This helps when picking the project back up after a while. Attach items (.csv, images, papers, etc.) to the card using your hard drive, Dropbox, Google Drive, or from a weblink. Integrates youtube videos for example.\nReferring to cards within boards with the link to the card. Also useful is an email address for each card. Attach that address when dealing with email and it will forward to the card.\nComments are great for communicating because you can tag people by their user name.\nAll the items on this card are tracked. Not only comments, but also movements between lists.\n\n ###### FIGURE 3\n\nClick on the menu bar where you will see a history of the entire board along with some options.\nAdd members to the board.\nYou can filter the cards you see by their color tag. This helps if it gets too crazy on a board. This is where you add the calendar integration and card aging power ups.\n\n\n\n\nFIGURE 4 Here is a reduced view of my personal project board.\n\nPlus time tracking. Click here for time spent on each board, reports, and all these other awesome features of how you spend your time.\nView the board as a calendar with all the due dates displayed.\nTiming is only on for current task: Trello Tutorial on my Website card.\nCard aging. A nice visual way to see what projects you have not touched for a while. This feature helps when reviewing goals and prioritizing the week.\n\n ###### FIGURE 5: This is what a collaborative board looks like. This is my undergrad’s lab notebooks and is organized a little differently than my personal work flow. Digital is nice because you can search the content. At the end of the quarter paper notebooks are scanned and attached to the notebook cards. This is where Trello really shines because it is flexible in communication and what can be associated with each card. For example, I take pictures of ideas in notebooks and white boards to post to Trello with some key words that make these ideas easily indexed.\n\nIndividual student lab notebooks.\nCollaborative learning projects we are working on.\nAnnouncements for goals, expectations, etc.\nResources. Comes in handy when new undergrad joins to get them up to speed quickly.\nGrants and longer term goals.\n\n\nBackups\nI backup my trello data once a week into a private repository using this script\n\n\nFile Sharing\nWe have joint Box accounts through our university for file sharing. No need to attach huge items to cards. Just link them to shared storage. These shared folders are also where all the boards are backed up and version controlled.\n\n\niOS Support\nTrello has an iOS App that I use to check up on things, send small messages, and add notes on the go.\n\n\nDecember 3, 2015 Update\nYou can also integrate Trello with Slack. Slack allows easy (free) access to github repositories. Currently you have to pay for that using Trello.\nMike Covington Pointed me to another Chrome plug-in, Elegantt, for nice visual summaries of project time-lines, overviews, and 100 foot views of projects.\nWhen researching slack integration I came across this post for managing REALLY large projects using Trello. It describes many of the same things above but for a much larger organization. Worth a read."
  },
  {
    "objectID": "posts/2022-01-01-Obsidian-Bibliography.html",
    "href": "posts/2022-01-01-Obsidian-Bibliography.html",
    "title": "Zotero + Obsidian",
    "section": "",
    "text": "Bibliography Software + Obsidian\nKeeping track of scientific papers, code tutorials and snippets, as well as highlighting from digital books has gotten a lot easier of over the past few years. Check out Zotero here. If you are completely new to Zotero work through this quickstart tutorial by Kartcher and Zelle. I have been using Zotero almost exclusively for the past 11 years for PDF management because it has plugins for Word or Google documents to quickly create linked bibliographies for research papers. The stand alone version of the Zotero App has various plugins that make it an even better research tool for my workflow. As an example, the Firefox plugin allows you to click the icon in the browser tab and save the content, webpage, or PDF to the open folder in your Zotero library. This makes it really fast to accumulate papers and resources to read and take notes offline for research projects.\nTwo of the newer plug-ins that I use most often are Zotfile and mdnotes. When I take notes or highlight sections in a PDF as part of my research workflow I use the Zotfile PDF highlighter extraction tool to create a text file of these items. The Zotfile highlighter extraction tool output saves within Zotero so it is connected to the PDF and bibliography meta-data. I then right click on these and use mdnotes to export them to a markdown file in my Obsidian Notes directory. I have mdnotes set-up to automatically use this Obsidian directory and create a markdown flavored hyperlink back to the PDF in Zotero. If I am working in Obsidian and I want to go back to the original paper where the note was taken from, the hyperlink will open the PDF from Zotero in the exact spot where the note was taken. A very handy feature for research projects.\nThe final Zotero tool I will mention is Better Bibtex. Better Bibtex allows you to manage bibliographies easier if you are authoring research papers in markdown or other LaTex flavored workflows. It is suggested you install this tool before installing Zotfile or mdnotes.\nHappy Researching!"
  },
  {
    "objectID": "posts/2022-01-20-rmarkdown-comic-script.html",
    "href": "posts/2022-01-20-rmarkdown-comic-script.html",
    "title": "Generic Markdown Comic Script",
    "section": "",
    "text": "A quick post to outline how I create simple comic scripts using markdown and then render them to a PDF. This is loosely based off of the Comics Experience Example Script with some modifications for markdown specific syntax like page-breaks. I like to have each comic page on it’s own printed page for editing. This allows room to thumbnail ideas directly on the scripts to workout storytelling ideas.\n\nRendering PDFs using rmarkdown\nlibrary(knitr)\nlibrary(rmarkdown)\nsetwd(\"path/to/markdown/file/directory\")\nlist.files()\nrender(\"comic-script.md\")\n\n\nrmarkdown formatted comic script example below\n---\ntitle: \"Title with version number: v6.1.1\"\nauthor: Author Name\ndate: January 20, 2022\nheader-includes:\n- \\usepackage{fancyhdr}\n- \\pagestyle{fancy}\n- \\fancyhead[CO,CE]{STORY NAME -NAME NAMERSON}\n- \\fancyfoot[CO,CE]{Copyright 2022 - NAME NAMERSON - email@email.com}\n- \\fancyfoot[LE,RO]{\\thepage}\noutput: pdf_document\n---\n\n# Background\nSTORY SENTENCE -One sentence summary.\n\nCHARACTER 1 BIO - What do they want in the pages?\n\nCHARACTER 2 BIO- What do they want in the pages?\n\n\n# Story Synopsis\n1 paragraph summary of the action/events of the story. Keep it dry and to the point. First sentence is the first page and the last sentence is the last page.\n\n# Contact Info\n**Your Name**\n\nemail@email.com\n\n[www.codymarkelz.com](www.codymarkelz.com)\n\n\n\n\\pagebreak\n\n# PAGE ONE- SIX PANELS\nOne sentence page summary.\n\n## PANEL 1\nPanel description of single action, dialogue, sound effects SFX.\n\n## PANEL 2\nPanel description of single action, dialogue, sound effects SFX.\n\n1. **CHARACTER 1**: statement and dialogue.\n\n## PANEL 3\nPanel description of single action, dialogue, sound effects SFX.\n\n1. **CHARACTER 1**: statement and dialogue.\n\n## PANEL 4\nPanel description of single action, dialogue, sound effects SFX.\n\n## PANEL 5\nPanel description of single action, dialogue, sound effects SFX.\n\n1. **CHARACTER 1**: dialogue!\n\n## PANEL 6\nPanel description of single action, dialogue, sound effects SFX.\n\n1. **CHARACTER 2**: **winded** dialogue!\n\n**SFX** WHOOOMPF!\n\n\n\n\\pagebreak\n\n#  PAGE TWO- THREE PANELS\nOne sentence page summary.\n\n## PANEL 1\nPanel description of single action, dialogue, sound effects SFX.\n\n## PANEL 2\nPanel description of single action, dialogue, sound effects SFX.\n\n## PANEL 3\nPanel description of single action, dialogue, sound effects SFX."
  },
  {
    "objectID": "posts/2023-02-15-Data-Science-Communications.html",
    "href": "posts/2023-02-15-Data-Science-Communications.html",
    "title": "Science Communications Manager",
    "section": "",
    "text": "In January 2023, I began as the Data Science Communications Manager at Berkeley Institute for Data Science (BIDS). I am really excited about this half-time role. I will get to use all the tools that are important for communicating with tens of thousands of interested scientists through newsletters and various social media platforms.\nThe other half of my role is broadening the science communications portion of my Global Environmental Change Fellowship. I will use my science outreach skills to develop a series of long form science articles as an extension of my research questions, but with a general science target audience. These articles will be enhanced with infographics, illustrations, interactive designs and data visualizations as web and print media research products. Short form articles will be packaged as blog posts and printed as zines.\nLastly, I am collaborating with BIDS scientists to create explainer sketchnotes, illustrations, and visual abstracts of their work to help fulfill broader scientific outreach goals and public engagement of their research."
  },
  {
    "objectID": "posts/2023-02-01-Obsidian3.html",
    "href": "posts/2023-02-01-Obsidian3.html",
    "title": "Introduction to Obsidian - 3",
    "section": "",
    "text": "After 1.5 years of use I have dialed in a nice workflow with Obsidian. See part 1 and part 2 for an introduction. One of the main reasons I like Obsidian is it just adds a layer on top of my current markdown notes. I can easily copy notes, back them up, move them to a new machine, access them in multiple ways, etc. completely independently of Obsidian. Adding the links between notes as I think about them and having those links updated if notes move around.\nI am primarily using obsidian as a personal wiki. I have some structure that fits the general categories of my life: MAKE, LIVE, THINK, EXPLORE. All of these overlap with one another, but it is helpful to partition them out in this way because it is similar to how I chunk my activity time.\nLIVE - This category includes human relationships, food and cooking, house and van related activities, our permaculture garden, and general socializing.\nMAKE - This category is dedicated to art, technique, illustration.\nTHINK - This category is for math, statistics, AI/ML, and science.\nEXPLORE - The category is for physical fitness, outdoor activities, gear maintenance, travel, nature observation, and exploration.\nA few examples of overlaps for these categories would be: group trail runs (LIVE-EXPLORE), analyzing heart rate data (THINK-EXPLORE), blogging about an adventure that included illustrations and data visualizations (THINK-EXPLORE-MAKE).\nNow with this structure in place I organize all my different projects and goals that fit into these categories using Obsidian. I have a balance between completely new notes for every single idea and predetermining the importance of that information as it comes in. I tried just being loose with the notes, but my projects are diverse enough, especially in the learning phase, that it becomes too cluttered. Each major sub-category gets its own markdown overview document. These overview docs link to one another, the individual notes and the images within the respective directories.\nA simplified and lightly edited view of my obsidian vault directory:\n\nOverview Documents\n1.1-LIVE-Social.md\n1.2-LIVE-House.md\n1.3-LIVE-Van.md\n1.4-LIVE-Garden.md\n2.1-MAKE-DIY-Art-School.md\n2.2-MAKE-DIY-Comic-School.md\n2.3-MAKE-Zines.md\n2.4-MAKE-Portfolio.md\n3.1-THINK-Blog.md\n3.2-THINK-DataScience.md\n3.3-THINK-Science.md\n3.4-THINK-Journal.md\n4.1-EXPLORE-AdventureSports.md\n4.2-EXPLORE-FlyFishing.md\n4.3-EXPLORE-Exercise.md\n\n\nGoal Documents\n2023-Goals.md\n2023-TODO.md\n\n\nAdditional Notes Directories\n/LIVE/notes\n/LIVE/notes/images/\n/MAKE/notes\n/MAKE/notes/images/\n/THINK/notes\n/THINK/notes/images/\n/EXPLORE/notes\n/EXPLORE/notes/images/\nOrganizing things in this way balances a structure and looseness of idea capture. It also mirrors how I organize my time in real life to reduce any frictions that might arise by having different mental models for organizing digital information and physical information and actions.\nUp next in this series: A more detailed view using obsidian for a project."
  },
  {
    "objectID": "posts/2022-09-30-DSxD-Sketchnote.html",
    "href": "posts/2022-09-30-DSxD-Sketchnote.html",
    "title": "DSxD Sketchnote",
    "section": "",
    "text": "Data Science by Design (DSxD) Reconnect Meeting Sketchnote\nThis fall, Data Science by Design (DSxD) hosted a Reconnect Meet-Up for previous participants of other meetings to get together again. The DSxD community is really diverse in interest and background. Since the first DSxD creator conference this has been one of my favorite online communities to interact with (mostly through Slack). There is always something interesting being shared there and I recently started attending the DSxD book club.\nThe sketchnote represents many of the major ideas discussed during the reconnect event. The illustration is wide ranging because DSxD topics and participants are wide ranging. The portion in the bottom left corner was my favorite. The idea was to map data and sketch with it using all of our senses. This section was led by multi-talented Max Graze. Overall, I really like being a part of such a delightful and creative community."
  },
  {
    "objectID": "posts/2022-10-25-ADSA-Sketchnote.html",
    "href": "posts/2022-10-25-ADSA-Sketchnote.html",
    "title": "ADSA Meeting Sketchnote",
    "section": "",
    "text": "Academic Data Science Alliance (ADSA) Career Workshop Sketchnote\nThe Academic Data Science Alliance (ADSA) and US Research Software Engineer Association (US-RSE) hosted a fall workshop on career tracks. The group was really committed and we wrote a rough draft of a book during a two day workshop! The goal was to identify the problems and write a handbook for data scientists or software engineers pursuing careers within academia. Contributions by Data Scientists and Software Engineers are often critical for projects to be completed and maintained after publication, but there currently is not a good career track model within academia to maintain talent.\nThe sketchnote I illustrated above shows the major workflow of the meeting. We had an introduction and problem definitions at the top and then broke out into smaller groups to tackle the 8 chapters (Intro, Need, Position, etc.) of the forthcoming book. The moderators ensured there was near immediate feedback sessions and time for incorporating comments and feedback. The workshop was run like a 2 day academic paper writing session with rapid critical feedback. After the first session, everyone was feeling a bit weary to get feedback that quickly. In the end though, it was the perfect way to write a draft of a book in 2 days!"
  },
  {
    "objectID": "adventure/nature-journal.html",
    "href": "adventure/nature-journal.html",
    "title": "Nature Journal",
    "section": "",
    "text": "Comic book art if my adventure sketching field kits. Read more about the kit details here."
  },
  {
    "objectID": "adventure/ski.html",
    "href": "adventure/ski.html",
    "title": "Ski",
    "section": "",
    "text": "Narrowly escaping a tree falling in Yosemite during a winter windstorm. Snow moon rise over Half Dome.\n\n\n\n\n\nCaryn taking a lunch break at Horse Camp after a long skin up."
  },
  {
    "objectID": "adventure/run.html",
    "href": "adventure/run.html",
    "title": "Run",
    "section": "",
    "text": "Comic book art for local trail ultra-run. Read more about the race here.\n\n\n\n\n\nCaryn trail running up to Horse Camp (2420m, 7950 ft) on Mount Shasta.\n\n\n\n\n\nCaryn trail running on the PCT with Mount Shasta in the background.\n\n\n\n\n\nTrail running in the Northern Cascades, WA and a view of our adventure van (NSBG) gear garage under our bed."
  },
  {
    "objectID": "adventure/van.html",
    "href": "adventure/van.html",
    "title": "Van",
    "section": "",
    "text": "Adventure van set-up with mountain bikes.\n\n\n\n\n\nTrail running in the Northern Cascades, WA and a view of our adventure van (NSBG) gear garage under our bed."
  },
  {
    "objectID": "adventure/hike.html",
    "href": "adventure/hike.html",
    "title": "Hike",
    "section": "",
    "text": "Caryn trail running on the PCT with Mount Shasta in the background."
  },
  {
    "objectID": "adventure/fish.html",
    "href": "adventure/fish.html",
    "title": "Fish",
    "section": "",
    "text": "Fly-fishing on the Sacramento river headwaters.\n\n\n\n\n\nTenkara fishing on the Kern River."
  },
  {
    "objectID": "adventure/bike.html",
    "href": "adventure/bike.html",
    "title": "Bike",
    "section": "",
    "text": "Mountain biking in Moab, UT.\n\n\n\n\n\nBike packing the Sierra Nevada.\n\n\n\n\n\nBike packing bike set-up."
  },
  {
    "objectID": "posts/2023-03-17-ImageXD.html",
    "href": "posts/2023-03-17-ImageXD.html",
    "title": "ImageXD Meeting Sketchnotes",
    "section": "",
    "text": "I participated, lead some sessions, and did some live sketchnote taking at ImageXD-2023. Below is the write-up I did for BIDS. If you are interested in sketchnotes, checkout my sketchnote portfolio.\n\nResearchers from across domains (XD) that use imaging data participated in ImageXD 2023. The two day workshop brought together imaging experts from diverse fields such as medical, biodiversity, machine learning, and software development. Each day had a blend of talks in the morning with “unconference” breakout working groups that were decided daily based on overlapping interests and questions formed and posted as part of a community question board.\nCheck out a detailed write-up by our co-sponsor Academic Data Science Alliance (ADSA): ImageXD Write-up\nBelow are some live sketchnotes of the event that I captured:\n\n\n\nDay 1 talk sketchnotes outline major ideas in the talks that were given by Sharmila Majumdar - UCSF professor and Director of the Center of Intelligent Imaging, Sara Beery - Assistant Professor at MIT and Visiting Researcher at Google on wildlife computer vision, Catherine Nakalembe - Africa Program Director for NASA Harvest and Assistant Professor at the University of Maryland’s Department of Geographical Sciences on food security, and Stéfan van der Walt - Researcher at UC Berkeley and Founder of scikit-image.\n\n\n\nSimilar to Day 1, Day 2 talk sketchnotes outline major ideas in the talks given by Dan Chitwood - plant biologist and Assistant Professor in the Departments of Horticulture and Computational Mathematics, Science & Engineering at Michigan State University on leaf shape morphometrics, Harry Chao - Assistant Professor of Computer Science & Engineering at The Ohio State University on training machine learning models for feature detection, and Kira Evans- Software Engineer at the Chan Zuckerberg Initiative on the Napari image processing Python package.\nThank you to the ImageXD sponsors: Chan Zuckerberg Initiative Alfred P. Sloan Foundation"
  },
  {
    "objectID": "art/sketchnotes.html",
    "href": "art/sketchnotes.html",
    "title": "Sketchnotes",
    "section": "",
    "text": "ImageXD Day 2 Sketchnote- Read more about ImageXD here\n\n\n\nImageXD Day 2 Sketchnote- Read more about ImageXD here\n Data Science by Design (DSxD) Reconnect Meeting Sketchnote - Read more about this event here\n Academic Data Science Alliance (ADSA) Career Workshop Sketchnote - Read more about this meeting here"
  }
]