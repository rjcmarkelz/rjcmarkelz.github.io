[
  {
    "objectID": "montology.html",
    "href": "montology.html",
    "title": "Montology",
    "section": "",
    "text": "Montology is the holistic study of mountains through a Liberal Arts and Sciences lens. Montology includes a generalist approach to studying mountains, taking ideas from physics, engineering, geology, data science, biology, chemistry, art, design, economics, psychology, and sociology.\nThis project will follow my journey as I work towards an integrative view of the surrounding mountains through project-based learning. I will document these projects using my newsletter (progress, failures, learning), my blog (detailed processes), and project integration insights here. My own twist is that I am a dyslexic visual thinker. You can expect an equal mix of text, visuals, explainer sketchnotes, illustrations, visual essays, and comics.\nIt is my hope with this project that it inspires at least one individual to take on their own integrative learning challenge.\n\n\n\nI have 4 main categories of projects: Sequential Art (SEQArt) Mechanical Engineering and Design of Bicycles (MechE) Let’s Be Ecologists Together (LBET) Visual Essays, Zines, Blog, Newsletter (VizThink)\nThe overview of my 5 year goals can be found on my website here, but the gist is to break things that I want to learn down into smaller units that are targeted “DIY Masters” level projects. This is how my brain works.\nWhile this list of projects seems ambitious (because it is), there are many points of overlap for the projects. For a hypothetical example, a short comic about nature journaling in an alpine meadow next to a lake in the Trinity Alps Wilderness could count for SeqArt masters, sequential art portfolio, nature journaling portfolio, ecology zine, one of the visual essays in VizThink, and a few panels can be conceptually reused for the Pyroscapes Project that has overlapping geographic areas. Now, if one of the panels had a data visualization or some other visual that explained something relating to the bike I took to ride up to the alpine, that could be part of MechE. There is overlap with all these projects like this, and these differentiations are somewhat arbitrary. I consider this one large “lifelong learning” project.\nThe other learning integration innovation I started doing regularly is using “See One, Do One, Teach One” (a medical school method), but using it to explain and “teach” the characters of my graphic novel and have them interact in small learning scenes. The main characters of my graphic novel project are Tarmo and Stick—best buddies that are re-exploring the surrounding mountain ranges in the future. As I am developing the story, I want to use these micro-lessons and interactions to get into the minds of these characters. How do they process information? How do they interact with one another when learning something new? How do they teach one another? They were long-time roommates in a college-like setting at the Explorers Academy in future San Francisco. They studied engineering, biology, ecology, and human physiology. In many ways, they are my classmates in these projects. They ride a bikepacking rig into the wilds of the Mount Shasta Bioregion, questing for new plant species. As explorers, they spend time making observations in journals using Nature Journaling, Sketchnotes, and other visual thinking techniques. This is the same project, just in fiction form. :)\n\nProjects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEQ-Art\n\n\nSequential Art Projects\n\n\n\n\n\n\n\n\n\n\n\n\nMechE\n\n\nMechanical Engineering Projects\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s Be Ecologists Together (LBET)\n\n\nEcological Projects\n\n\n\n\n\n\n\n\n\n\n\n\nVisual Thinking (VisThink)\n\n\nVisual Thinking and Communications Projects\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "General\nI am generally interested in the complexities of nature and choose problems that require at least a paper and pencil to work out. I use data, mathematical models, and illustrations as tools to understand the beauty and complexity of nature. When not behind the command-line building models and visualizing data, I can be found exploring California’s extensive backcountry on foot, bicycle, or skis and documenting my adventures through illustration, paintings, photos or prose.\n\n\n\nNow (2025-11-15)\nMy life’s purpose is to become the best “Renaissance Human” I can be. The current instantiation of that is a 5 year learning curriculum that will challenge me across multiple domains: art, storytelling, writing, mechanical engineering, data visualization, physical, ecology, social, and entrepreneurial. Read more about my 5 year goal project.\nThe current show at www.darmera.studio features paintings by Marie Brennan and Funerary Arts. The show runs until December 6, 2025."
  },
  {
    "objectID": "montology/SEQART.html",
    "href": "montology/SEQART.html",
    "title": "SEQ-Art",
    "section": "",
    "text": "Sequential Art (SeqArt) I finished thumbnailing 50 pages (2 issues) of my ~150-page graphic novel (6 issues released sequentially). I did some basic character designs focusing on the main shapes of the characters to make them visually “read” when seeing them on the page. I am working on getting the faces and expressions consistent enough before I dive into the detailing work on the issues. I have a specific set of tutorials I am working on in order to do this to the level of detail that I want for the book. One thing that has been a hang-up is the dialogue. The two main characters are easy to distinguish physically, but the dialogue is tripping me up a bit. The reason is that it needs to be so freaking tight to fit within a word balloon, to complement the visuals in the panel, and to reveal something about how the character thinks/feels etc. that cannot be conveyed through visuals. I have some decent banter between the two characters (longtime friends, university equivalent roommates), but I need to differentiate them a bit more. One is INTJ, the other is ENTJ… (yeah not the biggest difference, but important for my personal Festina Lente quest)… There will be other characters with much different personalities, but I gotta start with what I know. After I wrote the first 50 pages of story, I stepped back and am redoing following the snowflake method."
  },
  {
    "objectID": "science/artofscience.html",
    "href": "science/artofscience.html",
    "title": "The Art of Science 2.0",
    "section": "",
    "text": "Some of the images that I produced as part of a NSF Graduate Research Fellowship project were chosen as part of the ongoing Art of Science Gallery Series in Champaign-Urbana, IL.\nThe piece above is titled “Spring growth, fall colors”. The image shows microscopic structures inside a leaf: chloroplasts in light blue, and mitochondria, which convert sugar into forms of usable energy, in a range of colors (yellow to brown) according to their size. Mitochondria react very quickly to changes in the cellular environment by clumping together or dispersing throughout the cell in response to changes in light, temperature, and rate of photosynthesis in the chloroplasts. Research to understand how mitochondria respond to climate change has implications for accurate prediction of future food supply and ecosystem function. The raw data for the image was created using a Spinning Disk Confocal and Imaris 3D visualization Software.\n\n\n\nThe piece above is titled “Opposing Forces”. By the end of this century, atmospheric CO2 levels are predicted to double. Plants use CO2 to produce sugar during photosynthesis, and release CO2 as they respire. With research that produces images like this one, researchers monitor how increased CO2 changes the balance between photosynthetic and respiratory processes. In the leaf cell shown here, chloroplasts are labeled with red, mitochondria that contribute to respiration are labeled with green, and other fluid inside the cell is labeled with blue. The raw data for the image was captured using a Zeiss LSM 700 Confocal Microscope and Imaris 3D visualization Software.\nExplaining complex images like these to a lay audience was a challenge and one of my first adventures in Science Communication."
  },
  {
    "objectID": "science/sbg-fund.html",
    "href": "science/sbg-fund.html",
    "title": "Dr. Sharon Gray Foundation",
    "section": "",
    "text": "Dr. Sharon B. Gray Memorial Foundation\n“I feel that when the human race acquired the technology and evolved the intelligence necessary to build an industrial society, it also acquired the moral obligation to understand and monitor its impact on the rest of the world.” -Dr. Sharon B. Gray\nDr. Sharon Gray was a bright human being with a passion for science and mentoring women. I miss her frequently and fiercely. Collectively across the projects, we raised $200,000 to support women in science. We set up endowments and special purpose gifts at UC Davis, University of Illinois Urbana-Champaign, American Society of Plant Biology, and the Ethiopian Agricultural Research Center (EIAR). To date (2025), 50+ scientists have received research or travel funding through the foundation. Read more about the projects here.\nUC Davis Sharon Gray Memorial Award."
  },
  {
    "objectID": "science/avalanche_data_science.html",
    "href": "science/avalanche_data_science.html",
    "title": "Avalanche Data Science",
    "section": "",
    "text": "Backcountry skiing and snowboarding are becoming popular ways to recreate on snow outside of a ski resort setting. However, there are additional dangers that come from skiing on ungroomed snow outside of a ski resort. Avalanche forecasters integrate daily snow observations with weather forecasts and snowpack history to issue daily estimates of how likely avalanches are. For this project, I am collaborating with the Mount Shasta Avalanche Center and the US Forest Service to visualize historic avalanche data and develop probabilistic models to help avalanche forecasters better predict avalanches. The project involves webscraping, database design, probabilistic models, and human decision making in the backcountry. All the code will be open-source and you can follow along on the blog here\nThe key collaborators on this project are Avalanche Forecasters Nick Meyers, Casey Glaubman, Eric Falconer, Sam Clairemont, and Corey Beattie of the Mount Shasta Avalanche Center.\n\n\n\nThree day rolling average model of snow accumulation versus avalanche danger forecast across recent avalanche forecasting seasons."
  },
  {
    "objectID": "science/avalanche_data_science.html#project-overview",
    "href": "science/avalanche_data_science.html#project-overview",
    "title": "Avalanche Data Science",
    "section": "",
    "text": "Backcountry skiing and snowboarding are becoming popular ways to recreate on snow outside of a ski resort setting. However, there are additional dangers that come from skiing on ungroomed snow outside of a ski resort. Avalanche forecasters integrate daily snow observations with weather forecasts and snowpack history to issue daily estimates of how likely avalanches are. For this project, I am collaborating with the Mount Shasta Avalanche Center and the US Forest Service to visualize historic avalanche data and develop probabilistic models to help avalanche forecasters better predict avalanches. The project involves webscraping, database design, probabilistic models, and human decision making in the backcountry. All the code will be open-source and you can follow along on the blog here\nThe key collaborators on this project are Avalanche Forecasters Nick Meyers, Casey Glaubman, Eric Falconer, Sam Clairemont, and Corey Beattie of the Mount Shasta Avalanche Center.\n\n\n\nThree day rolling average model of snow accumulation versus avalanche danger forecast across recent avalanche forecasting seasons."
  },
  {
    "objectID": "science/national-pollinator-week.html",
    "href": "science/national-pollinator-week.html",
    "title": "National Pollinator Week",
    "section": "",
    "text": "National Pollinator Week\nFor 2010 and 2011, I co-organized this community event with Dr. Michelle Duennes, A.K.A the Polly Nator! For the month leading up to National Pollinator Week Michelle and I worked a booth at the Urbana Farmers Market discussing the importance of pollinators for food production.\n\nAt the end of National Pollinator Week we hosted all day events that included:\n\nNature walks led by The Prairie Monk\nInsect photography workshop by Scientific American Blogger Alex Wild\nHoney Tastings\nNurturing native bee workshop\nNative bee identification workshop\nLive concert by Duke of Uke and His Novelty Orchestra\n\n\n\n\nFly pollinator from nature walks."
  },
  {
    "objectID": "science/international-impact.html",
    "href": "science/international-impact.html",
    "title": "International Impact",
    "section": "",
    "text": "UIUC International Impact\nFundraising and service project in Ecuador building a school for a small indigenous village North of the capital city, Quito"
  },
  {
    "objectID": "science/rev_genomics.html",
    "href": "science/rev_genomics.html",
    "title": "Rev Genomics",
    "section": "",
    "text": "Company Overview\nI was the co-founder and VP of Genomics and led the technical aspects of Rev Genomics from idea to post series-A (2015-2020). I led, designed and implemented a probabilistic framework to elucidate novel biochemical pathways in Cannabis. Under my leadership my team built a data driven Cannabis breeding pipeline using genomic prediction leading to 15+ commercial strains being developed for the legal California market. Notable investors for Rev Genomics are Y-Combinator and Gron Ventures.\n\n\nOpen Cannabis SNP Map Dataset\nAs part of my work at Rev Genomics, I analyzed and generated a dataset of 23500+ SNP and 2200+ InDel molecular markers from 1358 cultivars of Cannabis to aid in open-source breeding projects. The project contains data and tutorial on how to view and use the data using open-source tools. The data and tutorial are licensed under Creative Commons Attributions License 4.0 and can be downloaded directly here (500MB). An accompanying article was published on the Future Cannabis Project Blog.\nRev Genomics continues in innovate in the Cannabis biotechnology space."
  },
  {
    "objectID": "science/postdoc_projects.html",
    "href": "science/postdoc_projects.html",
    "title": "Postdoc",
    "section": "",
    "text": "Physiological Systems Biology of Competition in Brassica rapa\nPlants growing in dense stands compete with one another for light resources at the top of the canopy. When plants sense neighbors through the phytochrome photoreceptor system they become apical dominant and grow upwards to maximize light capture. This response is termed shade avoidance and has very important ecological and agronomic consequences if plant resources are used for competitive growth instead of reproductive output. For example, over-seeding in an agricultural field is wasteful of seed resources if many individuals die after competing with neighbors for limited light and nutrient resources. In ecological settings, mixed plant communities are competing for resources in a similar way to agricultural settings, but without the direct human management of inputs. In order to study the agronomic and ecological consequences of competition I am worked with the emerging model species Brassica rapa. B. rapa is an ideal model for plant competition research because it has a sequenced genome, is both a crop and a weed in agricultural settings, and is a highly morphologically and physiologically diverse species. I approached this from many different angles that relied on my diverse research background and interests.\n\n\n\nresearch-overview\n\n\n\n\n1) B. rapa trait database\n\n\n\ngraph_db\n\n\nHard won biological data (especially from the field) should not just sit in a lab note book or on spread sheets scattered across various machines. Sharing phenotypic data after publication should be a priority for us as a community, just like putting sequencing data into NCBI databases (see Zamir 2013). This allows for the data to be used to ask multiple questions, for modeling, or to be analyzed using systems biology techniques. Towards all these goals I designed a graph database to house all of the published trait data, experimental meta-data, publications, gene expression data, from the B. rapa population.\nA partial realization of this work has come out of working with an undergraduate Tiffany Ho to create an interactive data visualization tool to examine co-occurrence of eQTL with physiological QTL called QTLVisR.\n\n\n2) Statistical Genetics\nIn collaboration with Mike Covington (who generated the SNPs), I created a saturated genetic map for this population (here). This new map, along with a Bayesian statistical approach and my graph database all blends together into a fun data science project. I am remapping all the published traits in the database using a multi-trait approach. This data is used directly in the next two aspects of my project.\nMarkelz et al. 2017\nBrock et al. 2016\n\n\n\ngenetic_map\n\n\n\n\n3) Multi-Scale Data Integration\nThe central dogma of molecular biology says DNA → RNA → Protein. Scaling the actions and interactions of proteins spatially across tissue or cell types is physiology. Scaling the actions of physiology across space and time is development. Updating the simple model to include physiology and development would look something like this: DNA → RNA → Protein → Metabolites → Physiology → Development. Of course there are feedbacks every step of the way, and it is hard to disentangle each of these into separate processes, but this simple conceptual model goes a long way. If there is a genomic location for these interactions explaining some of the variance observed in the physiological or developmental phenotype, then there is a QTL in that genomic location. QTL studies are conducted using genetic mapping populations where the parents of these populations are differ significantly from one another in the trait of interest. Up until recently, a majority of QTL studies have focused on traits that are the result of many proteins interacting one level of biological organization below the physiological or developmental trait. It is a large jump in biological organization to work backwards from physiology and development to DNA sequence differences. Quantifying messenger RNA (mRNA) acts as a stepping stone between the physiology and the DNA. Or to put it another way, mRNA can provide clues as to what proteins cells are planning to make given the current information from internal developmental and external environmental cues. The collection of mRNA expression is generally referred to as the gene co-expression network. I am interested in understanding the gene co-expression network and how it relates to DNA polymorphisms in one direction and physiological and developmental phenotypes in the other direction. In order to be able to do this, we not only need a good understanding of the biology, but we also need a good understanding of the ways in which these pieces of biological information fit together. I developed statistical techniques to connect these pieces of information in a probabilistic framework.\nBaker et al. 2019\nMarkelz et al. 2017\nBrock et al. 2016\nBaker et al. 2015\n\n\n4) Genetically Informed B. rapa Physiological Growth Models\nI am using this data to parameterize physiologically based models of plant growth. Coming full circle to my PhD work in metabolism and physiology. This is my favorite part of my project. It involves integrating environmental time course data, physiological QTLs, and programming mathematical models of plant growth. Based on my meta-analysis results, and preliminary physiological modeling results, I choose a subset of genotypes to grow in the field for 2014 to test model predictions. The field site I work at is home to three close collaborators at University of Wyoming: Dr. Rob Baker, Dr. Marc Brock, and Dr. Cynthia Weinig.\nBaker et al. 2019\nBaker et al. 2015\nHere is a preview of a canopy scale model output predicting peak canopy N content for four different treatments. Notice that there is a clear interaction between N availability and crowding as to when there is peak canopy N.\n\n\n\nphysiology_simulations\n\n\n\n\n5) Computer Vision Plant Quantification and 3D Reconstruction\nI developed a high-throughput 3D imaging robot and analysis pipeline to take non-destructive plant growth data for model calibration/validation of Brassica rapa. It was really enjoyable to build equipment. It pulls together many ways of thinking about biological problems. It forces the biologist to really think about what process they are trying understand and how to quantify it using some sort of sensor. These projects help biologists build intuition about measurement error, instrument limitation, methods development, materials selection, and design. These are skills that are undervalued in biology.\nBucksch et al. 2017\nFriesner et al. 2017\nI also co-designed a similar system for measuring Arabidopsis growth.\nAn et al. 2016\nAn et al. 2017\n\n\n\n3D_summary\n\n\n{{&lt; vimeo 108757972 &gt;}}"
  },
  {
    "objectID": "science/threatened-species.html",
    "href": "science/threatened-species.html",
    "title": "Threatened Species Survey",
    "section": "",
    "text": "Threatened Species Survey\nVolunteering with a group that finds, identifies, and catalogs endemic and rare plants in the Grampians National Park, Victoria, Australia. Species we identified included the Grampians Bitter Pea (Daviesia Laevis) and various post fire orchid species. The illustration above is of the Bitter Pea specimen we found and GPS tagged."
  },
  {
    "objectID": "art/PCT-jack-alana-din-Sierra.html",
    "href": "art/PCT-jack-alana-din-Sierra.html",
    "title": "PCT Book Sierra",
    "section": "",
    "text": "PCT Northern California\nMy friends hiked most of the PCT Southbound with a baby!\nPublished illustrations for the book “You Carry the Tent, I’ll Carry the Baby: One Family’s Journey on the Pacific Crest Trail”"
  },
  {
    "objectID": "art/nature-journal.html",
    "href": "art/nature-journal.html",
    "title": "Aloe Sketchbook",
    "section": "",
    "text": "Comic book art of my adventure sketching field kits. Read more about the kit details here."
  },
  {
    "objectID": "art/ski.html",
    "href": "art/ski.html",
    "title": "Ski",
    "section": "",
    "text": "Narrowly escaping a tree falling in Yosemite during a winter windstorm. Snow moon rise over Half Dome.\n\n\n\n\n\nCaryn taking a lunch break at Horse Camp after a long skin up."
  },
  {
    "objectID": "art/AzNatureJournalTrip-1.html",
    "href": "art/AzNatureJournalTrip-1.html",
    "title": "Arizona Nature Journal Zine - 1",
    "section": "",
    "text": "Read more about the trip and zine: Arizona Nature Journaling Retreat"
  },
  {
    "objectID": "art/bikepacking-sierra.html",
    "href": "art/bikepacking-sierra.html",
    "title": "Cody Bike Packing Sierra",
    "section": "",
    "text": "Bike packing the Sierra Nevada."
  },
  {
    "objectID": "art/parvenu-1.html",
    "href": "art/parvenu-1.html",
    "title": "Parvenu Comic Sample Page",
    "section": "",
    "text": "Sample Comic Page from “Parvenu”"
  },
  {
    "objectID": "art/PCT-jack-alana-din-Desert.html",
    "href": "art/PCT-jack-alana-din-Desert.html",
    "title": "PCT Book Desert",
    "section": "",
    "text": "PCT Northern California\nMy friends hiked most of the PCT Southbound with a baby!\nPublished illustrations for the book “You Carry the Tent, I’ll Carry the Baby: One Family’s Journey on the Pacific Crest Trail”"
  },
  {
    "objectID": "art/PCT-jack-alana-din-NorCal.html",
    "href": "art/PCT-jack-alana-din-NorCal.html",
    "title": "PCT Book Northern California",
    "section": "",
    "text": "PCT Northern California\nMy friends hiked most of the PCT Southbound with a baby!\nPublished illustrations for the book “You Carry the Tent, I’ll Carry the Baby: One Family’s Journey on the Pacific Crest Trail”"
  },
  {
    "objectID": "art/van.html",
    "href": "art/van.html",
    "title": "Van",
    "section": "",
    "text": "Above: Adventure van set-up with mountain bikes.\nOur van is named Notorious SBG after my late wife Dr. Sharon Beth Gray whose adventurous spirit lives on in our hearts, minds, and the van’s power-steering. :). NSBG is a 2015 Ford Transit 250 Hightop with a 148 wheel base purchased with 16000 miles in early 2017 for 25k cash + ~4k in build out. The current bluebook value of the van (without the build out), is $30-34k so not an investment by any means, but it has maintained value over time with the recent vehicle shortages. This model is the largest that will fit in a standard parking spot. They also make extra long ones, but that would much more of a pain. We did the build (continue to do, ha!) ourselves. It was quite a challenge trying to build something in an apartment parking lot in the East Bay while also watching the tools at all times. Fortunately, I lived within walking distance from a hardware store and from a West Marine (all of our electrical components).\nWe chose this model because it is basically a larger version of the Ford F150 truck. Same chassis and engine. While I am pretty handy, if we did need to get work done, many mechanics can work on this type of engine and parts are more abundant (also considered diesel).\nThe bed platform is just shy of 77 inches in length and the height inside the current build is also 77 inches. We fit a queen sized mattress in there. Rearranging some long pillows and our large duffel bags, you can make a number of comfortable seating arrangements on the bed.\nThere are trade-offs for everything of course and we actually rebuilt the main living area a few times based on needs. We keep it pretty minimalist and flexible (e.g. we are not going to put a ton of time into building cabinets when milk crates are way more flexible and can be taken inside our house once the trip is over).\nThe one thing we wish we did have is AWD or 4WD. So far we have gotten along without it, but only through planning and also owning a 2011 Subaru. Snow tires solve a lot of the issues, but not on sand or gravel bars (we spend time on these frequently fishing).\nThe largest upgrades that are worth buying outright if you will be living in/out of a van is swivel chairs for captain and copilot seat (see image) and a magnetic bug net for the slider and back doors that is custom to your specific model. Roll these down and it instantly turns your van into a large screened-in porch. We had a bunch of netting that we would use (also with magnets), but it was always a gigantic hassle to set up and only about an 80% solution for keeping insects out.\n\n\n\n\n\nAbove: Trail running in the Northern Cascades, WA and a view of our adventure van (NSBG) gear garage under our bed."
  },
  {
    "objectID": "art/MountShastaAlpineHut.html",
    "href": "art/MountShastaAlpineHut.html",
    "title": "Mount Shasta Alpine Hut Caretaker",
    "section": "",
    "text": "Check out more about my sweet job taking care of the Mount Shasta Alpine Hut here: Mount Shasta Alpine Hut Post"
  },
  {
    "objectID": "posts/2023-02-15-Data-Science-Communications.html",
    "href": "posts/2023-02-15-Data-Science-Communications.html",
    "title": "Science Communications Manager",
    "section": "",
    "text": "In January 2023, I began as the Data Science Communications Manager at Berkeley Institute for Data Science (BIDS). I am really excited about this half-time role. I will get to use all the tools that are important for communicating with tens of thousands of interested scientists through newsletters and various social media platforms.\nThe other half of my role is broadening the science communications portion of my Global Environmental Change Fellowship. I will use my science outreach skills to develop a series of long form science articles as an extension of my research questions, but with a general science target audience. These articles will be enhanced with infographics, illustrations, interactive designs and data visualizations as web and print media research products. Short form articles will be packaged as blog posts and printed as zines.\nLastly, I am collaborating with BIDS scientists to create explainer sketchnotes, illustrations, and visual abstracts of their work to help fulfill broader scientific outreach goals and public engagement of their research."
  },
  {
    "objectID": "posts/2023-11-20-edna-fire-accepted.html",
    "href": "posts/2023-11-20-edna-fire-accepted.html",
    "title": "Fire Impacts on Pollinators Across Ecosystem Types",
    "section": "",
    "text": "The post thumbnail was created by Anna Holmquist as a sampling figure for the paper. It shows the 2020 fire outlines around the greater Bay Area and where our Arthropod sampling sites were across six different University of California Reserves. We are happy to report that our paper was accepted for publication in Global Change Biology. It is currently available as a pre-print here.\n\nAbstract\nWildfires are increasingly altering ecosystems, posing significant challenges for biodiversity conservation and ecosystem management. In this study, we used DNA metabarcoding to assess the response of arthropod communities to large-scale wildfires across diverse habitat types. We sampled six reserves within the University of California Natural Reserve System (UCNRS), each which was partially burned in the 2020 Lightning Complex wildfires in California. Using yellow pan traps to target pollinators, we collected arthropods from burned and unburned sites across multiple habitat types including oak woodland, redwood, scrub, chamise, grassland, forest, and serpentine habitats. We found no significant difference in alpha diversity values between burned and unburned sites; instead, seasonal variations played a significant role in arthropod community dynamics, with the emergence of plant species in Spring promoting increased pollinator richness at all sites. Compositional similarity analysis revealed that burn status was not a significant grouping factor when comparing all sites. Instead, community composition primarily varied across reserves, indicating distinct pools of arthropods structured geographically. Habitat type played a crucial role in determining the response of arthropod communities to fire. While communities in grasslands and oak woodlands exhibited recovery following burn, scrublands experienced substantial changes in community composition. Our study highlights the importance of examining community responses to wildfires across broad spatial scales and diverse habitat types. By understanding the nuanced dynamics of arthropod communities in response to fire disturbances, we can develop effective conservation strategies that promote resilience and maintain biodiversity in the face of increasing wildfire frequency and intensity driven by climate change.\nThe code repository is available here. The repository also contains instructions on how to make reproducible data science docker containers for each of the major steps in the analysis pipeline. We made the docker container with the largest number of software dependencies available on docker hub here. A permanent repository with code and a citeable DOI number is available here."
  },
  {
    "objectID": "posts/2022-06-15-cobralily/index.html",
    "href": "posts/2022-06-15-cobralily/index.html",
    "title": "California Pitcher Plant",
    "section": "",
    "text": "Spring is in full swing in the higher elevations around Mount Shasta and the surrounding ranges. I am always struck by the large patches of Cobra Lilies that grow along nutrient poor seeps in alpine meadows. I nearly always stop to take some photos and take in all the cool colors and shapes when out on training runs or hikes. I have made many observations of these over the past few years, but here is a quick post to pull out observations from GBIF.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(rgbif)\nlibrary(gpx)\n\nMake the large Northern California polygon to look for observations in GBIF.\n\nnorcal_geometry &lt;- paste('POLYGON((-124.4323 42.0021, -121.5045 42.0021, -121.5045 40.194, -124.4323 40.194, -124.4323 42.0021))')\n\ncobra_lily &lt;- occ_data(scientificName = \"darlingtonia californica\", hasCoordinate = TRUE, limit = 1000,\n                   geometry = norcal_geometry)\nhead(cobra_lily)\n\n$meta\n$meta$offset\n[1] 900\n\n$meta$limit\n[1] 100\n\n$meta$endOfRecords\n[1] FALSE\n\n$meta$count\n[1] 1582\n\n\n$data\n# A tibble: 1,000 × 128\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ hosti…⁷ publi…⁸\n   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1 45123… Darlin…    41.7   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 2 45163… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 3 45191… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 4 45253… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 5 45280… Darlin…    41.7   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 6 40286… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 7 40347… Darlin…    40.7   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 8 40394… Darlin…    41.6   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 9 41655… Darlin…    41.8   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n10 40629… Darlin…    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n# … with 990 more rows, 118 more variables: protocol &lt;chr&gt;, lastCrawled &lt;chr&gt;,\n#   lastParsed &lt;chr&gt;, crawlId &lt;int&gt;, basisOfRecord &lt;chr&gt;,\n#   occurrenceStatus &lt;chr&gt;, taxonKey &lt;int&gt;, kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;,\n#   classKey &lt;int&gt;, orderKey &lt;int&gt;, familyKey &lt;int&gt;, genusKey &lt;int&gt;,\n#   speciesKey &lt;int&gt;, acceptedTaxonKey &lt;int&gt;, acceptedScientificName &lt;chr&gt;,\n#   kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   species &lt;chr&gt;, genericName &lt;chr&gt;, specificEpithet &lt;chr&gt;, taxonRank &lt;chr&gt;, …\n\n\nQuick map of observations.\n\ncobra_lily_coords &lt;- cobra_lily$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n\nmaps::map(database = \"state\", region = \"california\")\npoints(cobra_lily_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\n\n\n\n\nPull in my run data using the gpx R library and subset the route to make plotting easier.\n\nrun &lt;-  read_gpx('~/DATA/data/cobra_lily_run.gpx')\nTrailRun1 &lt;- as.data.frame(run$routes)\n\nMake a quick run plot.\n\nTrailRun_plot &lt;- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black') +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot\n\n\n\n\n\n\n\n\nSubset the larger California dataset to only include a zoomed in portion where I ran based on the maximum and minimum coordinates from the run plot above.\n\ncobra_lily_coords_sub &lt;- subset(cobra_lily_coords, decimalLatitude &gt; 41.3 & decimalLatitude &lt; 41.365 & decimalLongitude &gt; -122.6 & decimalLongitude &lt; -122.5 )\n\nOverlay the plots and add a triangle for the seep where I observed some Cobra Lilies next to the trail.\n\nTrailRun_plot2 &lt;- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black') +\n          geom_point(data=cobra_lily_coords_sub, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n          geom_point(aes(x = -122.55, y = 41.325), pch=25, size= 12, colour=\"purple\") +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot2\n\n\n\n\n\n\n\n\nIn a follow-up post we will import some additional environmental data to make a multi-layered map."
  },
  {
    "objectID": "posts/2022-12-01-baja-species/index.html",
    "href": "posts/2022-12-01-baja-species/index.html",
    "title": "Baja Species - 1",
    "section": "",
    "text": "Introduction\nI saw these beautiful birds while out train running in Baja Sur, Mexico. I had never even heard of them until now, but Crested Caracaras are really interesting birds! They are technically falcons, but act more like buzzards. This might explain why they were looking over me while I exercised in the desert. I saw the distribution map on the wikipedia link, but I wanted to see how many entries in GBIF there were in the general region I was visiting.\n\nLoad the libraries\n\nlibrary(rgbif)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\nSubset our search to only Southern Baja Sur. I used this website to make a quick bounding box which I convert into a polygon as an input to the GBIF search function. I search the general area and then clean up the output for easier plotting.\n\nbaja_geometry &lt;- paste('POLYGON((-112.632285206 22.4136232805, -109.1001807138 22.4136232805, -109.1001807138 25.4259663625, -112.632285206 25.4259663625, -112.632285206 22.4136232805))')\n\ncaracara &lt;- occ_data(scientificName = \"Caracara plancus\", hasCoordinate = TRUE, limit = 10000,\n                     geometry = baja_geometry )\n\ncaracara_coords &lt;- caracara$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nThe standard maps packages I use did not have a good map of the Mexican states for quick plotting and that also integrate with the sf package well. rnaturalearth and rnaturalearthdata are good resources for plotting specific regions in various countries using the maps stored as sf objects. I subset the larger dataset to just zoom in on Mexico and plot the appoximate location where my observation was.\n\ncaracara_obs &lt;- data.frame(decimalLongitude = c(-110.18917658541324), decimalLatitude = c(23.369598786877447))\n\nworld_maps &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nmexico &lt;- subset(world_maps, name == \"Mexico\")\n\nggplot(data = mexico) +\n                geom_sf() +\n                geom_point(data = caracara_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red')\n\n\n\n\n\n\n\n\nZoom into the Baja penninsula and plot all the points. There have been many observations of the Crested Caracara all over the general region I visited.\n\ntheme_set(theme_bw())\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue') +\n        geom_point(data = caracara_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red')\n\n\n\n\n\n\n\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue') +\n        geom_point(data = caracara_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n        coord_sf(xlim = c(-115, -109), ylim = c(22.5, 27), expand = TRUE) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")"
  },
  {
    "objectID": "posts/2022-03-15-pacificyewtrailrun/index.html",
    "href": "posts/2022-03-15-pacificyewtrailrun/index.html",
    "title": "Miracle Mile Species 1",
    "section": "",
    "text": "I have started checking off all the conifer species that occur in the Miracle Mile. I recently found some Pacific Yew (Taxus brevifolia) on a trail run with a friend. This was also my first post to iNaturalist. A good time to take a look at the data.\nLoad the libraries.\n\nlibrary(rinat)\nlibrary(tidyverse)\n\nLoad the data.\n\nTrailRun1 &lt;- read.csv(\"~/DATA/data/TrailRun_PacYew.csv\")\nglimpse(TrailRun1)\n\nRows: 7,077\nColumns: 10\n$ X              &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ timestamp      &lt;chr&gt; \"2022-02-27 16:41:35\", \"2022-02-27 16:41:43\", \"2022-02-…\n$ position_lat   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ position_long  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ distance       &lt;int&gt; 0, 21, 24, 28, 32, 36, 41, 41, 51, 55, 59, 64, 68, 72, …\n$ altitude       &lt;dbl&gt; NA, 791.2, 790.8, 790.6, 790.4, 790.4, 790.0, 789.6, 78…\n$ cadence        &lt;int&gt; NA, 87, 86, 85, 84, 84, 85, 87, 87, 87, 87, 85, 85, 84,…\n$ speed          &lt;dbl&gt; NA, 2.58, 2.58, 2.92, 2.92, 3.34, 3.34, 3.78, 3.78, 4.0…\n$ temperature    &lt;int&gt; NA, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 24, 24, 24,…\n$ vertical_speed &lt;dbl&gt; NA, -0.02, -0.04, -0.06, -0.06, -0.08, -0.10, -0.10, -0…\n\n\nMake a Northern California polygon for iNaturalist, pull in the data and take look.\n\nbounds &lt;- c(40.194, -124.4323, 42.0021, -120)\nspecies &lt;- c(\"taxus brevifolia\")\npacyew_iNat &lt;- get_inat_obs(query = species, bounds = bounds, maxresults = 1000, quality = \"research\")\ndim(pacyew_iNat)\n\n[1] 285  37\n\n\nI had one of the newest observations of this species in the data set. My username is rjcmarkelz.\n\nglimpse(pacyew_iNat)\n\nRows: 285\nColumns: 37\n$ scientific_name                  &lt;chr&gt; \"Taxus brevifolia\", \"Taxus brevifolia…\n$ datetime                         &lt;chr&gt; \"2024-03-14 09:53:00 -0700\", \"2024-02…\n$ description                      &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ place_guess                      &lt;chr&gt; \"Willow Creek, CA, USA\", \"Shasta-Trin…\n$ latitude                         &lt;dbl&gt; 40.90617, 41.13873, 41.23730, 41.1107…\n$ longitude                        &lt;dbl&gt; -123.7070, -122.1695, -122.2685, -123…\n$ tag_list                         &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ common_name                      &lt;chr&gt; \"Pacific yew\", \"Pacific yew\", \"Pacifi…\n$ url                              &lt;chr&gt; \"https://www.inaturalist.org/observat…\n$ image_url                        &lt;chr&gt; \"https://inaturalist-open-data.s3.ama…\n$ user_login                       &lt;chr&gt; \"colmanbc\", \"taradurb\", \"herbaljunkie…\n$ id                               &lt;int&gt; 202457147, 200553158, 197615086, 1933…\n$ species_guess                    &lt;chr&gt; \"Taxus brevifolia\", \"Pacific yew\", \"P…\n$ iconic_taxon_name                &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ taxon_id                         &lt;int&gt; 55209, 55209, 55209, 55209, 55209, 55…\n$ num_identification_agreements    &lt;int&gt; 1, 2, 3, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2…\n$ num_identification_disagreements &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ observed_on_string               &lt;chr&gt; \"2024/03/14 9:53 AM\", \"2024-02-24 13:…\n$ observed_on                      &lt;chr&gt; \"2024-03-14\", \"2024-02-24\", \"2023-09-…\n$ time_observed_at                 &lt;chr&gt; \"2024-03-14 16:53:00 UTC\", \"2024-02-2…\n$ time_zone                        &lt;chr&gt; \"Pacific Time (US & Canada)\", \"Pacifi…\n$ positional_accuracy              &lt;int&gt; 218, 4, 179, 100, 5005, 4, 9, 10, 4, …\n$ public_positional_accuracy       &lt;int&gt; 218, 4, 179, 100, 5005, 4, 9, 10, 4, …\n$ geoprivacy                       &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ taxon_geoprivacy                 &lt;chr&gt; \"open\", \"open\", \"open\", \"open\", \"open…\n$ coordinates_obscured             &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"…\n$ positioning_method               &lt;chr&gt; \"\", \"\", \"gps\", \"\", \"\", \"\", \"\", \"\", \"\"…\n$ positioning_device               &lt;chr&gt; \"\", \"\", \"gps\", \"\", \"\", \"\", \"\", \"\", \"\"…\n$ user_id                          &lt;int&gt; 4765474, 4070907, 7728335, 2101146, 3…\n$ user_name                        &lt;chr&gt; \"colmanbc\", \"Tara Durboraw\", \"\", \"Zan…\n$ created_at                       &lt;chr&gt; \"2024-03-14 22:04:15 UTC\", \"2024-02-2…\n$ updated_at                       &lt;chr&gt; \"2024-03-15 01:08:03 UTC\", \"2024-02-2…\n$ quality_grade                    &lt;chr&gt; \"research\", \"research\", \"research\", \"…\n$ license                          &lt;chr&gt; \"CC-BY-NC\", \"\", \"CC-BY-NC\", \"CC-BY-NC…\n$ sound_url                        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ oauth_application_id             &lt;int&gt; NA, 3, 2, 3, 333, 3, 3, 3, NA, NA, NA…\n$ captive_cultivated               &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"…\n\nhead(pacyew_iNat$user_login, 10)\n\n [1] \"colmanbc\"      \"taradurb\"      \"herbaljunkies\" \"zanethebrain\" \n [5] \"paige15\"       \"mikhela\"       \"danjuel\"       \"zanethebrain\" \n [9] \"mikhela\"       \"mikhela\"      \n\n\nHere is my image that I uploaded. I had a species confirmation from the community within 12 hours.\n\nQuick map to show all the observations.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(TrailRun1[ , c(\"position_long\", \"position_lat\")], pch = \".\", col = \"red\", cex = 3)\npoints(pacyew_iNat[ , c(\"longitude\", \"latitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\n\n\n\n\nMake a quick plot to show the overlay of the run data and the coordinates of the image I took shown as a red dot.\n\ntr_plot1 &lt;- ggplot(TrailRun1, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point() +\n                    ylab(\"Latitude\") + xlab(\"Longitude\") + \n                 geom_point(aes(x=-122.1683, y=41.120),color=\"red\", size = 5)\ntr_plot1"
  },
  {
    "objectID": "posts/2024-10-05-MontologyJournalZinesYear38.html",
    "href": "posts/2024-10-05-MontologyJournalZinesYear38.html",
    "title": "Montology - Year 38",
    "section": "",
    "text": "Montology Studios creates illustrated Zines and media around the theme of mountains and culture. Think of this Zine as a cross between National Geographic, punk rock, adventure, natural history and data science.\nMy first larger Zine issues (40+ pages) are collected illustrated monthly journal entries.\nThis issue covers Year 38- August 2022-2023. The other two published issues cover the periods between Year 37- August 2021-July 2022 and Year 39- August 2023-July 2024.\nSign up for the newsletter to learn how to pre-order or check out the Etsy Shop to purchase copies of previous issues of the zine."
  },
  {
    "objectID": "posts/2023-05-19-blue-oak-fire.html",
    "href": "posts/2023-05-19-blue-oak-fire.html",
    "title": "Fire Ecology Class - 3",
    "section": "",
    "text": "Here is the second of the three zines I made for teaching wildfire science. This zine focused on the recent fire history of the Blue Oak Ranch Reserve where the class was held.\n\n\n\nA map of where Blue Oak Ranch Reserve is located in the state and the shape outline of it’s border.\n\n\n\n\nThe shape of the landscape helps define what plants can grow and provide the fuel load for fires. The topology of the landscape also heavily influences how fire spreads once started. As an example, steep slopes provide easier routes for fire to burn up slope compared to flat ground.\n\n\n\n\nBlue Oak Ranch Reserve plant composition of open grassland and denser oak woodland.\n\n\n\n\nTaking a state-wide perspective of fire history in the state of California.\n\n\n\n\nExamining the subset of fires across the state of California were purposefully started for controlled burning.\n\n\n\n\nA visualization of the controlled burns for parts of Blue Oak Ranch Reserve.\n\n\n\n\nThe 2020 SCU lightning complex fire burned half of the Blue Oak Ranch Reserve. Do you notice anything about the outline of the fire running along the middle of the reserve? Are there any topological features that would make this occur in a natural fire and also provide a natural boundary during a controlled burn?\n\n\n\n\nZooming back out to the state fire map you can see how large the 2020 SCU complex fire was. Less visible are the blue outlines of all of the reserves that make up the University of California Natural Reserve System."
  },
  {
    "objectID": "posts/2022-12-15-baja-species-3/index.html",
    "href": "posts/2022-12-15-baja-species-3/index.html",
    "title": "Baja Species 3",
    "section": "",
    "text": "Introduction\nI hiked in the Sierra de la Laguna National Park in Baja California Sur. The region is a biodiversity hotspot as very old mountains rise out of the sea above 6000’ elevation. There are a number of endemic species in this range. My previous posts were about the Caracara and the Cardon cacti. Below is a quick data visualization of the out and back hike we did along with some publicly available species observations.\n\nLoad the libraries\n\nlibrary(rgbif)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\nInfile the hiking data and make a plot.\n\nhike_data &lt;- read.csv(\"~/DATA/data/baja-hike.csv\")\n\nhike_plot1 &lt;- ggplot(hike_data, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point()\nhike_plot1\n\n\n\n\n\n\n\n\nBy taking the Latitude and Longitude limits of the hike, we can create a polygon to filter observations only falling within that shape.\n\nbaja_geometry &lt;- paste('POLYGON((-110.1 23.45, -110.00 23.45, -110.00 23.55, -110.1 23.55, -110.1 23.45))')\n\nPull in some observations of our new Caracara friends.\n\ncaracara &lt;- occ_data(scientificName = \"Caracara plancus\", hasCoordinate = TRUE, limit = 10000,\n                     geometry = baja_geometry )\n\ncaracara_coords &lt;- caracara$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nSubset world maps for Mexico. Plot the hiking data and publically available Caracara observations.\n\nworld_maps &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nmexico &lt;- subset(world_maps, name == \"Mexico\")\n\ntheme_set(theme_bw())\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = hike_data, aes(x = position_long, y = position_lat), color = 'black') +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue')\n\n\n\n\n\n\n\n\nZoom into the hiking region by changing the coordinate limits in the coord_sf() arguments.\n\n# zoom in\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = hike_data, aes(x = position_long, y = position_lat), color = 'black', shape = 3) +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red', shape = 4) +\n        coord_sf(xlim = c(-110.1, -110.0), ylim = c(23.45, 23.56), expand = TRUE) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")\n\n\n\n\n\n\n\n\nBeautiful!\nNow to see a random sampling of what other species are also in the area of the hike.\n\nspecies &lt;- occ_data(hasCoordinate = TRUE, limit = 1000,\n                       geometry = baja_geometry )\n\nspecies_coords &lt;- species$data[ , c(\"scientificName\",\"phylum\", \"order\", \"family\", \"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nPlot the hike data, Caracara data, and other species data on the same map. I changed the size of the hiking and Caracara points so they are easier to see. I also just plotted things by Phylum as to not overload the plot.\n\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = hike_data, aes(x = position_long, y = position_lat), color = 'black', size = 5, shape = 3) +\n        geom_point(data = caracara_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red', size = 6, shape = 4) +\n        geom_point(data = species_coords, aes(x = decimalLongitude, y = decimalLatitude, color = phylum)) +\n        coord_sf(xlim = c(-110.1, -110.0), ylim = c(23.45, 23.56), expand = TRUE) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")\n\n\n\n\n\n\n\n\nYou can see that there are various species to explore representing Arthropods (Insects, Spiders etc.), Cordates (Animals), Bisidomycota (fungi), and Tracheophyta (vascular plants). Also, a majority of the observations are on the trail itself. This shows one of the main limitations of this publicly available data, that it is not randomly collected. That is of course not to say it is not useful! It is still very useful. A lot to explore in another post!"
  },
  {
    "objectID": "posts/2025-07-15-RedGreenColorblind.html",
    "href": "posts/2025-07-15-RedGreenColorblind.html",
    "title": "Red Green Color Blind",
    "section": "",
    "text": "Mount Shasta from Gray Butte - Green Red Colorblind Trail Run- July 2025\nSam Merano and I did an adventure day to start at the Horse Camp Trail Head, summiting Green Butte, Red Butte, and then Gray Butte in one big loop back to Horse Camp. Most of the snow had melted, but we got some good glissading down the steep sections off Green Butte into Old Ski Bowl. We stopped to fill up our water at a spring before heading over to Red Butte.\nRed Butte was the most adventurous part of the run because neither of us knew the trail-less route around the steep faces. We contoured around and found a spot that looked climbable. We left our running poles and climbed up a gully that had some trees growing in it. This was not ideal! The gully led up to a false summit. We eventually wandered around on the top of the butte and found the actual summit. Great views!\nWe found a less treacherous way down on the southeast side of Red Butte. We contoured around to collect our poles before overlanding towards Gray Butte. Once we met up with the main Gray Butte Trail, the rest of the trip was on trails we were familiar with. We summited Gray Butte and then headed back down and back up to Old Ski Bowl to take the Snow Bunny Trail back to the Bunny Flat Trailhead. My watch glitched a little because I hit stop with my wrist while climbing up the gully on Red Butte, but ~25 km, 5 hours, 1600 m gain/loss all above 2,130 m in elevation. A great day out!"
  },
  {
    "objectID": "posts/2024-10-25-CodyMarkelzNaturalProcessesGalleryShow.html",
    "href": "posts/2024-10-25-CodyMarkelzNaturalProcessesGalleryShow.html",
    "title": "Natural Processes",
    "section": "",
    "text": "I will be doing a gallery show that opens Saturday November 9th at Darmera Gallery in Dunsmuir, CA. The show comes out of a desire to make physical manifestations of some of the digital art that I created over the past few years. I will write more about the process details with examples after the show opens, but the show focuses on a series of pinecone illustrations I did that are associated with various blog posts. If you are a reader of the blog, you will recognize the shapes and physical versions of these images. Nature is a common theme in my art and this show is very much about the process of making that art. Hence the show title: Natural Processes.\nSneak Peak of Images: Sugarpine Cone Foxtail Pine Cone"
  },
  {
    "objectID": "posts/2024-04-25-UnitedBicycleInstituteAdvancedClasses.html",
    "href": "posts/2024-04-25-UnitedBicycleInstituteAdvancedClasses.html",
    "title": "Certified Fox Suspension Technician + DT Swiss Wheelbuilder",
    "section": "",
    "text": "I have been riding, racing, and wrenching on my own bikes since I was in grade school. I decided to take my bike mechanic skills to the next level. Last fall I completed the Professional Mechanics class at United Bicycle Institute in Ashland, Oregon to become a Certified Bicycle Mechanic. This month I completed the the continued learning certification classes including advanced suspension, Fox suspension, DT Swiss wheel building, disc brakes, and dropper posts. Another 8 days of great instruction at United Bicycle Institute. I built a set of wheels from scratch that passed at 84.5 out of 100 possible points. Anything over 75 points is deemed a passing/sell-able wheel-set in a shop by DT Swiss. It was hard working under a time crunch and I got dinged because I went up to working tension too soon on my front wheel and had a radial hiccup just under 0.4 mm that was hard to get any better (80/100). My back wheel was much better because I took more time to set it up (89/100). The instructor comment was “Nice job. Add some spoke freeze and enjoy.” Only a few students out of 12 passed this class.\nOn the suspension side we worked on 6 different kinds over the 4 days including brand new Fox forks. The tech inside these small compartments and the abuse they go through on a regular ride of a recreation rider blows my mind. It is amazing that they continue to work at all without regular maintenance. The higher end suspensions degrade in performance slow enough that it might not be apparent to the rider. So much engineering and physics to continue learning!"
  },
  {
    "objectID": "posts/2025-09-15-ShastaAlpineHutObservations.html",
    "href": "posts/2025-09-15-ShastaAlpineHutObservations.html",
    "title": "Shasta Alpine Hut",
    "section": "",
    "text": "The Sierra Club owns a large chunk of land (720 acres) on Mount Shasta that contains the Shasta Alpine Hut. The Shasta Alpine Hut (Formally Horse Camp Hut). This is my second season working up at the Shasta Alpine Hut. I spend my time hiking around the alpine, doing art, nature journaling, meditating, reading about alpine ecology, managing the hut, talking to tourists, working on trails, and cleaning the bathrooms. This year Caryn and I stayed up at the campsites around the hut. I collected hundreds of nature observations as part of my DIY masters in Alpine Ecology. I will publish them along with illustrations and nature comics next year, but until then here are few pages that are finished.\n\n\n\nWilkin’s Harebell is a rare plant only found in ~20 locations in California, many of those sites are located on Mount Shasta. There is a sub-population of these plants just up from the Alpine Hut that I visit on a regular basis during my shifts.\n\n\n\nI have a sit-spot in a grove of White Bark Pines where I go to nearly every time I am up at the Alpine Hut. There is a resident population of Clark’s Nutcrackers that have gotten used to me being there. I made many, many observations near and far of these wonderful corvids. Clark’s Nutcrackers are really smart and disperse the seeds of Whitebark Pine all over the mountain. Enjoy the comic!"
  },
  {
    "objectID": "posts/2023-09-28-explorer-exercise-4.html",
    "href": "posts/2023-09-28-explorer-exercise-4.html",
    "title": "Explorer Fitness - 4",
    "section": "",
    "text": "Introduction\nThis post will focus on heart rate training progress over time from last year to early this season to a recent personal record on the same 13.15 km (8.17 mile) course with ~300m (984 ft) of elevation gain and loss. The two efforts are Zone 3/4 efforts. I like this course because it is technical, has some climbing, and I have done it enough that I know my splits at certain portions of the run for how well I am doing.\nFrom my trained perspective, the heart rate zones (HRZs) break down as follows:\n\n&lt; 120 - Rest - Rest, recovery, daily living\n120-155 - Zone 1 - Nose breathing pace, all-day pace\n156-162 - Zone 2 - Avoid if possible, too hard for Zone 1, too easy for Zone 3\n163-173 - Zone 3 - 1.5-hour pace for me, or many shorter bursts\n174-184 - Zone 4 - Shorter HARD efforts\n185-195 - Zone 5 - Pushing max pace/effort\n\nLoad the relevent libraries.\n\nlibrary(FITfileR)\nlibrary(tidyverse)\nlibrary(patchwork)\n\nFor more information on each of the data import and processing steps, check out the previous post in this series.\nRead in the data for a single run, process it to create heart rate zones, make a color vector for consistent color displays and do some basic plotting.\nThe run below is a Zone3/Zone4 heart rate zone run. This is my fastest time to date on this route at 1:00:31.\n\nRunZone3_Sept &lt;- readFitFile(\"~/DATA/data/local-route-zone3-FKT.fit\") # load file\nRunZone3_Sept &lt;- records(RunZone3_Sept) %&gt;% bind_rows() %&gt;% arrange(timestamp)\n\nRunZone3_Sept$HRzone &lt;- cut(RunZone3_Sept$heart_rate,c(0,120,158,164,173,184, 200))\nlevels(RunZone3_Sept$HRzone) &lt;- c(\"R\",\"Z1\",\"Z2\",\"Z3\",\"Z4\",\"Z5\")\nRunZone3_Sept$seconds &lt;- as.numeric(rownames(RunZone3_Sept))\n\ncols3 &lt;- c(\"R\" = \"#d4d4d4\",  \"Z1\" = \"#5192cb\", \"Z2\" = \"#4cbd57\", \n          \"Z3\" = \"#e4e540\", \"Z4\"= \"#ffb217\", \"Z5\" = \"#ff5733\", \"NA\" = \"#454545\")\n\nz3_p &lt;- ggplot(RunZone3_Sept, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(limits = c(100, 200), name=\"Heart Rate (bpm)\") +\n      scale_color_manual(values = cols3) +\n      ggtitle(\"September 2023\")\nz3_p\n\n\n\n\n\n\n\n\nNow we can take a look at the elevation profile of the run. A majority of the gain is in the first 30 minutes of the run, then it is rolling hills with a net down for the rest of the run. The steepest sustained section nearly always ensures I am at the Zone 3/4 threshold.\n\nz3_p_alt &lt;- ggplot(RunZone3_Sept, aes(x=seconds,  y=altitude)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Elevation (m)\")\nz3_p_alt\n\n\n\n\n\n\n\n\n\nHow do I know that I am getting faster? We could just look at raw times, but we can also compare heart rate zones across time on the same course. This can give a better indication of how well my training is contributing to hard efforts over time.\nLoad and process the comparison run from September 2022.\n\nRunZone3_2022 &lt;- readFitFile(\"~/DATA/data/local-route-2022-2nd-place.fit\") # load file\nRunZone3_2022 &lt;- records(RunZone3_2022) %&gt;% bind_rows() %&gt;% arrange(timestamp)\n\nRunZone3_2022$HRzone &lt;- cut(RunZone3_2022$heart_rate,c(0,120,158,164,173,184, 200))\nlevels(RunZone3_2022$HRzone) &lt;- c(\"R\",\"Z1\",\"Z2\",\"Z3\",\"Z4\",\"Z5\")\nRunZone3_2022$seconds &lt;- as.numeric(rownames(RunZone3_2022))\n\nA quick comparison in times for each of the runs.\n\nmax(RunZone3_Sept$seconds) # September 2023\n\n[1] 3619\n\nmax(RunZone3_2022$seconds) # September 2022\n\n[1] 3718\n\n\n3619 seconds for September 2023 and 3718 seconds for September of last year.\nI have gotten faster in absolute terms, but have I gotten faster for a given heart rate? We will start to answer that question by looking at comparison plots between the runs.\nTo stack the plots we will use the Patchwork R package functions.\n\nz322_p &lt;- ggplot(RunZone3_2022, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(limits = c(100, 200), name=\"Heart Rate (bpm)\") +\n      scale_color_manual(values = cols3) +\n      ggtitle(\"September 2022\")\n\nstacked_plots &lt;- z3_p / z322_p +  plot_layout(ncol = 1, heights = c(10, 10))\nstacked_plots\n\n\n\n\n\n\n\n\n\nWe can take a look at the accumulated number of seconds spent in each of the various heart rate zones:\n\nz3_p2 &lt;- ggplot(RunZone3_Sept, aes(x=HRzone, fill=HRzone)) +\n      geom_bar(na.rm = TRUE) +\n      scale_y_continuous(limits = c(0, 1750), name=\"Seconds in HR Zone\") +\n      scale_fill_manual(values = cols3) + \n      scale_x_discrete(na.translate = FALSE) +\n      ggtitle(\"September 2023\")\n\nz322_p2 &lt;- ggplot(RunZone3_2022, aes(x=HRzone, fill=HRzone)) +\n      geom_bar(na.rm = TRUE) +\n      scale_y_continuous(limits = c(0, 1750), name=\"Seconds in HR Zone\") +\n      scale_fill_manual(values = cols3) + \n      scale_x_discrete(na.translate = FALSE) +\n      ggtitle(\"September 2022\")\n\nstacked_plots2 &lt;- z3_p2  / z322_p2 +  plot_layout(ncol = 1, heights = c(4, 4))\nstacked_plots2\n\n\n\n\n\n\n\n\nWith all the accumulated cardio training I can now run a faster time for this course with a much lower average heart rate and much less time of the run spent in Zone 4. My top time is spent mostly in Zone 3. This is in comparison to June 2023 which had more time spent in Zone 4.\nOverall, my fitness training is paying off!\n\nIf you are interested in other posts in this explorer series check out Explorer Fitness 1, Explorer Fitness 2, Explorer Fitness 3 and Trail Running Training."
  },
  {
    "objectID": "posts/2023-08-18-Data-Science-Academia-Career.html",
    "href": "posts/2023-08-18-Data-Science-Academia-Career.html",
    "title": "Academic Data Science Career Guide",
    "section": "",
    "text": "Academic Data Science Alliance (ADSA) Career Workshop Sketchnote. The sketchnote I illustrated above shows the major workflow of the meeting and this became the back cover illustration for the book!\nThe Academic Data Science Alliance (ADSA) and US Research Software Engineer Association (US-RSE) hosted a fall workshop on career tracks in 2022. We collectively wrote a career guide book which was just published: https://zenodo.org/record/8274378.\nBook Abstract: The importance of data, software, and computation has long been recognized in academia and is reflected in the recent rise of job opportunities for data scientists and research software engineers. Big data, for example, created a wave of novel job descriptions before the term Data Scientist (DS) was widely used. And even though software has become a major driver for research (Nangia and Katz, 2017), Research Software Engineer (RSE) as a formal role has lagged behind in terms of job openings, recognition, and prominence within the community. Despite their importance in the academic research ecosystem, the value of DS and RSE roles is not yet widely understood or appreciated in the academic community, and research data, software, and workflows are, in many domains, still regarded as by-products of research. Data Scientists and Research Software Engineers (DS/RSEs) face similar challenges when it comes to career paths in academia - both are non-traditional academic professions with few incentives and a lack of clear career trajectories. This guidebook presents the challenges and suggestions for solutions to improve the situation and to reach a wide community of stakeholders needed to advance career paths for DS/RSEs."
  },
  {
    "objectID": "posts/2025-01-30-January2025Review.html#montology",
    "href": "posts/2025-01-30-January2025Review.html#montology",
    "title": "January 2025 Review",
    "section": "Montology",
    "text": "Montology\nI came into Darmera early on a Saturday morning to box up a piece and deliver it locally to a buyer. When I pulled up to the entrance there were a few guys peeking in the window. I opened and invited them in. One of the guys really wanted one of the sold pieces still hanging on the wall. I said it was not for sale. He said what about for cash over asking price? I said yes of course! I boxed it up for him and off he went back to SF. The original buyer was a local and we had a handshake deal. I explained the situation to him, he congratulated me, and then I agreed to make him a new one at the original price as a commission. 5 pieces total sold from my show. :). Late in the month, I received a text message from one of the art buyers that the piece had arrived and a photo of my piece hanging in her living room in Philadelphia. I have sold art before, but I felt very proud of how far I have come as an artist in that moment. My art is on stranger’s walls in Philly and SF. Crazy!\nI finished up the layouts for the next three issues of my graphical essay series on exploring fire landscapes. The plan is to have these done and printed for an art opening in November. A non-profit reached out after hearing about this project. They have funding for these types of projects so I am going to be paid to do a series of lectures, field trips, and nature journaling classes that will proceed the gallery show.\nI spent a lot of time this month on gouache value studies. I am working on originals for the Pyroscapes project and to be displayed for the November opening. These also overlap with a near future gallery show that my business partner and I will do on small format plein air paintings."
  },
  {
    "objectID": "posts/2025-01-30-January2025Review.html#darmera",
    "href": "posts/2025-01-30-January2025Review.html#darmera",
    "title": "January 2025 Review",
    "section": "Darmera",
    "text": "Darmera\nI had 5 new students this month between the two classes I teach. We have been break even for the past 3 months and we will be profitable from February going forward after paying yearly business fees, insurance, and digital fees.\nWe are making some mini-painting kits out of old cigar boxes for small format plein air paintings. We have a list of sites picked out that we will start taking clients, but first we will paint at these locations and create marketing content for upcoming retreats. The paintings will make up a small format gallery show to have a pure profit summer show to shovel back into the business.\nWe had an art opening of student work from another art studio in town, Art Roster. It was fun to co-mingle the groups and make additional connections in the art community."
  },
  {
    "objectID": "posts/2025-01-30-January2025Review.html#movement",
    "href": "posts/2025-01-30-January2025Review.html#movement",
    "title": "January 2025 Review",
    "section": "Movement",
    "text": "Movement\nI completed the second 4 week training block that was co-designed by my coach (heading into the end of the rest week this weekend). I spent more days sleeping 9-10 hours a night and eating more protein (mostly supplemental pea protein shake). Going into this block I was well rested, but the last day of my rest week I went a little too hard. I paid for it immediately. I do not need coaching to go harder. I need coaching to go easier on rest and recovery days. The top of my Zone 2 is between 155-160 (nose breathing) depending how warmed up I am and accumulated fatigue. He keeps me in check because many hours of Zone 2 is too hard for me to recover from effectively. Everything clicked this training block. I skate skied 501 km and made massive deposits to the Zone1/Zone2 base bank. The block had increasingly big days at the end of the week. My last day I skied 100km in Zone1/Zone 2 in 6:45:30 with 1850 m gain/loss. I balanced this with ridiculously easy recovery days on the stationary bike (i.e. 90 bpm average). I have gotten way faster and efficient for a given heart rate. I look forward to harvesting some of these gains in early March at the end of the ski season. The game has completely changed for me because these past two blocks unlocked the mental discipline to go easier and put in the boring time for recovery days."
  },
  {
    "objectID": "posts/2025-01-30-January2025Review.html#community",
    "href": "posts/2025-01-30-January2025Review.html#community",
    "title": "January 2025 Review",
    "section": "Community",
    "text": "Community\nI volunteered for a local Ascension ski-mo race (up and down on skis). A friend and I lead the food prep for the post race party. It was fun to work in a large commercial kitchen at the venue and to see how willing various food vendors were to give out donations to support the event."
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html",
    "title": "Professional Bicycle Mechanic",
    "section": "",
    "text": "I have been riding, racing, and wrenching on my own bikes since I was in grade school. I decided to take my bike mechanic skills to the next level. This fall I completed the Professional Mechanics class at United Bicycle Institute in Ashland, Oregon. The instruction was excellent. The hands-ons were up-to-date for common technology. The course struck a great balance of lecture and hands-on application. The immersion with other bike nerds that were only thinking about bike mechanics is my preferred way to learn. I learned just as much from other students/mechanics as I did from the instructors. The hands-ons rotated partners and benches each day simulating a real shop environment. We would often end the day with a deconstruction of a component, lay everything out, and then come back the next day to a new bench with a different layout!\nAlways be knollin’\nThey teach the class as sub-systems that interact to give you the larger bike/rider/environment systems. This style of teaching helps you build intuition for what might be wrong given a few key hints (even a few steps up or down stream).\nI filled an entire sketchbook with sketchnotes during the course. I plan to do a detailed series of posts on each of the following sections and the hands-on sections with my relevant sketchnotes (see examples below)."
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#mechanical-properties",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#mechanical-properties",
    "title": "Professional Bicycle Mechanic",
    "section": "1 - Mechanical Properties",
    "text": "1 - Mechanical Properties"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#bearings",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#bearings",
    "title": "Professional Bicycle Mechanic",
    "section": "2 - Bearings",
    "text": "2 - Bearings"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#hubs",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#hubs",
    "title": "Professional Bicycle Mechanic",
    "section": "3 - Hubs",
    "text": "3 - Hubs"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#wheels-building-and-service",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#wheels-building-and-service",
    "title": "Professional Bicycle Mechanic",
    "section": "4 - Wheels, Building and Service",
    "text": "4 - Wheels, Building and Service"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#tires-and-tubes",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#tires-and-tubes",
    "title": "Professional Bicycle Mechanic",
    "section": "5 - Tires and Tubes",
    "text": "5 - Tires and Tubes"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#pedals",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#pedals",
    "title": "Professional Bicycle Mechanic",
    "section": "6 - Pedals",
    "text": "6 - Pedals"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#crankset-bottom-brackets-chainrings",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#crankset-bottom-brackets-chainrings",
    "title": "Professional Bicycle Mechanic",
    "section": "7 - Crankset, Bottom Brackets, Chainrings",
    "text": "7 - Crankset, Bottom Brackets, Chainrings"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#fixed-gear-freewheel-freehub-cassette",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#fixed-gear-freewheel-freehub-cassette",
    "title": "Professional Bicycle Mechanic",
    "section": "8 - Fixed Gear, Freewheel, Freehub & Cassette",
    "text": "8 - Fixed Gear, Freewheel, Freehub & Cassette"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#chains",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#chains",
    "title": "Professional Bicycle Mechanic",
    "section": "9 - Chains",
    "text": "9 - Chains"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#derailleurs",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#derailleurs",
    "title": "Professional Bicycle Mechanic",
    "section": "10 - Derailleurs",
    "text": "10 - Derailleurs"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#rim-brakes",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#rim-brakes",
    "title": "Professional Bicycle Mechanic",
    "section": "11 - Rim Brakes",
    "text": "11 - Rim Brakes"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#hub-brakes",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#hub-brakes",
    "title": "Professional Bicycle Mechanic",
    "section": "12 - Hub Brakes",
    "text": "12 - Hub Brakes"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#headsets",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#headsets",
    "title": "Professional Bicycle Mechanic",
    "section": "13 - Headsets",
    "text": "13 - Headsets"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#suspension",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#suspension",
    "title": "Professional Bicycle Mechanic",
    "section": "14 - Suspension",
    "text": "14 - Suspension"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#frame-materials-and-construction",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#frame-materials-and-construction",
    "title": "Professional Bicycle Mechanic",
    "section": "15 - Frame Materials and Construction",
    "text": "15 - Frame Materials and Construction"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#contact-points",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#contact-points",
    "title": "Professional Bicycle Mechanic",
    "section": "16 - Contact Points",
    "text": "16 - Contact Points"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#shop-operation-and-industry",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#shop-operation-and-industry",
    "title": "Professional Bicycle Mechanic",
    "section": "17 - Shop Operation and Industry",
    "text": "17 - Shop Operation and Industry"
  },
  {
    "objectID": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#final-hands-on-day",
    "href": "posts/2023-12-20-UnitedBicycleInstituteProClass.html#final-hands-on-day",
    "title": "Professional Bicycle Mechanic",
    "section": "Final hands on day",
    "text": "Final hands on day\nTake ticket from your service writing, do full road bike inspection, complete deconstruction (wheels, hubs, brakes, handlebars, cables/housing, derailleurs, cassette, chainring, bottom bracket, etc.). Repack bearings, reassemble wheels, true wheels (&lt;1mm tolerance) and fully reassemble bike within spec in allotted time (6 hours).\nThere was an odd number of students so one student was always working alone. I was chosen to work alone on the overhaul day. I finished up and got checked off only 10 minutes behind the faster students that were working in a team! WhooAHHH!\nFinal written test: 100 multiple choice questions in 90 minutes. Open note, but 275 pages of text to pull specific answers from!!! No practice tests.\n75 to pass, I got an 88!\nI have to say this was a challenging test as it was VERY specific with ~54 seconds a question. My dyslexic brain had a hard time with some of the questions under such a time crunch (e.g. double negatives –&gt; cross reference 2 look up tables).\nI am now a UBI Certified Bicycle Mechanic."
  },
  {
    "objectID": "posts/2023-09-01-explorer-exercise-3.html",
    "href": "posts/2023-09-01-explorer-exercise-3.html",
    "title": "Explorer Fitness - 3",
    "section": "",
    "text": "Introduction\nI have discussed the importance of targeted heart-rate zone training numerous times before. This post will show three different trail running workouts on the same 13.15 km (8.17 mile) course with ~300m (984 ft) of elevation gain and loss. The route is an out and back lollipop loop with a majority of the climbing in the first half of the run. The route is a regular workout distance for me and I currently have 54 attempts accumulated over a few years. This provides ample data to look at trends over time and to compare different types of workouts over the same distance.\nFrom my trained perspective, the heart rate zones break down as follows:\n\n120-155 - Zone 1 - Nose breathing pace, all-day pace\n156-162 - Zone 2 - Avoid if possible, too hard for Zone 1, too easy for Zone 3\n163-173 - Zone 3 - 1.5-hour pace for me, or many shorter bursts\n174-184 - Zone 4 - Shorter HARD efforts\n185-195 - Zone 5 - Pushing max pace/effort\n\nWith that background out of the way let’s load the libraries.\n\n# Install Fit File Reader if not already installed\nif(!requireNamespace(\"remotes\")) {\n   install.packages(\"remotes\")\n}\nremotes::install_github(\"grimbough/FITfileR\")\n\n\nlibrary(FITfileR)\nlibrary(tidyverse)\n\nPull in a Zone 1 workout, arrange it by time-stamp and plot the latitude and longitude (removing exact coordinates).\n\nRunZone1 &lt;- readFitFile(\"~/DATA/data/local-route-zone1.fit\") # load file\nRunZone1 &lt;- records(RunZone1) %&gt;% bind_rows() %&gt;% arrange(timestamp)\n\n\n\nLocalRunplot1 &lt;- ggplot(RunZone1, aes(x = position_long, y = position_lat)) +\n                      coord_quickmap() + \n                      geom_point() + \n                      theme(axis.text.x=element_blank(),\n                      axis.ticks.x=element_blank(),\n                      axis.text.y=element_blank(),\n                      axis.ticks.y=element_blank() \n                      )\nLocalRunplot1\n\n\n\n\n\n\n\n\nThe heart rate zones do not record on the watch, only the heart rate values at each second interval. Here we make a new variable that is defined by the heart rate zones mentioned in the introduction. I add a manual color vector for the plotting so that all the plots are consistent with one another and with previous posts. And finally, just to keep things tidy, I also add a seconds column of data.\n\nRunZone1$HRzone &lt;- cut(RunZone1$heart_rate,c(0,120,158,164,173,184, 200))\nlevels(RunZone1$HRzone) &lt;- c(\"R\",\"Z1\",\"Z2\",\"Z3\",\"Z4\",\"Z5\")\ncols3 &lt;- c(\"R\" = \"#d4d4d4\",  \"Z1\" = \"#5192cb\", \"Z2\" = \"#4cbd57\", \n          \"Z3\" = \"#e4e540\", \"Z4\"= \"#ffb217\", \"Z5\" = \"#ff5733\", \"NA\" = \"#454545\")\nRunZone1$seconds &lt;- as.numeric(rownames(RunZone1))\n\nNow we can plot the entire workout and color it by the heart rate zones. This workout is primarily a Zone 1 workout, so you can see that most of the time is spent in Zone 1 (blue).\n\nz1_p &lt;- ggplot(RunZone1, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Heart Rate (Beats Per Minute)\") +\n      scale_color_manual(values = cols3)\nz1_p\n\n\n\n\n\n\n\n\nHere I do the same process as above for a Zone 1/Zone 2 workout. The plot shows a shift to the higher end of Zone 1 with more Zone 2.\n\nRunZone2 &lt;- readFitFile(\"~/DATA/data/local-route-zone1-2.fit\") # load file\nRunZone2 &lt;- records(RunZone2) %&gt;% bind_rows() %&gt;% arrange(timestamp)\n\nRunZone2$HRzone &lt;- cut(RunZone2$heart_rate,c(0,120,158,164,173,184, 200))\nlevels(RunZone2$HRzone) &lt;- c(\"R\",\"Z1\",\"Z2\",\"Z3\",\"Z4\",\"Z5\")\nRunZone2$seconds &lt;- as.numeric(rownames(RunZone2))\n\nz2_p &lt;- ggplot(RunZone2, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Heart Rate (Beats Per Minute)\") +\n      scale_color_manual(values = cols3)\nz2_p\n\n\n\n\n\n\n\n\nThe run below is a Zone3/Zone4 heart rate zone run. This is my fastest time to date on this route at 1:00:31. I am shooting for a sub 1 hour next time I do a hard effort like this! The heart rate zones are shifted all the way up into Zone 3 (yellow) and Zone 4 (orange) with a few times I tipped into Zone 5.\n\nRunZone3 &lt;- readFitFile(\"~/DATA/data/local-route-zone3-FKT.fit\") # load file\nRunZone3 &lt;- records(RunZone3) %&gt;% bind_rows() %&gt;% arrange(timestamp)\n\nRunZone3$HRzone &lt;- cut(RunZone3$heart_rate,c(0,120,158,164,173,184, 200))\nlevels(RunZone3$HRzone) &lt;- c(\"R\",\"Z1\",\"Z2\",\"Z3\",\"Z4\",\"Z5\")\nRunZone3$seconds &lt;- as.numeric(rownames(RunZone3))\n\nz3_p &lt;- ggplot(RunZone3, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Heart Rate (Beats Per Minute)\") +\n      scale_color_manual(values = cols3)\nz3_p\n\n\n\n\n\n\n\n\n\nWe will do some detailed comparisons in another post, but here we can make plots of the heart rate data as the number of seconds in each heart rate zone.\n\nz1_p2 &lt;- ggplot(RunZone1, aes(x=HRzone, fill=HRzone)) +\n      geom_bar() +\n      scale_y_continuous(name=\"Total Seconds in Heart Rate Zone\") +\n      scale_fill_manual(values = cols3)\n\n\nz2_p2 &lt;- ggplot(RunZone2, aes(x=HRzone, fill=HRzone)) +\n      geom_bar() +\n      scale_y_continuous(name=\"Total Seconds in Heart Rate Zone\") +\n      scale_fill_manual(values = cols3)\n\n\nz3_p2 &lt;- ggplot(RunZone3, aes(x=HRzone, fill=HRzone)) +\n      geom_bar() +\n      scale_y_continuous(name=\"Total Seconds in Heart Rate Zone\") +\n      scale_fill_manual(values = cols3)\n\nThese really show the shift from Zone 1 –&gt; Zone 1/2 –&gt; Zone 3/4. Plot them all and scroll down to compare.\n\nz1_p2\n\n\n\n\n\n\n\nz2_p2\n\n\n\n\n\n\n\nz3_p2\n\n\n\n\n\n\n\n\nWe will revisit these data to do more comparisons over the different parts of the workout course. If you are interested in other posts in this explorer series check out Explorer Fitness 1, Explorer Fitness 2, and Trail Running Training."
  },
  {
    "objectID": "posts/2024-07-08-BikeWrenchIssue1.html",
    "href": "posts/2024-07-08-BikeWrenchIssue1.html",
    "title": "Montology Zines - Bike Wrench Issue 1.0",
    "section": "",
    "text": "I have a lifelong passion for riding and wrenching on bicycles. This zine series documents my journey from amateur to professional bicycle mechanic to repair shop owner: Montology Bicycle Repair.\nI have a scientific research background in quantitative biology and statistical modeling biological processes. I use a scientific lens to try understanding how components work through physics and how to develop mathematical models of how the components work in isolation and together as a larger system. This issue follows the lessons that are taught at the United Bicycle Institute Professional Bike Mechanic Class. There are scientific principles underlying all of the lessons contained in this class, but the class was much more hands on. This series will bounce back and forth between theory and application. You as the reader will be able to follow along my development as a bicycle mechanic and working through the underlying physics, mechanical engineering and design thinking principles around bicycles.\nOther bike mechanic posts:\nUBI Pro Class Post\nUBI Certified Fox Suspension Technician + DT Swiss Wheelbuilder Post\n\nMontology Studios creates illustrated Zines and media around the theme of mountains and culture. Think of this Zine as a cross between National Geographic, punk rock, adventure, natural history and data science. Each zine has a specific sub-theme. Some previous themes have been trail running, fire ecology, adventure vans, and frugality.\nSign up for the newsletter to learn how to pre-order or check out the Etsy Shop to purchase copies of previous issues of the zine."
  },
  {
    "objectID": "posts/2022-08-01-drseussplant/index.html",
    "href": "posts/2022-08-01-drseussplant/index.html",
    "title": "Mount Shasta Wilderness Wildflowers",
    "section": "",
    "text": "I went on a quick overnight to a spring fed creek above 8000 feet on Mount Shasta. I noticed these interesting flowers that I have never seen before. They reminded me of something that Dr. Seuss would have illustrated in his various children’s books. After searching the internet with no luck I finally needed rely on some California Botany experts to help with the ID: Anemone occidentalis. The hair-like calyx tissue on top of each ovary are what give this plant it’s unique look once reproductively mature. These are similar structures to white dandelion heads and aid in seed dispersal via wind.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(rgbif)\nlibrary(gpx)\n\nMake the large Northern California polygon to look for observations in GBIF.\n\nnorcal_geometry &lt;- paste('POLYGON((-124.4323 42.0021, -121.5045 42.0021, -121.5045 40.194, -124.4323 40.194, -124.4323 42.0021))')\n\ndr_seuss &lt;- occ_data(scientificName = \"Anemone occidentalis\", hasCoordinate = TRUE, limit = 1000,\n                   geometry = norcal_geometry)\n# length(dr_seuss)\nhead(dr_seuss)\n\n$meta\n$meta$offset\n[1] 0\n\n$meta$limit\n[1] 300\n\n$meta$endOfRecords\n[1] TRUE\n\n$meta$count\n[1] 44\n\n\n$data\n# A tibble: 44 × 114\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1 40229… Anemon…    41.4   -122. cdc    b05154… a8a2b5… cb27a4… US      DWC_AR…\n 2 40229… Anemon…    41.4   -122. cdc    b05154… a8a2b5… cb27a4… US      DWC_AR…\n 3 40229… Anemon…    41.4   -122. cdc    b05154… a8a2b5… cb27a4… US      DWC_AR…\n 4 89974… Anemon…    41.6   -123. cdc,c… 7a2660… 0674ae… 6038e5… DE      BIOCASE\n 5 24179… Anemon…    40.5   -122. cdc,a… ae33dc… c6e100… cb27a4… US      DWC_AR…\n 6 29820… Anemon…    41.2   -123. cdc,c… 695862… c10e9f… cb27a4… US      DWC_AR…\n 7 33207… Anemon…    41.5   -122. cdc,g… 677aec… 314e47… cb27a4… US      DWC_AR…\n 8 33207… Anemon…    41.2   -123. cdc,g… 677aec… 314e47… cb27a4… US      DWC_AR…\n 9 33207… Anemon…    41.5   -123. cdc,g… 677aec… 314e47… cb27a4… US      DWC_AR…\n10 29820… Anemon…    41.6   -123. cdc,g… 695862… c10e9f… cb27a4… US      DWC_AR…\n# … with 34 more rows, 104 more variables: lastCrawled &lt;chr&gt;, lastParsed &lt;chr&gt;,\n#   crawlId &lt;int&gt;, hostingOrganizationKey &lt;chr&gt;, basisOfRecord &lt;chr&gt;,\n#   occurrenceStatus &lt;chr&gt;, taxonKey &lt;int&gt;, kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;,\n#   classKey &lt;int&gt;, orderKey &lt;int&gt;, familyKey &lt;int&gt;, genusKey &lt;int&gt;,\n#   speciesKey &lt;int&gt;, acceptedTaxonKey &lt;int&gt;, acceptedScientificName &lt;chr&gt;,\n#   kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   species &lt;chr&gt;, genericName &lt;chr&gt;, specificEpithet &lt;chr&gt;, taxonRank &lt;chr&gt;, …\n\n\nQuick map of observations in Northern California. There are a few observations across the general bioregion I live near, but none on the hike I went on.\n\ndr_seuss_coords &lt;- dr_seuss$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n\nmaps::map(database = \"state\", region = \"california\")\npoints(dr_seuss_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\n\n\n\n\nPull in my hike data using the gpx R library and subset the route to make plotting easier.\n\nhike &lt;-  read_gpx('~/DATA/data/mount_shasta_hiking.gpx')\nhike1 &lt;- as.data.frame(hike$routes)\n\nOverlay the hiking data and the image/observation coordinates as a triangle.\n\nhike_plot2 &lt;- ggplot() +\n          coord_quickmap() +\n          geom_point(data = hike1, aes(x = Longitude, y = Latitude), color = 'black') +\n          geom_point(aes(x = -122.19, y = 41.36325), pch=25, size= 5, colour=\"purple\") +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nhike_plot2"
  },
  {
    "objectID": "posts/2022-04-15-sugar-pine-trail-run/index.html",
    "href": "posts/2022-04-15-sugar-pine-trail-run/index.html",
    "title": "Sugar Pine (Pinus lambertiana)",
    "section": "",
    "text": "Another species found! I am attempting to ID all the conifer species that occur in the Miracle Mile while out on runs so I can make a visit to the Miracle Mile and ID all of them in one go.\n\n\n\nThese sugar pine cones are huge! I have a few in my pinecone collection that are greater than 35 cm! Sugar pines (Pinus lambertiana) are fairly common species and I see them on trail runs often. For this post I first pulled the observations from GBIF, plotted them, and then looked where I had recently ran that would overlap with the species observation data. In this case, it was on a section of the Pacific Crest Trail (PCT) that I did an out and back run on.\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(maps)\n\nSubset our search to only Northern California\n\nmm_geometry &lt;- paste('POLYGON((-124.4323 42.0021, -121.5045 42.0021, -121.5045 40.194, -124.4323 40.194, -124.4323 42.0021))')\n\nPull in the publicly available data and make a few quick plots.\n\npinus_lambertiana_NC &lt;- occ_data(scientificName = \"Pinus lambertiana\", hasCoordinate = TRUE, limit = 10000,\n                     geometry = mm_geometry )\nhead(pinus_lambertiana_NC)\n\n$meta\n$meta$offset\n[1] 300\n\n$meta$limit\n[1] 2\n\n$meta$endOfRecords\n[1] TRUE\n\n$meta$count\n[1] 302\n\n\n$data\n# A tibble: 302 × 120\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1 40463… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 2 40463… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 3 34993… Pinus …    41.9   -124. cdc    50c950… 28eb1a… 997448… US      DWC_AR…\n 4 37057… Pinus …    41.5   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 5 37053… Pinus …    41.2   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 6 37472… Pinus …    40.9   -124. cdc    50c950… 28eb1a… 997448… US      DWC_AR…\n 7 37598… Pinus …    41.8   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 8 39613… Pinus …    40.4   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 9 37642… Pinus …    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n10 37603… Pinus …    41.9   -124. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n# … with 292 more rows, 110 more variables: lastCrawled &lt;chr&gt;,\n#   lastParsed &lt;chr&gt;, crawlId &lt;int&gt;, hostingOrganizationKey &lt;chr&gt;,\n#   basisOfRecord &lt;chr&gt;, occurrenceStatus &lt;chr&gt;, taxonKey &lt;int&gt;,\n#   kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;, classKey &lt;int&gt;, orderKey &lt;int&gt;,\n#   familyKey &lt;int&gt;, genusKey &lt;int&gt;, speciesKey &lt;int&gt;, acceptedTaxonKey &lt;int&gt;,\n#   acceptedScientificName &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;,\n#   family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;, genericName &lt;chr&gt;, …\n\npinus_lambertiana_coords &lt;- pinus_lambertiana_NC$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n\nmaps::map(database = \"state\", region = \"california\")\npoints(pinus_lambertiana_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\n\n\n\n\nPull in my run data.\n\nTrailRun1  &lt;- read.csv(\"~/DATA/data/TrailRun_SugarPine.csv\")\n\nMake a quick plot.\n\nTrailRun_plot &lt;- ggplot(TrailRun1, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point() +\n                    xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot\n\n\n\n\n\n\n\n\nSubset the larger California dataset to only include a zoomed in portion where I ran based on the maximum and minimum coordinates from the run plot above.\n\npinus_lamb_coords_sub &lt;- subset(pinus_lambertiana_coords, decimalLatitude &gt; 41.1525 & decimalLatitude &lt; 41.1650 & decimalLongitude &gt; -122.295 & decimalLongitude &lt; -122.265 )\n\nOverlay the plots!\n\nTrailRun_plot2 &lt;- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = position_long, y = position_lat), color = 'black') +\n          geom_point(data=pinus_lamb_coords_sub, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot2"
  },
  {
    "objectID": "posts/2022-10-01-slacmethodforcomics/index.html",
    "href": "posts/2022-10-01-slacmethodforcomics/index.html",
    "title": "SLAC Method for Comics Creation",
    "section": "",
    "text": "I have been listening to the Making Comics podcast for the last few years. The creators are diehard indie comic book creators that are inspiring in how they meet deadlines for their art projects while also holding down full time jobs, going to comic conventions, and spending an absurd amount of time discussing basketball stats. Fortunately, they moved the non-comics stuff to the end of the show so it is easily skipped.\nOne of the co-creators of the show Scott Lost developed a method for comics creation he calls the SLAC method. It stands for the Scott Lost Advanced Cartooning Method. It works really well as a digital comics creation workflow. The idea is to take a comic script and thumbnail out the entire issue in one go including panels on an 8 page thumbnail sheet. I made a template example below. You can download a free .psd file version from my Gumroad Page. If you want to set up your own sheet the dimensions are 300 dpi, 5100 pixels long by 3300 pixels wide. This is a standard comic art page size (11 x 17 inches) turned on its side. I added in the blue line page guides for all 8 pages including the bleed and trim areas. After the thumbnails are completed you can finish the panel layouts and start working on the rough pencils stage on another layer. The pencils layer can then be copied over and appropriately scaled into a final inks/line work file. The final step is finishing the comic coloring and lettering.\n\n\n\nThe magic of the method though is that by doing all of the layouts ahead of time, you can work on whatever you feel motivated to work on each day knowing that the main story elements are already taken care of. This helps break out of the funks of only making sequential art… well… sequentially. Do not feel like working on backgrounds? No problem work on characters. Really digging working on your character’s expression? Only work on that today. It allows you to hop around the entire issue and work on like category drawings always keeping the stoke high and potentially staying more consistent in the art across the issue.\nAn example of the method in action from my upcoming Cartographer exploration and adventure book (stay tuned!)."
  },
  {
    "objectID": "posts/2023-06-30-cyanotype-prints.html",
    "href": "posts/2023-06-30-cyanotype-prints.html",
    "title": "Cyanotype Printing",
    "section": "",
    "text": "A style of illustration I have been working on since I started taking drawing more seriously are these geometric animals. I start drawing shapes on a piece of paper making sure that each one connects directly to other shapes. I rotate the paper multiple times as the drawing progresses. Eventually an abstract animal shape appears in my minds-eye and I take the drawing in that direction. This is similar to looking at cloud shapes and coming up with animals or objects that they look like. When I start a new sketchbook, I always do one of these animals on the first page as a way to break in the book and never delay in starting a new book.\nRecently, I learned how to do cyanotype prints. The technique has been around since the 1840’s for making prints and helped to advance highly technical drawings (blue prints) for relatively cheap. The basic idea is that there is a chemical reaction with a paper that is coated in a UV reactive iron compound. When exposed to UV, the compound oxidizes and turns a deep blue. If part of the exposed area is covered and blocks the UV, that part will not oxidize and show up as white.\nIn the above illustration of the ape, I scanned the image and digitally inverted the image. The black pen shapes became white and the white background of the paper became black. I printed this out on a transparency sheet with an inkjet printer. This is my negative image that I can make endless cyanotype prints with.\nI coated some pieces of paper with cyanotype chemical mixture (Potassium Ferricyanide and Ammonium Citrate) in a dark room using the red light of a head lamp. Once they were dry, I fit the ape negative print over the paper and sandwiched it between a board and some thin plexiglass using clamps. I placed the prints in the sun for 15 minutes. If you go too long it will overexpose the image and the lines will not be as crisp. You then stop the reaction by dumping some hydrogen peroxide on the print and then do several washes with clean water to remove any excess reactive compounds.\nThe final prints look like below:\n\n\n\nThe print is overexposed in some areas. There are a number of variables to play with here including the paper type, the prep of the chemical coating, the exposure time, how rapid you do the hydrogen peroxide and water washes etc.\nThis geometric llama is one of the best prints as far as process goes. The space between the lines are a bit thicker in the original image making it easier for the negative image to only expose the lines:\n\n\n\nFor comparison, here is the original illustration. I cut out the cliff to simplify the image and make the negative smaller for the cyanotype."
  },
  {
    "objectID": "posts/2022-04-01-foxtailpinetrailrun/index.html",
    "href": "posts/2022-04-01-foxtailpinetrailrun/index.html",
    "title": "Miracle Mile Species 2 and 3",
    "section": "",
    "text": "Foxtail Pine\n\n\n\nWestern White Pine\nContinuing to check off the conifer species that occur in the Miracle Mile so I can make a visit and try to ID all of them. Last summer I found some Foxtail Pine (Pinus balfouriana) and (Pinus monticola) near Mount Eddy in the Klammath Range (among others).\nLoad the libraries.\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(maps)\n\nLoad the data.\n\nski_data &lt;- read.csv(\"~/DATA/data/SkiTouring.csv\")\nTrailRun1 &lt;- read.csv(\"~/DATA/data/TrailRun_FoxtailPine.csv\")\n\nMake a quick plot using the latitude and longitude coordinates and color by the date of the tour.\n\nrun1 &lt;- ggplot(TrailRun1, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point()\nrun1\n\n\n\n\n\n\n\n\nMake a general area polygon for GBIF and query the database to see if there are public observations of our two species of interest in the general region I ran in.\n\nnorcal_geometry &lt;- paste('POLYGON((-122.6 41.35, -122.35 41.35, -122.35 41.25, -122.4 41.25, -122.6 41.25, -122.6 41.35))')\n\nmm_species &lt;- c(\"pinus balfouriana\", \"pinus monticola\")\n\nfoxtail_data &lt;- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = norcal_geometry)\n\nfoxtail_coords &lt;- foxtail_data$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nmm_all &lt;- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = norcal_geometry)\nmm_species_coords_list &lt;- vector(\"list\", length(mm_species))\nnames(mm_species_coords_list) &lt;- mm_species\nhead(mm_species_coords_list)\n\n$`pinus balfouriana`\nNULL\n\n$`pinus monticola`\nNULL\n\n\nLoop through and make a dataframe from the lists.\n\nfor (x in mm_species) {\n  coords &lt;- mm_all[[x]]$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n  mm_species_coords_list[[x]] &lt;- data.frame(species = x, coords)\n}\n\ntree_df &lt;- rbindlist(mm_species_coords_list, fill = T)\n\nJust take a quick look at the raw observations plotted by latitude and longitude. Plot the species on the California map to see the limited polygon sampled.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(tree_df[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\n\n\n\n\nPlot all of the species using ggplot for the zoomed in area.\n\nrun_plot1  &lt;- ggplot(tree_df, aes(x=decimalLongitude, y = decimalLatitude, color = species)) +\n                             geom_point() + labs(color = \"Species\", title = \"MM Zone\")\nrun_plot1\n\n\n\n\n\n\n\n\nCombine trail running and species occurrence observations.\n\nrun_plot2 &lt;- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = position_long, y = position_lat), color = 'black') +\n          geom_point(data=tree_df, aes(x = decimalLongitude, y = decimalLatitude, color = factor(species))) +\n          xlab(\"Longitude\") + ylab(\"Latitude\") + labs(color='Species')\nrun_plot2"
  },
  {
    "objectID": "posts/2022-07-21-artventuregear/index.html",
    "href": "posts/2022-07-21-artventuregear/index.html",
    "title": "Art-venture Kit and Sketches",
    "section": "",
    "text": "A quick digital illustration of my small and medium sized travel/adventure art sketch kits. The top row is the small kit that fits into a Patagonia Black Hole fanny pack. The middle/bottom rows make up my medium kit. My small kit technically fits inside also, but it is its own kit. I always have some form of sketchbook with me when out and about. #dailysketching\n\nSmall Kit Contents\n\nruler\nfine and medium Pentel aqua-water brush\nfine water brush with 30% india ink diluted\nfine water brush with 70% india ink diluted\nCopic brush pen for large dark areas\nTWSBI Eco refillable fountain pen with extra-fine nib filled with Platinum Carbon Black ink\n0.3 Copic multiliner\n0.3 Micron fineliner\nUni-ball KuruToga mechanical pencil with 4b lead (I like to punch in darks in my pencil sketches)\nDIY watercolor kit in old mint tin\nStillman and Birn 3.5” by 5.5” 150 GSM Epsilon series multi-media sketchbook (can take a few watercolor washes)\nShop paper towel for washing out brushes before switching colors\nPatagonia Black Hole Fanny Pack\n\n\n\nMedium Kit Contents\n\nKavu Grizzly Kit Bag with climbing rated carabiners and climbing webbing strap\nKindle paper white with all my art books (for practice or inspiration)\nMoleskine 5” by 8.5” sketchbook\nMoleskine 5” by 8.5” landscape watercolor sketchbook (friend art journal)\nruler\nCopic 0.3 and 0.5 seppia toned fineliners\nUni-ball KuruToga mechanical pencil 0.7 mm with 4b lead\nFine retractable eraser\nold 4b pencil (pencil extender not drawn)\nZebra Brush pen\nUni-ball KuruToga mechanical pencil 0.5 mm with 4b lead\nballpoint pen 1\nballpoint pen 2\nCopic large brush pen\nSteadtler 2 mm lead mechanical pencil 4B, 2H, 2B\nwater soluble black pen\nfine and medium Pentel aqua-water brush\n4b 0.7 leads\nink container\n2 mm lead sharpener\nstandard pencil sharpener\ngum eraser\nLarge watercolor palette\nShop paper towel for washing out brushes before switching colors\n\n\n\nSmall Kit Examples\nSketch at local park.\n\n\n\nSketch at local concert venue.\n\n\n\nSketch of aloe plant and pinyon pine cones.\n\n\n\nSketch crawl at local watering hole.\n\n\n\n\n\nMedium Kit Examples\nSepia toned pages of dog toys and living room objects at a friend’s house.\n\n\n\nLarger watercolor of headphones.\n\n\n\nWater color landscape Moab Utah."
  },
  {
    "objectID": "posts/2025-05-10-DarmeraAnniversaryShow.html",
    "href": "posts/2025-05-10-DarmeraAnniversaryShow.html",
    "title": "Darmera Anniversary Art Show",
    "section": "",
    "text": "Happy Anniversary Darmera\nDarmera Studio is celebrating our one-year anniversary for May 2025! We’re grateful to everyone who has taken a class, come to a workshop, or visited the gallery - you’ve made this possible!\nDavis Elliott and I had our Anniversary Show opening on Saturday, May 10th, from 4–8 pm. We curated a small-format show featuring techniques we teach in our classes and workshops. There was a great turnout and we sold a number of pieces! The show runs until June 7th."
  },
  {
    "objectID": "posts/2023-06-21-DSxD-Fire-Zine.html",
    "href": "posts/2023-06-21-DSxD-Fire-Zine.html",
    "title": "Data Science by Design (DSxD) - Fire Zine",
    "section": "",
    "text": "My first published art work came out earlier this month in the Data Science by Design (DSxD) anthology titled “Our Environment.”\nThe zine is titled- Fire Zine: Ecosystems and Human Scales. I collaborated with Jackie Dean, an Alaskan Fire Scientist on a short fire zine examining the differences between Alaskan and California ecosystems, as well as looking at fire from a human scale up to the ecosystem scale. We really had to compress our ideas into the 5 pages, but I think we came up with some cool visuals. I assembled everything and did the layouts of the information. I had a great time working on this project from concept to physical publication.\nYou can order a printed version of the DSxD Anthology here. Or if you want to check out the individual sections that are released slowly over time, you can see them on the DSxD blog here."
  },
  {
    "objectID": "posts/2025-10-27-PyroscapesPresentation.html",
    "href": "posts/2025-10-27-PyroscapesPresentation.html",
    "title": "Pyroscapes Presentation",
    "section": "",
    "text": "I collaborated with the Mount Shasta Sisson Museum and Mount Shasta Bioregional Ecology Center (MSBEC) for a presentation on California’s Fire Ecology from an explorer, scientist, and artist’s lens. Pyroscapes is the creative exploration of the fire landscape in Californian ecosystems. The project is part science, part data visualization, part art, and part personal story.\nPyroscapes are dynamic across time, space, and governmental jurisdictions. If you are a resident in California, you live in an active pyroscape. The talk was about building a resilient pyro-culture to live alongside wildfire. In addition to the lecture, I had mini-illustrated zines discussing fire ecology principles. These mini-zines have been used in the past as portable lecture notes for field trips visiting recently burned areas. I had planned on teaching nature journaling observational skills in and around the burn area, focusing on the fire history of the area, but we got rained out!\nA few slides and visuals from the presentation:\n\nSiskiyou County 100 year fire history.\n\n\n\nI plotted the burn scars for the last 100 years in Siskiyou County (Data Source: CalFire). Each fire scar is transparent orange, so it’s easier to see the “fire mosaic” pattern in the Klamath Range in Western Siskiyou County. The blue burns are controlled or prescribed burns.\n\n\nSub-alpine Lava Fire Scar Exploration by Bike.\n\n\n\nI rode my bike up 3,000 feet of sketchy forest road to get to the upper reaches of the Lava Fire (2021) scar (~7,000 ft) on Mount Shasta near Diller Canyon. The forest is growing back slowly! The ride down was fast and there were many patchs of loose sand. haha.\n\n\nSpring Hill Fire Regrowth Observation Exploration by Trail Run.\n\n\n\nThe fire on Spring Hill in the city limits of Mount Shasta started on May 19th, 2025. It was put out right away, but part of the main trail near the top of the hill burned. I had been monitoring the development of individual green leaf manzanita plants as part of another project. I use Spring Hill as a trail running training area, so I visit frequently. I followed the regrowth of a green leaf manzanita after the fire. Shown in the illustration is the growth from a burl emerging from the roots over the course of the summer and into the fall. Green leaf manzanita often regrows after fire using this exact strategy!\n\n\nAnnouncement\n\n\n\nThe announcement of the event. Read the website announcement in the Sisson Museum Archive."
  },
  {
    "objectID": "posts/2024-01-16-edna-fire-published.html",
    "href": "posts/2024-01-16-edna-fire-published.html",
    "title": "Fire Impacts on Pollinators Across Ecosystem Types",
    "section": "",
    "text": "The post thumbnail was created by Anna Holmquist as a sampling figure for the paper. It shows the 2020 fire outlines around the greater Bay Area and where our Arthropod sampling sites were across six different University of California Reserves.\nOur Paper is now published in the January 2024 issue of Global Change Biology:\nHolmquist AJ, Markelz RJC, Martinez CC, Gillespie RG (2024). The importance of habitat type and historical fire regimes in arthropod community response following large-scale wildfires. Global Change Biology (30:1). paper.\n\nAbstract\nWildfires are increasingly altering ecosystems, posing significant challenges for biodiversity conservation and ecosystem management. In this study, we used DNA metabarcoding to assess the response of arthropod communities to large-scale wildfires across diverse habitat types. We sampled six reserves within the University of California Natural Reserve System (UCNRS), each which was partially burned in the 2020 Lightning Complex wildfires in California. Using yellow pan traps to target pollinators, we collected arthropods from burned and unburned sites across multiple habitat types including oak woodland, redwood, scrub, chamise, grassland, forest, and serpentine habitats. We found no significant difference in alpha diversity values between burned and unburned sites; instead, seasonal variations played a significant role in arthropod community dynamics, with the emergence of plant species in Spring promoting increased pollinator richness at all sites. Compositional similarity analysis revealed that burn status was not a significant grouping factor when comparing all sites. Instead, community composition primarily varied across reserves, indicating distinct pools of arthropods structured geographically. Habitat type played a crucial role in determining the response of arthropod communities to fire. While communities in grasslands and oak woodlands exhibited recovery following burn, scrublands experienced substantial changes in community composition. Our study highlights the importance of examining community responses to wildfires across broad spatial scales and diverse habitat types. By understanding the nuanced dynamics of arthropod communities in response to fire disturbances, we can develop effective conservation strategies that promote resilience and maintain biodiversity in the face of increasing wildfire frequency and intensity driven by climate change.\nThe code repository is available here. The repository also contains instructions on how to make reproducible data science docker containers for each of the major steps in the analysis pipeline. We made the docker container with the largest number of software dependencies available on docker hub here. A permanent repository with code and a citeable DOI number is available here."
  },
  {
    "objectID": "posts/2025-08-15-ShastaAlpineHutMap.html",
    "href": "posts/2025-08-15-ShastaAlpineHutMap.html",
    "title": "Shasta Alpine Hut Map",
    "section": "",
    "text": "This is my second season working up at the Shasta Alpine Hut. I was commissioned by the Sierra Club Foundation to make a map of the the major trails through their property and the adjacent land. It was a fun project to figure out how to make a map with The Shasta Alpine Hut (Formally Horse Camp Hut) as the central hub of trails on this side of the mountain. After I finished the map, we had copies up at the hut. Throughout the season I talked to a number of tourists who used my map to navigate during their hike. Success!"
  },
  {
    "objectID": "posts/2025-02-28-TrailRunningComic.html",
    "href": "posts/2025-02-28-TrailRunningComic.html",
    "title": "Trail Running Comic",
    "section": "",
    "text": "1 Page Comic\nA simple comic to try out a workflow in my 9x12 sketchbooks."
  },
  {
    "objectID": "posts/2023-05-08-intro-fire-science.html",
    "href": "posts/2023-05-08-intro-fire-science.html",
    "title": "Fire Ecology Class - 2",
    "section": "",
    "text": "Here is the first of the three zines I made for teaching wildfire science. I had this zine printed and folded for the students so we could walk around the reserve and discuss the following concepts with examples on the landscape itself. Active learning.\n\n\n\nThe fire triangle defines the needs of a fire to grow or if you are managing it, to maintain or shrink it.\n\n\n\n\nAn illustrated outline of the chemistry of fire.\n\n\n\n\nThe physics of combustion.\n\n\n\n\nHow energy is released from a wildfire.\n\n\n\n\nHow spacing of fuels influence fire spread.\n\n\n\n\nThe recent fire history of California.\n\n\n\n\nThe relatively small amount of controlled burning in California compared to natural fires. We need to do much, much more!\n\n\n\n\nHow the complex fire history of an area creates pyrodiversity."
  },
  {
    "objectID": "posts/2024-2-01-NSBG-van-introduction.html",
    "href": "posts/2024-2-01-NSBG-van-introduction.html",
    "title": "Notorious SBG",
    "section": "",
    "text": "Above: Adventure van set-up with mountain bikes.\nWe have gotten a few questions lately regarding the details of our van build so I decided to write them up.\nOur van is named Notorious SBG after my late wife Dr. Sharon Beth Gray whose adventurous spirit lives on in our hearts, minds, and the van’s power-steering. :). NSBG is a 2015 Ford Transit 250 Hightop with a 148 wheel base purchased with 16000 miles in early 2017 for 25k cash + ~4k in build out. The current bluebook value of the van (without the build out), is $30-34k so not an investment by any means, but it has maintained value over time with the recent vehicle shortages. This model is the largest that will fit in a standard parking spot. They also make extra long ones, but that would much more of a pain. We did the build (continue to do, ha!) ourselves. It was quite a challenge trying to build something in an apartment parking lot in the East Bay while also watching the tools at all times. Fortunately, I lived within walking distance from a hardware store and from a West Marine (all of our electrical components).\nWe chose this model because it is basically a larger version of the Ford F150 truck. Same chassis and engine. While I am pretty handy, if we did need to get work done, many mechanics can work on this type of engine and parts are more abundant (also considered diesel).\nThe bed platform is just shy of 77 inches in length and the height inside the current build is also 77 inches. We fit a queen sized mattress in there. Rearranging some long pillows and our large duffel bags, you can make a number of comfortable seating arrangements on the bed.\nThere are trade-offs for everything of course and we actually rebuilt the main living area a few times based on needs. We keep it pretty minimalist and flexible (e.g. we are not going to put a ton of time into building cabinets when milk crates are way more flexible and can be taken inside our house once the trip is over).\nThe one thing we wish we did have is AWD or 4WD. So far we have gotten along without it, but only through planning and also owning a 2011 Subaru. Snow tires solve a lot of the issues, but not on sand or gravel bars (we spend time on these frequently fishing).\nThe largest upgrades that are worth buying outright if you will be living in/out of a van is swivel chairs for captain and copilot seat (see image) and a magnetic bug net for the slider and back doors that is custom to your specific model. Roll these down and it instantly turns your van into a large screened-in porch. We had a bunch of netting that we would use (also with magnets), but it was always a gigantic hassle to set up and only about an 80% solution for keeping insects out.\nBelow are some images of the current van build for reference.\n\nurl &lt;- \"https://imgur.com/cprGoMX\"\nknitr::include_graphics(url)\n\n\n\n\n\n\n\n\nLeft: Current view inside of the van. I was doing some work in there recently so we temporarily removed the mattress.\nMiddle: Swivel chairs increase the usable space inside by ~20%. You can also nap with these fully reclined and sleep a few additional people if you had to.\nRight: Van with bed/mattress above the garage. This photo is taken after we packed before going to a friend’s desert festival in the Southern Sierra. Bikes, adventure gear, lots of books, shared activities, pickles etc. Normal trips would be less packed. The top right of the garage is a collapsible table. That space is perfectly designed to fit our backcountry ski bag and our XC ski bag.\n\n\n\n\n\nAbove: Trail running in the Northern Cascades, WA and a view of our adventure van (NSBG) gear garage under our bed."
  },
  {
    "objectID": "posts/2025-04-27-FieldIllustratorBag.html",
    "href": "posts/2025-04-27-FieldIllustratorBag.html",
    "title": "Cody Markelz - Field Illustration Bag",
    "section": "",
    "text": "I designed a field illustration bag!\nI collaborated with with the incredibly talented Zach Pheiffer-Hansen over at Sovyrn in Mount Shasta to bring this project to life.\nI wanted a lightweight water resistant field illustration bag that would fit a 6x9 inch sketchbook and my supplies. I sent some sketches and reference images over to Zach and then joined him in his studio one evening to make the bag. You can see the entire process illustrated in the sketchnote above.\nYou can order one for $79 directly from Sovyrn. Zach can also do some custom colors. Make sure to reach out to him!\nUnique features of this bag are: - custom size to fit 6x9 sketchbooks/journals without a lot of wiggle room - comfortable to wear while out in the field all day - a way to attach to the front of a bike for bikesketching adventures - a removable and velcro quick access pouch for common pencil, pen, waterbrush - light weight water resistant material\n\n\n\nThis was an incredibly fun project. Zach went from my ideas to a finished bag prototype with exact patterns over the course of an evening. This bag lives on my body except when I am sleeping. Or maybe I sleep with it on too. ;)"
  },
  {
    "objectID": "posts/2022-09-15-shastasketchersnaturejournal/index.html",
    "href": "posts/2022-09-15-shastasketchersnaturejournal/index.html",
    "title": "Shasta Sketchers",
    "section": "",
    "text": "Our first Drink and Draw event was a success! We are going to continue this once a month. Additionally, there was some interest in a Nature Journaling Club Meet-up. To find out more about upcoming events please visit our website at Shasta Sketchers. We will start hosting outdoor sketching meet-ups in the spring of 2023.\n\n\n\nIf you like my sketches you can check out the sketchbook section of my art portfolio website or follow me on instagram codymarkelz."
  },
  {
    "objectID": "posts/2024-10-06-MontologyJournalZinesYear39.html",
    "href": "posts/2024-10-06-MontologyJournalZinesYear39.html",
    "title": "Montology - Year 39",
    "section": "",
    "text": "Montology Studios creates illustrated Zines and media around the theme of mountains and culture. Think of this Zine as a cross between National Geographic, punk rock, adventure, natural history and data science.\nMy first larger Zine issues (40+ pages) are collected illustrated monthly journal entries.\nThis issue covers Year 39- August 2023-2024. The other two published issues cover the periods between Year 37- August 2021-July 2022 and Year 38- August 2022-July 2023.\nSign up for the newsletter to learn how to pre-order or check out the Etsy Shop to purchase copies of previous issues of the zine."
  },
  {
    "objectID": "posts/2025-06-25-HeadwatersUltraRace.html",
    "href": "posts/2025-06-25-HeadwatersUltraRace.html",
    "title": "Headwaters Trail Run + Poster",
    "section": "",
    "text": "This race year of the Headwaters Trail Run Race was special for me. Not only did I train hard for the race, but I also got commissioned to make the poster! The poster features the diversity of pine cones that are present throughout the Headwaters course. The cones are arranged in the pyramid shape representing the relative elevation band the species inhabit as you go from Lake Siskiyou 3,185 ft (971 m) to the summit of Mt. Eddy 9,037 ft (2,754 m).\nFrom top to bottom, left to right in the image:\n\nWhite Bark Pine (Pinus albicaulis)\nShasta Red Fir (Abies magnifica var. shastensis)\nFoxtail Pine (Pinus balfouriana)\nWestern White Pine (Pinus monticola)\nLodgepole Pine (Pinus contorta)\nIncense Cedar (Calocedrus decurrens)\nJeffery Pine (Pinus jeffreyi)\nPacific Yew (Taxus brevifolia)\nWhite Fir (Abies concolor var. lowiana)\nKnobcone Pine (Pinus attenuata)\nPort Orford Cedar (Chamaecyparis lawsoniana)\nDouglas Fir (Pseudotsuga menziesii)\nPonderosa Pine (Pinus ponderosa)\nSugar Pine (Pinus lambertiana)\n\nThe race has over 8000 ft (~2400 m) of elevation gain and loss. The weather was significantly cooler than previous years. The top of Mt. Eddy was windy and snowy in June. I am really happy with my effort 6:21:01. I beat the course record from previous years by 9 minutes! However, the field was completely stacked! 8th overall out of ~90 entrants. I will take it! The last time I ran the race I also had a blast. Read about it in this post: Headwaters Run."
  },
  {
    "objectID": "posts/2023-02-23-BIDS-welcome.html",
    "href": "posts/2023-02-23-BIDS-welcome.html",
    "title": "BIDS Illustration",
    "section": "",
    "text": "SDH Hall Sketch\nBerkeley Institute for Data Science (BIDS) finally moved into our new space in Sutardja Dai Hall on the UC Berkeley campus. I designed this flier for our welcome event featuring an illustration of SDH. I knew immediately that I wanted to sketch this great building, but did not know it would become part of a flier!\nThe welcome event was great. I met a lot of really interesting people and struck up some collaborations to visualize some research through illustrations and sketchnotes! I am really excited about this new opportunity to apply my love for learning, illustration and data visualization towards science communications of the cool projects that are going on at BIDS."
  },
  {
    "objectID": "posts/2022-02-15-ski-touring-data/index.html",
    "href": "posts/2022-02-15-ski-touring-data/index.html",
    "title": "Ski Touring Movement Data",
    "section": "",
    "text": "When thinking about how to combine datasets to ask more complex questions it is important to determine where the overlaps in the datasets might be. As an example, The Mount Shasta Avalanche Center keeps records of seasonal weather and avalanche forecast data that I discussed in a previous post. I just made a small movement dataset from some of the ski tours I have done in the Mount Shasta area. Here are just a few summary views of the dataset below. In the next series of posts we will overlap the avalanche forecast data, weather data, and the ski touring movement data based on date, time, elevations, and aspects.\n\nlibrary(tidyverse)\nski_data &lt;- read.csv(\"~/DATA/data/SkiTouring.csv\")\n\nThe data set has a number of interesting variables including my movement as I skied, some speed data, some altitude data, and some biometric heart rate data. All of the tours were in the 2019-2020 or the 2020-2021 ski season on the lower slopes of Mount Shasta, Ca.\nTake a quick look.\n\nglimpse(ski_data)\n\nRows: 13,491\nColumns: 17\n$ timestamp      &lt;chr&gt; \"2020-01-18 18:33:31\", \"2020-01-18 18:33:58\", \"2020-01-…\n$ position_lat   &lt;dbl&gt; 41.35011, 41.35010, 41.35012, 41.35014, 41.35016, 41.35…\n$ position_long  &lt;dbl&gt; -122.2793, -122.2793, -122.2793, -122.2792, -122.2792, …\n$ altitude       &lt;dbl&gt; NA, 1504.2, 1504.8, 1504.8, 1505.0, 1505.2, 1505.6, 150…\n$ heart_rate     &lt;int&gt; NA, 55, 62, 62, 64, 64, 69, 66, 67, 76, 74, 73, 72, 70,…\n$ cadence        &lt;int&gt; NA, 64, 48, 52, 49, 46, 46, 43, 43, 0, 48, 72, 75, 75, …\n$ temperature    &lt;int&gt; NA, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,…\n$ distance       &lt;int&gt; NA, NA, NA, NA, 7, 9, NA, 15, NA, NA, NA, 24, 26, 29, 3…\n$ speed          &lt;dbl&gt; NA, NA, NA, NA, 0.5, 0.8, 1.1, 1.1, 0.7, 0.0, 0.0, 1.0,…\n$ vertical_speed &lt;dbl&gt; NA, 0.00, 0.02, 0.00, 0.00, 0.00, 0.00, 0.00, 0.04, 0.0…\n$ File_Path      &lt;chr&gt; \"Move_2020_01_18_10_33_29_Ski_touring.fit\", \"Move_2020_…\n$ activity       &lt;chr&gt; \"SkiTouring\", \"SkiTouring\", \"SkiTouring\", \"SkiTouring\",…\n$ HRzone         &lt;chr&gt; NA, \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"…\n$ datetime       &lt;chr&gt; \"2020-01-18 18:33:31\", \"2020-01-18 18:33:58\", \"2020-01-…\n$ year           &lt;int&gt; 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2…\n$ date           &lt;chr&gt; \"2020-01-18\", \"2020-01-18\", \"2020-01-18\", \"2020-01-18\",…\n$ seconds        &lt;chr&gt; \"18:33:31\", \"18:33:58\", \"18:34:42\", \"18:34:45\", \"18:34:…\n\nsummary(ski_data)\n\n  timestamp          position_lat   position_long       altitude   \n Length:13491       Min.   :41.35   Min.   :-122.3   Min.   :1504  \n Class :character   1st Qu.:41.36   1st Qu.:-122.2   1st Qu.:1827  \n Mode  :character   Median :41.36   Median :-122.2   Median :2052  \n                    Mean   :41.36   Mean   :-122.2   Mean   :2031  \n                    3rd Qu.:41.36   3rd Qu.:-122.2   3rd Qu.:2262  \n                    Max.   :41.37   Max.   :-122.2   Max.   :2532  \n                                                     NA's   :8908  \n   heart_rate        cadence        temperature       distance    \n Min.   : 42.00   Min.   :  0.00   Min.   :12.00   Min.   :   7   \n 1st Qu.: 55.00   1st Qu.: 37.00   1st Qu.:19.00   1st Qu.:1640   \n Median : 71.00   Median : 48.00   Median :20.00   Median :3144   \n Mean   : 76.91   Mean   : 49.95   Mean   :20.83   Mean   :3309   \n 3rd Qu.: 98.00   3rd Qu.: 69.00   3rd Qu.:22.00   3rd Qu.:4668   \n Max.   :148.00   Max.   :114.00   Max.   :31.00   Max.   :9317   \n NA's   :361      NA's   :8908     NA's   :8908    NA's   :10905  \n     speed      vertical_speed    File_Path           activity        \n Min.   :0.00   Min.   :-1.180   Length:13491       Length:13491      \n 1st Qu.:0.80   1st Qu.:-0.020   Class :character   Class :character  \n Median :1.00   Median : 0.040   Mode  :character   Mode  :character  \n Mean   :1.48   Mean   :-0.021                                        \n 3rd Qu.:1.40   3rd Qu.: 0.100                                        \n Max.   :8.40   Max.   : 0.240                                        \n NA's   :8912   NA's   :8908                                          \n    HRzone            datetime              year          date          \n Length:13491       Length:13491       Min.   :2020   Length:13491      \n Class :character   Class :character   1st Qu.:2020   Class :character  \n Mode  :character   Mode  :character   Median :2020   Mode  :character  \n                                       Mean   :2020                     \n                                       3rd Qu.:2020                     \n                                       Max.   :2021                     \n                                                                        \n   seconds         \n Length:13491      \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\nMake a quick plot using the latitude and longitude coordinates and color by the date of the tour.\n\nski_plot1 &lt;- ggplot(ski_data, \n                    aes(x = position_long, y = position_lat, color = date)) +\n                    coord_quickmap() + geom_point() +\n                    ylab(\"Latitude\") + xlab(\"Longitude\")\n  \nski_plot1"
  },
  {
    "objectID": "posts/2023-08-11-Adventure-Route-Planning.html",
    "href": "posts/2023-08-11-Adventure-Route-Planning.html",
    "title": "Explorer Planning Toolkit - 1",
    "section": "",
    "text": "We planned back to back ultra-runs from our hometown of Mount Shasta, CA up into the Klamath range. I wanted to balance the ease of running using established trails as much as possible with running through areas that have burned in the last 100 years. An additional constraint was road access and camping for our crew. The light blue is the first day and the dark blue is the second day. The orange outlines are fire scars from the last 100 years (Data Source, CALFIRE). In the next few posts in this series I will talk about the fire history of each of the many fire scars we ran by or directly through and what story they have to tell about the pyroscape in my backyard.\n\nDAY 1\n\nThursday August 3 - Mount Shasta to Scott Mountain Campground\n39 miles - +6335/-4501 (feet gain/loss)\nTrails: Sission Trail to PCT Northbound\nMidway Stop: Parks Creek PCT Trailhead\nDirections from Mount Shasta to Scott Mountain Campground\nScott Mountain Campground Weather Forecast\n\n\n\nDAY 2\n\nFriday August 4 - Scott Mountain to Etna Summit\n39 miles - (+7826/-7289)\nTrail:PCT Northbound\nMidway Stop: Scott Mountain to Hidden Lake Trail - 30 minute drive\nDirections from Hidden Lake to Etna Summit - 54 minute drive\nEtna Summit Forecast"
  },
  {
    "objectID": "posts/2024-03-01-Montology-Overview.html",
    "href": "posts/2024-03-01-Montology-Overview.html",
    "title": "Montology Zines",
    "section": "",
    "text": "Montology Studios creates illustrated Zines and media around the theme of mountains and culture. Think of this Zine as a cross between National Geographic, punk rock, adventure, natural history and data science. Each zine has a specific sub-theme. Some previous themes have been trail running, fire ecology, adventure vans, and frugality.\nMy first larger Zine issues (40+ pages) are collected illustrated monthly journal entries. The first two issues cover the periods between August 2021-July 2022 and August 2022-July 2023. These first two issues will be available to ship mid-April.\nIn addition, four series that will be published quarterly for 2024. The 2024 schedule for sub-themes are Fire Runner Zine (first issue available mid-April), Bicycle Repair Zine (first issue available mid-July), Life by the River Zine (first issue available mid-October), and Primitive Technology (first issue available Late December).\nSign up for the newsletter to learn how to pre-order or check out the Etsy Shop to purchase copies of previous issues of the zine."
  },
  {
    "objectID": "posts/2024-12-17-2025Goals.html",
    "href": "posts/2024-12-17-2025Goals.html",
    "title": "2025 Goals",
    "section": "",
    "text": "A breakdown of the hours for 2025. This is part of a much larger series of 5 year projects that you can read about here.\nI proportionally scaled the space devoted to each goal on the page based on the number of hours for each. I think that doing it this way makes it visual how much time we should be spending sleeping :). It also reflects priorities with the base physiological and personal needs along with my relationship with Caryn, then and only then do the other projects get additional time. All of these projects have significant time buffers built into them. As an example, I rarely sleep 9 hours, but when I am completely worked from exercise I do. Another way to build in a buffer is that I am not accounting for overlaps even though I typically do overlap projects. For example, Caryn and I will be going for a long gravel ride today. This ride is scouting for a local gravel guide zine we are putting together. This touches on both exercise and planet, but I am not counting on that happening all the time.\n\n8760 - Total Hours\n\n5475 - Sleep 9 hours (3285)\n4475 - Planet (1000)\n3975 - Life Maintain (500)\n3475 - Alpine Ecology (500)\n2975 - Comics (500)\n2475 - MechE (500)\n1975 - Exercise (500)\n1875 - Montology Maintain (100)\n1375 - Darmera (500)\n1275 - Darmera Maintain (100)\n775 - Medium Projects (500)\n275 - Small Projects (500)\n0 - Social (275)\n\nI want to not feel time stress this year. I am much more creative when I am not time crunched in multiple aspects of life. This happens with external demands, so I build in a lot of extra buffer. A single deadline is enhanced when I have time buffers for everything else. If I have extra time to sit around for some reason, I sketch or write in my EDC sketchbook. All is well.\nThe projects this year are continuations of this year, but they are about going much deeper on some topics and finishing up some other ones that I now feel confident in the skillset to do it right (e.g. comics). The other thing I remind myself is that with all of these projects built on top of my personal and relationship base are super low stakes. THE STAKES ARE LOW. I want to do them because I think they are cool and I want to learn new things.\n\n\nSocial\n\nNature Journal Meetup (April)\nWedding (Late June)\nThe rest is flexible\n\n\n\nDarmera and Montology Admin (200 hrs)\n\n\nMedium Sized Projects - 500 hours\n\nGravel Bike Components Zine\nDesign Drawing portfolio (12)\nPyroscapes Graphic Essay (story scrolling website)\n\ntraining\nobservation\necology\nspecies\nadventure\n\nWatershed History Comic? (idea if I have time)\nMTB - Overhaul\nMedium repairs for customers\nTeach Field Bike wrenching class\n\n\n\nSmall Projects - 500 hrs\n\nSuspension Class Zine\n\nlayouts\ncover\nprint\n\nMinor Van Projects\nMinor Bike Repairs for customers\nNature Illustration Portfolio\n\nWebsite\nCards\nPrints\nMagnets\nStickers\nPins\n\n\n\n\nCOMICS - 500 hours - M/F\n\nCartographer Issue 1\n\nPage Layouts\nWord Balloons\nPencils\nInks\nColors\nPrint\nGallery Show - Comic launch! November 2025\n\n\n\n\nDarmera - 500 Hours W/R/F/Sun\n\nTeach -\nWatercolor and Ink\nNature Journaling\nArt Fundamentals\nNature Journal Retreat Hosting\n\nSummer\nFall\n\nNature Screen Printing Workshop\nVideo Classes Record\n\n\n\nAlpine Ecology- 500 Hours - R/S/S\n\nAlpine ecology zine (50 pages - sketchnotes, hut observations, writing)\n\nGraphical Essay(s)\nAlpine Hut Season 1\nAlpine Hut Season 2\n\nNature Journaling 1 page per week (Portfolio 12 pages- 1 portfolio piece per month)\nNature Journal Comics Pages\n\n1 - Foxtail Pine\n2 - clarks nutcracker\n3 - Western White Pine\n4 - Snow comic\n\n\n\n\nMECHE - 500 Hours Sketchnotes - T/W\n\nBicycle mechanical engineering zine (50 pages sketchnotes)\n\nMechE Hand Book 1\nMechE 4th Edition 2\nMechE Design Book\nBirds Engineering Math Reference Book\nBicycles and Tricycles - Concepts applied above\nBicycle Science - Concepts applied above\n\n\n\n\nPlanet - 1000 Hours\n\nFlexible - Conversation, Hangout, Neighborhood Walks\nGravel Zine collaboration with DW\n\n1 - Ride, Map Viz, Nature, Essay, Illustrations\n2 - Ride, Map Viz, Nature, Essay, Illustrations\n3 - Ride, Map Viz, Nature, Essay, Illustrations\n4 - Ride, Map Viz, Nature, Essay, Illustrations\n5 - Ride, Map Viz, Nature, Essay, Illustrations\n\nBC Permaculture Farm Trip Zine - with DW\nDate Nights\nCook Meals\nHouse Cleaning\nMedium sized van projects\nFire wood gather, split, stack, dry, store\n\n\n\nMove - 500 hours T/W/R/F/S/S\n\nAll Round Mountain Athlete\nAdvanced Training Program (Uphill Athlete PLUS)\n\nBike (MTB and Gravel)\nTrail Run\nHike (weighted)\nSki (Nordic, Downhill, BC)\n\nBegin Base Training Phase with 10 hours- Later Goal TBD\n\n\n\nLife - 500 hrs\n\nPersonal Hygiene\nThink\nWrite/Journal\nRead\nBlog\nExercise data - data viz portfolio\nCook Meals\nGrocery Shop\nFrugal Explorer Nutrition Zine\nHouse Cleaning\n\n\n\nSleep - 3285 hrs\n\nmmmm ….dreams"
  },
  {
    "objectID": "posts/2022-07-01-headwaters/index.html",
    "href": "posts/2022-07-01-headwaters/index.html",
    "title": "Headwaters Race",
    "section": "",
    "text": "Last month I ran the Headwaters Ultra here in Mount Shasta, CA. The race starts at Lake Siskiyou, heads up the steep trails on Rainbow Ridge and then heads over into the Eddy Range in the Klamath Mountains. The course meets up with the Sisson-Callahan Trail to go up and over the saddle (~8000 ft) just below the summit trail to the top of Mount Eddy (9,037 ft; 2,754 m). After the last aid station at Deadfall Meadows, the course goes back up and over the saddle followed by 12 miles of fast, quad-busting descent all the way down the Sisson-Callahan trial. It was really fun overall. It rained and snowed the night before, so the race went through a few inches of fresh snow at the higher elevations above ~6500 ft. The moody dark clouds at higher elevations were interrupted by moments of bright sunshine poking through reflecting off the snow and illuminating the Foxtail Pine Grove. I finished the race 8th overall with a time of 6:44:15. A great day out!\nTake a quick look at some of the course data collected by my exercise watch.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(gpx)\nlibrary(rayshader)\n\nPull in my run data using the gpx R library and subset the route to make plotting easier. Add a Time column for seconds elapsed for plotting purposes.\n\nrun &lt;-  read_gpx('~/DATA/data/headwaters-2022-06-18.gpx')\nsummary(run)\n\n          Length Class  Mode\nroutes    1      -none- list\ntracks    1      -none- list\nwaypoints 1      -none- list\n\nTrailRun1 &lt;- as.data.frame(run$routes)\nTrailRun1$Time &lt;- as.numeric(row.names(TrailRun1))\n\nQuick plot.\n\nTR_p1 &lt;- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black', size = 2) +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTR_p1\n\n\n\n\n\n\n\n\nTake a look at the elevation profile in meters.\n\nTR_p2 &lt;- ggplot() +\n          geom_line(data = TrailRun1, aes(x = Time, y = Elevation), color = 'black', size = 2) +\n          xlab(\"Time (seconds)\") + ylab(\"Elevation (m)\")\nTR_p2\n\n\n\n\n\n\n\n\nMake a new factor column to see what parts of the race had snow on them.\n\nTrailRun1$snow &lt;-  as.factor(if_else(TrailRun1$Elevation &gt; 1980, \"Yes\", \"No\"))\nTR_p3 &lt;- ggplot() +\n          geom_line(data = TrailRun1, aes(x = Time, y = Elevation, color = snow), size = 2) +\n          xlab(\"Time (seconds)\") + ylab(\"Elevation (m)\")\nTR_p3\n\n\n\n\n\n\n\n\nThe rayshader package is really cool. You can take ggplot2 figures and make them 3D with this package. The code for doing so is below, but is not run to keep the website rendering time short. It takes a few minutes to render the snapshot view on my Macbook Pro using a few available cores.\n\nTR_p4 &lt;- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude, color = Elevation), size = 2) +\n          scale_color_continuous(limits=c(800,2800))\nTR_p4\n\n\n\n\n\n\n\n# Not run for website rendering purposes, but you should!\n# plot_gg(TR_p4, width = 15, height = 15, multicore = TRUE, scale = 1000,\n#         zoom = .7, theta = 10, phi = 20, windowsize = c(3000, 3000))\n# Sys.sleep(0.2)\n# render_snapshot(filename = \"run-elevation-plot3.png\", clear = TRUE)"
  },
  {
    "objectID": "posts/2022-03-01-trout-data/index.html",
    "href": "posts/2022-03-01-trout-data/index.html",
    "title": "Trout and Food Species",
    "section": "",
    "text": "In this post we will look at some spatial data of Rainbow Trout (Oncorhynchus mykiss) and one of their food sources Blue Winged Olives (Baetis tricaudatus). We will take a look using publicly available observation data from the GBIF database. See previous posts here and here for other examples of species occurrence data.\nLoad the necessary R libraries.\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(maps)\nlibrary(leaflet)\n\nPull in the species observation data from GBIF.\n\nrb_trout &lt;- occ_data(scientificName = \"Oncorhynchus mykiss\", hasCoordinate = TRUE, limit = 1000)\nbw_olive &lt;- occ_data(scientificName = \"Baetis tricaudatus\", hasCoordinate = TRUE, limit = 1000)\n\nSubset these datasets for only a few pieces of data.\n\nrb_trout_coords &lt;- rb_trout$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n\"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"references\")]\nbw_olive_coords &lt;- bw_olive$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n\"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"references\")]\n\nPlot on a map of California. Rainbow trout in red and Blue winged Olives in blue.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(rb_trout_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\npoints(bw_olive_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\n\n\n\n\nSubset our search to only Northern California and combine the query for both species.\n\nnorcal_geometry &lt;- paste('POLYGON((-124.4323 42.0021, -120 42.0021, -120 40.194, -124.4323 40.194, -124.4323 42.0021))')\nspecies &lt;- c(\"Oncorhynchus mykiss\", \"Baetis tricaudatus\")\n\nspecies_data &lt;- occ_data(scientificName = species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = norcal_geometry)\nsummary(species_data)\n\n                    Length Class  Mode\nOncorhynchus mykiss 2      -none- list\nBaetis tricaudatus  2      -none- list\n\n\nName the individual lists within the species_data object and pull out the relevant data for plotting.\n\nspecies_data_coords_list &lt;- vector(\"list\", length(species_data))\nnames(species_data_coords_list) &lt;- species\nnames(species_data_coords_list)\n\n[1] \"Oncorhynchus mykiss\" \"Baetis tricaudatus\" \n\nfor (x in species) {\n  coords &lt;- species_data[[x]]$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n  species_data_coords_list[[x]] &lt;- data.frame(species = x, coords)\n}\n\nCombine into single long dataframe for easier plotting.\n\ntrout_df &lt;- rbindlist(species_data_coords_list, fill = T)\n\nThere are only a few observations of the Blue Winged Olives that overlap the Rainbow Trout in this range.\n\nspecies_plot1 &lt;- ggplot(trout_df, aes(x=decimalLongitude, y = decimalLatitude,\n                        color = species)) +\n                        geom_point() +  \n                        scale_color_manual(values = \n                           c(\"Oncorhynchus mykiss\" = \"red\",\n                           \"Baetis tricaudatus\" = \"blue\")) + \n                        labs(color = \"Species\", \n                             title = \"Northern California Rainbow Trout \n                             and Blue Winged Olive\") +\n                        ylab(\"Latitude\") + xlab(\"Longitude\")\nspecies_plot1\n\n\n\n\n\n\n\n\nPlot the data on an actual map. The overlapping data points for Blue Winged Olives and Rainbow Trout are on the Trinity River, the McCloud River, and Rush Creek in the North Eastern part of the state in Modoc county.\n\npalette &lt;- colorFactor(c(\"blue\", \"red\"), domain = c(\"Oncorhynchus mykiss\", \"Baetis tricaudatus\"))\n\nleaflet(trout_df) %&gt;% addTiles() %&gt;%\n  addCircleMarkers(~decimalLongitude, ~decimalLatitude,\n    color = ~palette(species),\n    stroke = FALSE, fillOpacity = 0.5\n  )\n\n\n\n\n\nNext up for this dataset is taking a look at dates of observations and overlapping those with weather and stream flow data from those river systems."
  },
  {
    "objectID": "posts/2023-02-01-Obsidian3.html",
    "href": "posts/2023-02-01-Obsidian3.html",
    "title": "Introduction to Obsidian - 3",
    "section": "",
    "text": "After 1.5 years of use I have dialed in a nice workflow with Obsidian. See part 1 and part 2 for an introduction. One of the main reasons I like Obsidian is it just adds a layer on top of my current markdown notes. I can easily copy notes, back them up, move them to a new machine, access them in multiple ways, etc. completely independently of Obsidian. Adding the links between notes as I think about them and having those links updated if notes move around.\nI am primarily using obsidian as a personal wiki. I have some structure that fits the general categories of my life: MAKE, LIVE, THINK, EXPLORE. All of these overlap with one another, but it is helpful to partition them out in this way because it is similar to how I chunk my activity time.\nLIVE - This category includes human relationships, food and cooking, house and van related activities, our permaculture garden, and general socializing.\nMAKE - This category is dedicated to art, technique, illustration.\nTHINK - This category is for math, statistics, AI/ML, and science.\nEXPLORE - The category is for physical fitness, outdoor activities, gear maintenance, travel, nature observation, and exploration.\nA few examples of overlaps for these categories would be: group trail runs (LIVE-EXPLORE), analyzing heart rate data (THINK-EXPLORE), blogging about an adventure that included illustrations and data visualizations (THINK-EXPLORE-MAKE).\nNow with this structure in place I organize all my different projects and goals that fit into these categories using Obsidian. I have a balance between completely new notes for every single idea and predetermining the importance of that information as it comes in. I tried just being loose with the notes, but my projects are diverse enough, especially in the learning phase, that it becomes too cluttered. Each major sub-category gets its own markdown overview document. These overview docs link to one another, the individual notes and the images within the respective directories.\nA simplified and lightly edited view of my obsidian vault directory:\n\nOverview Documents\n1.1-LIVE-Social.md\n1.2-LIVE-House.md\n1.3-LIVE-Van.md\n1.4-LIVE-Garden.md\n2.1-MAKE-DIY-Art-School.md\n2.2-MAKE-DIY-Comic-School.md\n2.3-MAKE-Zines.md\n2.4-MAKE-Portfolio.md\n3.1-THINK-Blog.md\n3.2-THINK-DataScience.md\n3.3-THINK-Science.md\n3.4-THINK-Journal.md\n4.1-EXPLORE-AdventureSports.md\n4.2-EXPLORE-FlyFishing.md\n4.3-EXPLORE-Exercise.md\n\n\nGoal Documents\n2023-Goals.md\n2023-TODO.md\n\n\nAdditional Notes Directories\n/LIVE/notes\n/LIVE/notes/images/\n/MAKE/notes\n/MAKE/notes/images/\n/THINK/notes\n/THINK/notes/images/\n/EXPLORE/notes\n/EXPLORE/notes/images/\nOrganizing things in this way balances a structure and looseness of idea capture. It also mirrors how I organize my time in real life to reduce any frictions that might arise by having different mental models for organizing digital information and physical information and actions.\nUp next in this series: A more detailed view using obsidian for a project."
  },
  {
    "objectID": "posts/2021-12-15-Obsidian-Intro.html",
    "href": "posts/2021-12-15-Obsidian-Intro.html",
    "title": "Introduction to Obsidian",
    "section": "",
    "text": "Obsidian Knowledge Graph\n\nWhat is it?\nObsidian is a way to take notes in markdown and link those notes together. Linking ideas is a powerful way to form new ones and reinforce old ones. Obsidian is fairly flexible, has a large number of extensions, an active community for ideas and troubleshooting, and is kind of an addictive productivity tool.\n\n\nWhy is it interesting?\nI was originally attracted to this option because I spend a lot of my time making markdown documents as part of daily research activities. Obsidian allows you to do this, but also version control your research notes by tracking the hidden .obsidian/workspace vault that lives inside a research notes directory. You can use the obsidian app viewer to look at all the documents in the directory, make new notes (all markdown documents), click on them, edit them, render them to html/webpage format or export them to other formats like PDF. It does not lock the notes into only being viewed by Obsidian so you can open the individual markdown notes in some other text editor if convenient. Obsidian can view the changes as soon as you hit save from another editor.\nOne of the most powerful features is the ability to create links between the documents similar to the way a wiki works by allowing hyperlinks between topics. In the case of Obsidian it is linking to other markdown documents within your “vault”. It also has a nifty visualization tool to view your own research knowledge graph.\n\n\nHow to use it for research?\nAs an example, let us say you are researching some ideas for a series of blog posts where you want to start broad and end up with a post or two as the final research output. Each idea that you are researching can start as its own new markdown document (also called a Note in Obsidian). The main points of all the individual notes documents could then be summarized in a “Summary” note markdown file with links to all the individual notes for future reference. The summary of main points is then used to create a blog post markdown document to further refine the ideas.\nCheck out Obsidian here\nFuture obsidian posts include: bibliographies, video information capture from captions, scrapping notes and links to passages in eBooks, and integrating LaTex tools for equation writing."
  },
  {
    "objectID": "science.html",
    "href": "science.html",
    "title": "Science",
    "section": "",
    "text": "I am currently working on a project to develop probabilistic models for avalanches in Northern California. Backcountry skiing and snowboarding are becoming popular ways to recreate on snow outside of a ski resort setting. However, there are additional dangers that come from skiing on ungroomed snow outside of a ski resort. Avalanche forecasters integrate daily snow observations with weather forecasts and snowpack history to issue daily estimates of how likely avalanches are. For this project, I collaborate with the Mount Shasta Avalanche Center and the US Forest Service to visualize historic avalanche data and develop probabilistic models to help avalanche forecasters better predict avalanches. The project involves webscraping, database design, probabilistic models, and human decision making in the backcountry.The key collaborators on this project are Avalanche Forecasters Nick Meyers, Casey Glaubman, Eric Falconer, and Sam Clairemont of the Mount Shasta Avalanche Center. Read more about the project here.\nMost recently, I was the Global Environmental Change Fellow at Berkeley Institute for Data Science (BIDS) working at the intersection between invasive species, climate change and wildfire in Californian ecosystems. My project involved developing probabilistic models to work across environmental scales to understand wildfire spread and impact. I was also the Data Science Communications Manager at BIDS. My projects in this role included visual and written science communications (sci-comm) articles, websites, data visualizations, illustrations, and infographics of data intensive projects across the institute.\nAs an NSF Graduate Research Fellow, I studied the effects of elevated atmospheric carbon dioxide and water availability on plant growth. I then blended this knowledge of plant metabolism with computational biology to build genetically informed mathematical models of plant growth as part of an NSF postdoctoral fellowship at UC Davis. Recently, I co-founded and was the VP of Genomics at Rev Genomics, which uses genomics, statistics, molecular genetics, and tissue culture to create new strains of Cannabis for the legal market. Rev Genomics was funded by Y-Combinator and other prominent Silicon Valley venture capital firms and continues to innovate in the Cannabis biotech space.\nIf you are interested in art, science and adventure check out my Montology Zine series. You can order zines through my Etsy Shop or Sign-up for the newsletter if you want to stay in the loop on new issues.\n\nProjects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAvalanche Data Science\n\n\n–Models for Northern California Avalanche Prediction and Forecasting\n\n\n\n\n\n\n\n\n\n\n\n\nBerkeley Institute for Data Science\n\n\n–Interactions between biodiversity and fire in California ecosystems\n\n\n\n\n\n\n\n\n\n\n\n\nRev Genomics\n\n\n–Biotech company making new strains of Cannabis\n\n\n\n\n\n\n\n\n\n\n\n\nPostdoc\n\n\n–NSF Postdoctoral Research Fellowship Projects\n\n\n\n\n\n\n\n\n\n\n\n\nDr. Sharon Gray Foundation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhD Projects\n\n\nNSF Graduate Research Fellowship\n\n\n\n\n\n\n\n\n\n\n\n\nEngineering Projects\n\n\n–Scientific equipment design, builds and controlling software development\n\n\n\n\n\n\n\n\n\n\n\n\nScience Teaching and Mentoring\n\n\n– Philosophy of Learning\n\n\n\n\n\n\n\n\n\n\n\n\nUndergraduate Research Projects\n\n\n–Senior Distinction Project and other original research\n\n\n\n\n\n\n\n\n\n\n\n\nSci-Comm Projects\n\n\n–Visual and Written Communications Projects\n\n\n\n\n\n\n\n\n\n\n\n\nHackathons - ArtScienceHack v1.0 + v2.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Art of Science 2.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThreatened Species Survey\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlants iView - Middle School Science\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNational Pollinator Week\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInternational Impact\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "art.html",
    "href": "art.html",
    "title": "Art",
    "section": "",
    "text": "Making things and drawing have been a part of my life since I was a child. The techniques have (hopefully) gotten better, but my childlike curiosity of filtering what I see remains a deep part of my experience as a human. Below the art is sorted by date. You can also choose a category on the right to see art related only to that category.\nIf you are interested in art, science and adventure check out my Montology Zine series. You can order zines through my Etsy Shop or Sign-up for the newsletter if you want to stay in the loop on new issues.\nI co-founded a gallery/classroom/studio space in Dunsmuir, CA called Darmera Studios. Darmera is an art studio dedicated to the natural world and community. We opened our doors May 4, 2024. Sign-up for our newsletter containing information about gallery shows, classes, workshops, and events.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "CV",
    "section": "",
    "text": "Current Affiliations\n\nFounder Montology Studios - Adventure Zines, Illustrations, Bicycle Repair 2023-present\nCo-Founder Darmera Studios - Art Gallery + Classroom 2023-present\nBoard of Directors - Friends of the Mount Shasta Avalanche Center - 2024-present\nShasta Alpine Hut Caretaker - Sierra Club Foundation 2024-present\n\n\n\nPrevious Affiliations\n\nBIDS Global Environmental Change Fellow- Berkeley Institute for Data Science (BIDS) 2021-24\nData Science Communications Manager Berkeley Institute for Data Science (BIDS) 2023-24\nCo-Founder and VP of Genomics - Rev Genomics 2016-20\nNSF Postdoctoral Fellow - UC Davis Department of Plant Biology 2014-17\nUC Davis Data Science Initiative 2016-17\nPostdoctoral Scholar - UC Davis Department of Plant Biology 2012-14\nNSF Graduate Fellow - University of Illinois Department of Plant Biology 2009-12\n\n\n\nEducation\n\nPh.D. Plant Biology, University of Illinois at Urbana-Champaign - 2012\nB.S. Integrative Biology, Minor: Chemistry, University of Illinois at Urbana-Champaign - 2007\n\n\n\n\nGrants, Fellowships, and Awards\n\nPI: Accenture Global Environmental Change Fellowship ($198,000)- 2021-23\nPI: NSF- Postdoctoral Fellowships in Biology- Develop a systems level model of resource allocation and partitioning in Brassica rapa to predict growth across multiple genotypes and environments. Plant Genome Research Program ($216,000) - 2014-17\n\nPI: Physiological systems biology of secondary metabolism in Brassica rapa leaves. Amaryllis Nucleics Research Grant ($9600)- 2016\n\nPI: Developing distributed image processing pipelines for plant growth phenotyping using Docker container based NVIDIA GPU Amazon EC2 instances. Amazon Web Services Research Grant ($5600). - 2015-2016\n\nCollaborator: Genotyping by Sequencing and Detection of eQTLs in a Recombinant Inbred Line Population of Brassica rapa. TACC Lonestar4 Super Computer Cluster (260,000 Units). - 2013-14\n\nPI: National Science Foundation Graduate Research Fellowship ($135,000) - 2009-12\nCo-PI: Project Leader, ASPB Education Foundation Grant- Plants iView ($20,000) - 2011-12\nCo-PI: Project Leader, UIUC Public Engagement Grant- Plants iView ($12,500) - 2011-12\nOutstanding Teaching Award- UIUC Department of Plant Biology ($400) - 2012\nGovindjee Award for Excellence in Biological Science ($1000) - 2011\nPI: Francis M. and Harlie M. Clark Research Grant ($1,000) - 2010\nPI: Francis M. and Harlie M. Clark Research Grant ($1,000) - 2009\nDistinction- School of Integrative Biology. Thesis Title: “How will elevated [CO2] alter soil and plant water status of the C3-crop soybean and the C4-crop maize?” Published as part of Hussain et al. (2013). - 2007\nTotal Academic Awards: $600,100\n\n\n\n\nPublications\nGoogle Scholar Profile\nCitations: 930\nH-Index: 14\n\nHolmquist AJ, Markelz RJC, Martinez CC, Gillespie RG (2024). The importance of habitat type and historical fire regimes in arthropod community response following large-scale wildfires. Global Change Biology (30:1). paper\nVan Tuyl, Steve (Ed.). (2023). Hiring, Managing, and Retaining Data Scientists and Research Software Engineers in Academia: A Career Guidebook from ADSA and US-RSE. Zenodo. Book\nBaker RL, Leong W, Brock MT, Rubin MJ, Markelz RJC, Welch S, Maloof JN, Weinig C (2019) Integrating transcriptomic network reconstruction and QTL analyses reveals mechanistic connections between genomic architecture and Brassica rapa development. PLoS Genetics 15 (9), e1008367. paper\nMarkelz RJC 1,Covington MF 1, Devisetty UK, Brock M, Weinig C, Ma. oof JN (2017) Using RNA-Seq for genomic scaffold placement, correcting assemblies, and genetic map creation in a common Brassica rapa mapping population. G3. paper 1Equal contribution.\nBucksch A, Atta-Boateng A, Azihou AF, Battogtokh D, Baumgartner A, Binder BM, Braybrook SA, Chang C, Coneva V, DeWitt TJ, Fletcher AG, Gehan MA, Diaz -Martinez DH, Hong L, Iyer -Pascuzzi AS, Klein LL, Leiboff S, Li M, Lynch JP, Maizel A, Maloof JN, Markelz RJC, Martinez CC, Miller LA, Mio W, Palubicki W, Poorter H, Pradal C, Price CA, Puttonen E, Reese JB, Rellán-Álvarez R, Spalding EP, Sparks EE, Topp CN, Williams JH and Chitwood DH (2017) Morphological plant modeling: unleashing geometric and topological potential within the plant sciences. Frontiers in Plant Science. 8:900. doi: 10.3389/fpls.2017.00900 paper\nAn N, Welch SM, Markelz RJC, Baker RL, Palmer CM, Ta J, Maloof JN, Weinig C (2017) Using photogrammetry and plant modeling techniques to quantify 2D and 3D rossette area for time-series high-throughput phenotyping. Computers and Electronics in Agriculture. 135: 222-232 paper\nAn N, Palmer CM, Baker RL, Markelz RJC, Ta JT, Covington MF, Maloof JN, Welch SM, Weinig C (2016) Plant High-Throughput Phenotyping Using Photogrammetry and imaging Techniques to Measure Leaf Length and Rosette Area. Computers and Electronics in Agriculture. 127:376-394 paper\nBrock MT, Lucas L, Anderson N, Rubin M, Markelz RJC, Covington MF, Devisetty UK, Chapple C, Maloof JN, Weinig C (2016) Genetic architecture, biochemical underpinnings, and ecological impact of floral UV patterning. Molecular Ecology. 25:1122-1140 paper\nBaker RL, Leong WF, Brock MT, Markelz RJC, Covington MF, Devisetty UK, Maloof JN, Welch S, Weinig C (2015) Modeling development and quantitative trait mapping reveal independent genetic modules for leaf size and shape. New Phytologist. 208: 257–268. paper\nMarkelz RJC, Vosseller LN, Leakey ADB (2014) Elevated CO2 concentration induces transcriptional reprogramming of respiration and a stimulation of dark respiration as Arabidopsis thaliana leaves transition from sinks to sources. Plant, Cell, and Environment. 37:2542-2552. paper\nMarkelz RJC, Lai LX, Vosseller LN, Leakey ADB (2014) The stimulation of leaf respiration and transcriptional reprogramming by elevated CO2 concentration is diminished, but not eliminated, under limiting nitrogen supply. Plant, Cell, and Environment. 37:886-898. paper\nHussain MZ, VanLoocke A, Markelz RJC, Leakey ADB, Ort DO, Bernacchi CJ (2013) Future carbon dioxide concentration decreases canopy evapotranspiration and soil water depletion by field-grown maize. Global Change Biology. 19:1572–1584. paper\nWalters KR, Rupassara SI, Markelz RJC, Leakey ADB, Muir W, Pittendrigh B (2012) Methamphetamine causes anorexia in Drosophila melanogaster, exhausting metabolic reserves and contributing to mortality. The Journal of Toxicological Sciences. 4:773-790. paper\nGillespie KM, Xu F, Richter KT, McGrath JM, Markelz RJC, Ort DR, Leakey DB, Ainsworth EA (2012) Greater antioxidant and respiratory metabolism in field-grown soybean exposed to elevated O3 under both ambient and elevated CO2 Concentrations. Plant, Cell, and Environment. 35:164-184. paper\nMarkelz RJC, Strellner RS, Leakey ADB (2011) Impairment of C4 photosynthesis by drought is exacerbated by limiting nitrogen and ameliorated by elevated [CO2] in maize. Journal of Experimental Botany. 62:3235-3246. paper\nLeakey ADB, Ainsworth EA, Bernard SM, Markelz RJC, Ort DR, Placella S, Rogers A, Smith MD, Sudderth EA, Weston DJ, Wullschleger SD, Yuan S (2009) Gene expression profiling – opening the black box of plant ecosystem responses to global change. Global Change Biology. 15:1201-1213. paper\n\n\n\n\nInvited Talks\n\nData Landscapes: Visual Storytelling of California’s Fiery and Frosty Extremes (2024) - BIDS Research Talks. UC Berkeley, CA\nScaling Fire - Merging Satellite data with eDNA to understand fire recovery in California Ecosystems (2023) - Ethical AI and Generative AI Leadership Summit. UC Berkeley, CA\nUsing Data Science to Understand California Ecosystem Responses to Fire (2022) Data & AI Innovation Day - Accenture. San Francisco, CA\nThe impact of fire on California Arthropods and fire data science techniques (2022) USFS Region 5 Hydrology Meeting, Online.\nThe impact of fire on California Arthropods (2021) UC Berkeley Accenture Day. Berkeley, CA.\nFull Stack Biology: Moving freely between biological layers with databases, statistics, and network modeling (2017) Phenome 2017. Tucson, AZ.\nWhole plant systems biology: a Brassica rapa exemplar (2016). Plant Research Lab- Michigan State University. East Lansing, MI.\nConnecting genotype to phenotype in Brassica rapa using statistical and computational techniques (2015). University of Minnesota, St. Paul, MN.\nSystems biology of plant competition in Brassica rapa (2014). Plant Genome Research Program- National Science Foundation. Arlington, VA.\nAdapting crops to global climate change (2009). Darwin 200: A South American celebration. Maldonado, Uruguay.\n\n\n\nContributed Talks\n\nCross-Domain Workshops (XDs) - ImageXD, AudioXD, TextXD - ADSA Annual meeting. San Antonio, TX. - 2023\nASPB Annual Meeting. Austin, TX. - 2016\nNorth American Arabidopsis Steering Committee Focus Group- Training the next generation of quantitative plant biologists. Phoenix, AZ. - 2016\nUC Davis Postdoctoral Research Symposium– Big Data Session. Davis, CA. - 2015\nUC Davis Plant Cell Biology Retreat. Davis, CA. - 2015\nUC Davis Plant Cell Biology Retreat. Marconi Historic Park, CA. - 2014\nUC Davis Postdoctoral Seminar Series. Davis, CA. - 2013\nUC Davis Plant Cell Biology Retreat. Asilomar, CA. - 2013\nASPB Annual Meeting. Austin, TX. - 2012\nUIUC Graduate Students in Ecology and Evolutionary Biology Symposium, Urbana, Illinois. - 2010\nProctor and Gamble Student Research Competition. Urbana, IL. - 2007\n\n\n\nContributed Posters\n\nASPB Annual Meeting. Austin, TX. - 2016\nUC Davis Postdoctoral Research Symposium. Davis, CA. - 2016\nProbabilistic Modeling in Genomics, CSHL, NY. - 2015\nNational Science Foundation, Arlington, VA. - 2015\nASPB Annual Meeting, Minneapolis, MN - 2015\nPlant Animal Genome, San Diego, CA. Poster Presentation. - 2015\nNational Science Foundation, Arlington, VA. - 2014\nASPB Annual Meeting. Portland, OR. Poster- 2014\nKeystone Symposium: Plant Abiotic Stress and Sustainable Agriculture. Taos, NM. - 2013\nASPB Annual Meeting. Austin, TX. - 2012\nWorld Crop FACE Workshop, Tsukuba, Japan. - 2012\nUniversity of Illinois Public Engagement Symposium: Transforming Our Society. Champaign, IL. - 2012\n8th Okazaki Biology Conference, Okazaki, Japan.- 2012\nUIUC Plant Biology Departmental Fall Welcome. Urbana, IL. - 2011\nInstitute for Genomic Biology Fellows Symposium. Poster Presentation. - 2011\nPlant respiration and climate change. Oxford, United Kingdom. - 2010\nASPB Annual Meeting. Honolulu, Hawaii. - 2009\nASPB Annual Meeting. Merida, Mexico. - 2008\n\n\n\n\nTeaching\n\nAdvanced Nature Journaling - Darmera Studios 2025-Present\nAdvanced Watercolor, Ink, Gouache - Darmera Studios 2025-Present\nIntroduction to Watercolor, Ink, Gouache - Darmera Studios 2024-Present\nIntroduction to Nature Journaling - Darmera Studios 2024-Present\nArt Fundamentals - Darmera Studios 2024-Present\nGuest Lecturer - Biogeography of the Bay Area- Fire Ecology Field Course 2023\nCritiques- Landscape Architecture Graduate Design Studio 438- University of Illinois - Experimental Design Thinking 2022\nGuest Lecturer- Landscape Architecture Graduate Design Studio 438- University of Illinois - Experimental Design Thinking 2021\nGuest Lecturer- Emerging Technologies- Kent School of Law - Biotech approaches to improving crops for a changing world 2020\nCo-instructor- PBI200C- Plant Biology Graduate Group Core, Plant Primary Productivity: Environmental Impacts on C-Fixation. Mathematical model based instruction using photosynthesis simulations. 2016\nGuest Instructor- BIS180L- Undergraduate Bioinformatics Lab. Genetic Networks 1: Clustering, Genetic Networks 2: Co-expression, 2015\nGuest Lecturer- Plant Biology 220: Plant Developmental Biology. QTL mapping with -omics scale data - 2015\nCo-instructor and Discussion Leader of General Education Class- Integrative Biology 107: Global Warming, Biofuels, and Food - 2011 List of Teachers Ranked Excellent by Their Students; Outstanding Teaching Award Department of Plant Biology\nTeaching Assistant- Integrative Biology 440: Plants and Global Change. Developed science communication module- Graduate students and undergraduates created Podcasts for primary climate change literature. - 2009\n\n\n\nShort Courses and Workshops\n\nUnited Bicycle Institute - DT Swiss - Certified Wheel Builder - 2024\nUnited Bicycle Institute - Certified Suspension Technician + Fox Shocks- 2024\nUnited Bicycle Institute - Advanced Bicycle Repair - Certified Bicycle Mechanic - 2023\nSpecies distribution modeling with Bayesian statistics in R - 2021\nMerging Crop Models and Genetics, University of Florida - 2015\nPathway Tools for Metabolic Modeling, SRI International - 2015\nSummer Institute in Statistical Genetics, University of Washington - 2014\nComputing in the Cloud: What Every Computational Life Scientist Should Know, NIMBioS, University of Tennessee - 2014\nFrontiers and Techniques in Plant Science- Cold Spring Harbor Laboratory - 2010\n\n\n\n\nMentoring\n\nAnna Holmquist (ESPM PhD Student, UC Berkeley) - 2021-2023\nLakshmi Pabbisetty (Biology, UC Davis) - 2015-2017\nChristina Day (Biology, UC Davis) - 2013-2017\nAmanjot Kaur (Biotechnology, UC Davis) - 2014-2015\nNeije Mukherjee-Roy (Microbiology, UC Davis) - 2015\nJames Ta (Junior Specialist, UC Davis) - Graduate Student Biophysics UC Davis 2014-2015\nTiffany Ho (Genetics, Bioinformatics, UC Davis) - Graduate Student at Cornell University - 2014-2015\nShweta Dash (Biology, UC Davis) - 2015\nKamalpreet Sahota (Religious Studies, Biology- UC Davis) – Graduate Student at Touro University - 2013-14\nNavi Singh (Biology- UC Davis) - 2013-14\nWilliam Landel (Plant Biology- UC Davis) - 2013\nKisha Thayapran (High School Student) - UC Davis Young Scholar - 2013\nNatalia Rodriquez (High School Student - Puerto Rico) RAP2 Program 2012\nLauren Vosseller (Molecular and Cellular Biology- University of Illinois) - Co-Author, Graduate Student University of Illinois- Chicago - 2010-12\nAlexander Petit (History- University of Illinois) - James Scholar Program\nBrian Zehr (IB- University of Illinois)- India rural eye-care network - 2010-11\nRyan Boyd (IB- University of Illinois) - Graduate student at Washington State University - 2009-10\nReid Strellner (IB- University of Illinois) - Co-author, Graduate student at Northwestern University - 2008-10\nDerek Haselhorst (IB- University of Illinois) - Graduate Student at University of Illinois- Urbana - 2008\n\n\n\n\nProfessional and Volunteer Service\n\nModerator : Data Science by Design 2021\nManuscript Reviewer: eLife; American Journal of Botany; Journal of Experimental Botany; Photosynthesis Research; Plant, Cell, and Environment- 2009-2017\nTechnical Editor: Bioinformatics Data Skills, Vince Buffalo, O’Reilly Publishing - 2013-2015\nOrganizer and Leader of Graduate Student Grant Writing: Plants iView - Middle School Plant Science Outreach ; successfully obtained funding from ASPB and UIUC. 2011-2012\nCreator: Plant Carbon Allocation Relay Race for K-12 Science Teachers Workshop for Ecosystem Ecology - 2012\nThe Art of Science 2.0 - I collaborated with an artist to blend disciplines and create art by visualizing biological processes using confocal microscopy. - 2012\nPresenter: Microscopy Outreach Event- Mahomet Seymour Junior High School Science Club - 2012\nOrganizer: National Pollinator Week - 2010 and 2011\nChair: Plant Biology Graduate Student Association - 2010-11\nRoots and Shoots, University of Illinois Branch - 2010\nDepartmental Colloquium Coordinator: Plant Biology Graduate Student Association - 2009-10\nThreatened Species Survey, Grampians National Park, Victoria, Australia - 2008\nInternational Impact, fund raising and school building project for small Ecuadorian Indigenous communities - 2005-07\n\n\n\nUnpaid Science Consulting\n\nJustin Gillis- NY Times Science Reporter 2011 HARVEST Article\nLI-COR Environmental 2011"
  },
  {
    "objectID": "posts/2015-01-01-ArtScienceHack.html",
    "href": "posts/2015-01-01-ArtScienceHack.html",
    "title": "Art Science Hackathon v1.0",
    "section": "",
    "text": "Concept\nI have two really good friends that are both professional designers/artists living in Chicago. Every year over the holiday break we would discuss how fun it would be to do a collaborative project, but never got around to doing one because of our busy schedules. This year we planned a few months in advance to have a hackathon style four day work session between Christmas and New Years. We wanted to move as quickly as possible and make as many ideas happen as possible in our short time frame. We discussed all of the different data sets that I had as part of various research projects and the ones that turned out to be most appealing were the high-throughput plant imaging data sets.\nRead more about the second ArtScienceHack here.\n\n\nCrew\nJohnny Clark is an architect and designer currently working for Jordan Mozer. The Mozer firm’s was our home base for creativity, industrial grade internet, and organic shape object art inspiration. Matt Harlan is a freelance designer and screen printing guru. Matt also works on this awesome architecture zine called soiled. And myself.\n\n\nArabidopsis thaliana architectural forms\nI just learned Rhino about four hours earlier so this was a successful visualization of an Arabidopsis growth time series. This is a mosaic of the steps in constructing this city. As part of another project in the lab I have thousands of Arabidopsis timelapse images. I quickly modified some other code for a quick python script to binerize the plant relative to the background and then quantified plant area in each successive image. The height of the buildings correspond to the difference in rosette size from the previous timepoint. Then I got to really have fun and make a skyline and city in the shape of one of the plant outlines. Moving around the city that I had just made was really trippy especially when doing it from a 6 foot tall person perspective. The upper right is a view from the skydeck of a building. Johnny helped me make the surface transparent to give it a glass coffeetable feel. I think overall this project might help me pass Architecture 101.\n\nArabidopsis City visualization using rosette growth data:\n\n\n\n\n\nBrassica rapa architectural forms\nFor another lab project I am doing some 3D reconstructions of Brassica rapa. I have loads of this kind of data, but thought it would be nice to see what an artist’s perspective might use the data for. First things first, it was much too dense to load into memory so we randomly sampled the point cloud and made some wire frames by nearest neighbor searches. The renderings are simple and elegant. Then Johnny took it to the next level with a Rhino plugin called Grasshopper to produce the metaball renderings and octree representations of the data. A free plugin that might make the cost of Rhino worth it.\n\nThe original 3D data of a brassica plant:\n\n\n\nBrassica rapa sparse proximity structure:\n\n\n\nBrassica rapa metaball space structure:"
  },
  {
    "objectID": "posts/2022-05-15-bayareainsects/index.html",
    "href": "posts/2022-05-15-bayareainsects/index.html",
    "title": "Bay Area Insects",
    "section": "",
    "text": "I am working on a project using data collected at some of the UC Reserves. I needed to see what observations of insects were available in GBIF.\nI found this drawing tool for bounding boxes. Make sure to export it as OGC WKT and then you can create a POLYGON to use as your query area.\n\nreserve_geometry &lt;- paste('POLYGON((-121.383275382 35.7567710044, -121.9875234289 36.3607073262, -122.525853507 37.2841110386, -123.1520742101 38.0753438834, -123.7123769445 38.8153202525, -123.8332265539 39.0972469563, -123.4596913976 39.2930774901, -122.0644277258 39.2250244313, -121.7568105383 38.0320888877, -121.4052480383 37.2578829342, -121.119603507 36.7402099684, -120.9987538976 36.1303379589, -121.383275382 35.7567710044))')\n\nLoad the libraries.\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(maps)\n\nQuery the greater Bay Area for insects using the classKey for Insecta using the above geometry. Make a new dataframe with only the data from the query for plotting and data manipulation.\n\ninsect &lt;- occ_data(classKey = 216, hasCoordinate = TRUE, limit = 1000, geometry = reserve_geometry)\ninsect_coords &lt;- insect$data\nhead(insect_coords)\n\n# A tibble: 6 × 78\n  key     scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n1 401151… Dishol…    37.5   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n2 401150… Dishol…    37.5   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n3 401170… Forfic…    37.5   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n4 401164… Danaus…    37.5   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n5 401182… Aphis …    37.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n6 401189… Vaness…    37.0   -122. cdc    50c950… 28eb1a… 997448… US      DWC_AR…\n# … with 68 more variables: lastCrawled &lt;chr&gt;, lastParsed &lt;chr&gt;, crawlId &lt;int&gt;,\n#   hostingOrganizationKey &lt;chr&gt;, basisOfRecord &lt;chr&gt;, occurrenceStatus &lt;chr&gt;,\n#   taxonKey &lt;int&gt;, kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;, classKey &lt;int&gt;,\n#   orderKey &lt;int&gt;, familyKey &lt;int&gt;, genusKey &lt;int&gt;, speciesKey &lt;int&gt;,\n#   acceptedTaxonKey &lt;int&gt;, acceptedScientificName &lt;chr&gt;, kingdom &lt;chr&gt;,\n#   phylum &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   genericName &lt;chr&gt;, specificEpithet &lt;chr&gt;, taxonRank &lt;chr&gt;, …\n\n\nVisualize the data for the state of California.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(insect_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\n\n\n\n\nRandomly subset the coordinates dataframe and plot species by color. If you have a large screen, you can make a larger plotting window with many more species than 25.\n\nset.seed(25344)\ninsect_coords_25 &lt;- sample_n(insect_coords, 25)\nspecies_plot1  &lt;- ggplot(insect_coords_25, aes(x=decimalLongitude, y = decimalLatitude, color =acceptedScientificName)) +\n       geom_point() + labs(x = \"Longitude\", y = \"Latitude\", color = \"Species\", title = \"Bay Area Insect Distributions\")\nspecies_plot1\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/bay_area_insects.png\")"
  },
  {
    "objectID": "posts/2024-01-05-MtShasta-summit-pass-data.html",
    "href": "posts/2024-01-05-MtShasta-summit-pass-data.html",
    "title": "Mount Shasta Summit Pass Data",
    "section": "",
    "text": "I am collaborating with the Mount Shasta Avalanche Center to visualize data sets and build models to help them forecast avalanches in the area better. A small dataset that they have been collecting since 1992 is the number of Summit Passes sold along with the Search and Rescue (SAR) activities that the Rangers perform. This data is available in the Avalanche Center Annual Reports and SAR statistics.\nSee the other posts in the Avalanche Data series: Post 1, Post 2, Post 3 and Post 4.\nHere are a few plots I made for the upcoming reports.\nLoad the libraries and in-file the data.\n\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(gridExtra)\n\n# Read in the CSV file\npass_data &lt;- read.csv(\"~/DATA/data/mount-shasta-summit-pass-data.csv\")\n\nI always take a quick look at the data to make sure it infiled correctly.\n\nhead(pass_data)\n\n  YEAR SUMMIT.PASSES.SOLD FATALITIES SEARCH RESCUE SELF.RESCUE Total\n1 1992                  0          0      0      3           0     0\n2 1992                  0          0      0      0           0     0\n3 1993                  0          1      0      3           0     0\n4 1994                  0          1      0      4           0     0\n5 1995                  0          1      0      3           0     0\n6 1996                  0          0      0      4           0     0\n\nsummary(pass_data)\n\n      YEAR      SUMMIT.PASSES.SOLD   FATALITIES         SEARCH      \n Min.   :1992   Min.   :   0       Min.   :0.0000   Min.   : 0.000  \n 1st Qu.:1999   1st Qu.:4532       1st Qu.:0.0000   1st Qu.: 1.000  \n Median :2008   Median :5592       Median :1.0000   Median : 3.000  \n Mean   :2008   Mean   :5084       Mean   :0.8182   Mean   : 2.941  \n 3rd Qu.:2016   3rd Qu.:6758       3rd Qu.:1.0000   3rd Qu.: 4.000  \n Max.   :2024   Max.   :9349       Max.   :3.0000   Max.   :10.000  \n                                   NA's   :1                        \n     RESCUE        SELF.RESCUE         Total      \n Min.   : 0.000   Min.   : 0.000   Min.   : 0.00  \n 1st Qu.: 4.000   1st Qu.: 0.000   1st Qu.: 9.00  \n Median : 6.000   Median : 2.000   Median :11.50  \n Mean   : 8.029   Mean   : 4.441   Mean   :15.62  \n 3rd Qu.:10.000   3rd Qu.: 5.750   3rd Qu.:20.00  \n Max.   :32.000   Max.   :20.000   Max.   :54.00  \n                                                  \n\n\nTransform the data into long format for easier plotting.\n\ndata_long &lt;- pass_data %&gt;% \n  pivot_longer(cols = c(\"FATALITIES\", \"SEARCH\",\"RESCUE\",\"SELF.RESCUE\"), \n               names_to = \"variable\", \n               values_to = \"value\")\n\nCreate the base plots for summit passes sold and the other Search and Rescue statistics collected.\n\nsummit_pass1 &lt;- ggplot() +\n  geom_line(data = pass_data, aes(x = YEAR, y = SUMMIT.PASSES.SOLD), color = \"blue\", size = 1) +\n  scale_y_continuous(name = \"Summit Passes Sold\") +\n  theme_minimal() +\n  labs(x = \"Year\")\nsummit_pass1\n\n\n\n\n\n\n\nSAR_1 &lt;- ggplot() +\n  geom_bar(data = data_long, aes(x = YEAR, y = value, fill = variable), stat = \"identity\", position = position_dodge()) +\n  scale_y_continuous(name = \"Number of Incidents\") +\n  theme_minimal() +\n  labs( x = \"Year\", fill = \"\")\nSAR_1\n\n\n\n\n\n\n\n\nI like to default to a minimal theme to see how it looks and then add gridlines and color back to the plots. Minimal plots are great for people who are used to looking at plots, however the end readers of this report are mostly from the general public so I decided to add in each year along the x-axis. I want to stack the plots so I will also move the legend for the SAR data to the bottom.\n\nsummit_pass2 &lt;- ggplot() +\n  geom_line(data = pass_data, aes(x = YEAR, y = SUMMIT.PASSES.SOLD), color = \"blue\", size = 1) +\n  scale_x_continuous(breaks = seq(1992, 2024, 1))  +\n  scale_y_continuous(name = \"Summit Passes Sold\") +\n  theme(axis.text.x = element_text(angle = -75, vjust = 0.5)) +\n  labs(x = \"Year\")\nsummit_pass2\n\n\n\n\n\n\n\nSAR_2 &lt;- ggplot() +\n  geom_bar(data = data_long, aes(x = YEAR, y = value, fill = variable), stat = \"identity\", position = position_dodge()) +\n  scale_x_continuous(breaks = seq(1992, 2024, 1))  +\n  scale_y_continuous(name = \"Number of Incidents\") +\n  theme(legend.position=\"bottom\", \n        axis.text.x = element_text(angle = -75, vjust = 0.5)) +\n  labs( x = \"Year\", fill = \"\")\nSAR_2\n\n\n\n\n\n\n\n\nUsing the gridExtra package we can combine the plots we already generated.\n\ncombined_plot &lt;- grid.arrange(summit_pass2, SAR_2)\n\n\n\n\n\n\n\ncombined_plot\n\nTableGrob (2 x 1) \"arrange\": 2 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (2-2,1-1) arrange gtable[layout]\n\n\nThese plots are going to be published and printed so we want to make sure they are large enough and have at least a 300 dpi resolution.\n\nggsave(plot = summit_pass2, \"~/DATA/images/summit-passes.png\", width = 10, dpi = 300)\n\nggsave(plot = SAR_2, \"~/DATA/images/sar-metrics.png\", width = 10, dpi = 300)\n\nggsave(plot = combined_plot, \"~/DATA/images/pass-sar-metrics.png\", width = 10, height = 8, dpi = 300)\n\nThere we have it. Some basic tidy-verse plots for inclusion in the Annual and SAR reports.\nSee the other posts in the Avalanche Data series: Post 1, Post 2, Post 3 and Post 4."
  },
  {
    "objectID": "posts/2022-01-01-Obsidian-Bibliography.html",
    "href": "posts/2022-01-01-Obsidian-Bibliography.html",
    "title": "Zotero + Obsidian",
    "section": "",
    "text": "Bibliography Software + Obsidian\nKeeping track of scientific papers, code tutorials and snippets, as well as highlighting from digital books has gotten a lot easier of over the past few years. Check out Zotero here. If you are completely new to Zotero work through this quickstart tutorial by Kartcher and Zelle. I have been using Zotero almost exclusively for the past 11 years for PDF management because it has plugins for Word or Google documents to quickly create linked bibliographies for research papers. The stand alone version of the Zotero App has various plugins that make it an even better research tool for my workflow. As an example, the Firefox plugin allows you to click the icon in the browser tab and save the content, webpage, or PDF to the open folder in your Zotero library. This makes it really fast to accumulate papers and resources to read and take notes offline for research projects.\nTwo of the newer plug-ins that I use most often are Zotfile and mdnotes. When I take notes or highlight sections in a PDF as part of my research workflow I use the Zotfile PDF highlighter extraction tool to create a text file of these items. The Zotfile highlighter extraction tool output saves within Zotero so it is connected to the PDF and bibliography meta-data. I then right click on these and use mdnotes to export them to a markdown file in my Obsidian Notes directory. I have mdnotes set-up to automatically use this Obsidian directory and create a markdown flavored hyperlink back to the PDF in Zotero. If I am working in Obsidian and I want to go back to the original paper where the note was taken from, the hyperlink will open the PDF from Zotero in the exact spot where the note was taken. A very handy feature for research projects.\nThe final Zotero tool I will mention is Better Bibtex. Better Bibtex allows you to manage bibliographies easier if you are authoring research papers in markdown or other LaTex flavored workflows. It is suggested you install this tool before installing Zotfile or mdnotes.\nHappy Researching!"
  },
  {
    "objectID": "posts/2022-01-15-scraping-weather-data/index.html",
    "href": "posts/2022-01-15-scraping-weather-data/index.html",
    "title": "Scraping Weather Data",
    "section": "",
    "text": "A quick post showing how to extract data from a website and make a few plots. I chose the Mount Shasta Avalanche Center data because I monitor this everyday throughout the season to see how the avalanche forecast changes and how the snowpack is developing.\n\nR vest\nThere is a great website scraping package that is part of the tidyverse called Rvest. Check out the Documentation.\n\nlibrary(rvest)\nlibrary(tidyverse)\nlibrary(lubridate)\n\n\nhtml &lt;- read_html(\"https://www.shastaavalanche.org/page/seasonal-weather-history-mount-shasta\")\n\n# right click on the page to see the table\nhtml %&gt;%\n    html_element(\".msac-wx-history-table\") %&gt;%\n    html_table()\n\n# A tibble: 13 × 2\n   `Weather History Summary from Oct 1, 2022 to Mar 29, 2023` Weather History …¹\n   &lt;chr&gt;                                                                   &lt;dbl&gt;\n 1 Temp Max (°F)                                                            49  \n 2 Temp Min (°F)                                                             3  \n 3 Temp Avg (°F)                                                            24  \n 4 Wind Max (mi/hr)                                                         68.5\n 5 Wind Min (mi/hr)                                                          0  \n 6 Wind Avg (mi/hr)                                                         12  \n 7 Wind Gust Max (mi/hr)                                                   110. \n 8 Total Snowfall (in)                                                     327. \n 9 Total Accumulated Precipitation (Water Equivalent) (in)                  28.4\n10 Max Snowfall in 24 Hrs (in)                                              36.2\n11 Snow Depth Max (in)                                                     212. \n12 Snow Depth Min (in)                                                      31.9\n13 Snow Depth Avg (in)                                                     124  \n# … with abbreviated variable name\n#   ¹​`Weather History Summary from Oct 1, 2022 to Mar 29, 2023`\n\n\n\n# Right click on the page and get the xpath to a specific table\nxpath &lt;- \"/html/body/div[2]/main/div/article/div/table[2]\"\nweather &lt;- html_nodes(html, xpath = xpath)\nhtml_table(weather)\n\n[[1]]\n# A tibble: 131 × 21\n   Observed an…¹ Obser…² Obser…³ Obser…⁴ Obser…⁵ Obser…⁶ Obser…⁷ Obser…⁸ Obser…⁹\n   &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1 \"\"            Ob Tem… Ob Tem… Ob Tem… Ob Win… Ob Win… Ob Win… Ob Win… Ob Win…\n 2 \"Date\"        Min     Max     Avg     Min     Max     Avg     Gust    Dir    \n 3 \"2023 03/28\"  16.5    23.5    18      5.5     20      9.5     42.93   SSE    \n 4 \"2023 03/27\"  16.5    23.5    18      5.5     20      11.5    42.93   SSE    \n 5 \"2023 03/26\"  4       28      15.5    1       10.5    5.5     24.54   SE     \n 6 \"2023 03/25\"  6.5     22      15      5.5     33.5    16.5    67.47   NW     \n 7 \"2023 03/24\"  5       24      14.5    4.5     39      22      61.34   NW     \n 8 \"2023 03/23\"  12.5    29      19.5    8.5     39      20      67.47   WNW    \n 9 \"2023 03/22\"  19      28.5    23.5    7       11.5    10      30.66   WNW    \n10 \"2023 03/21\"  19      28.5    23.5    4.5     37      25.5    67.47   E      \n# … with 121 more rows, 12 more variables:\n#   `Observed and Forecast Weather by Day` &lt;chr&gt;,\n#   `Observed and Forecast Weather by Day` &lt;chr&gt;,\n#   `Observed and Forecast Weather by Day` &lt;chr&gt;,\n#   `Observed and Forecast Weather by Day` &lt;chr&gt;,\n#   `Observed and Forecast Weather by Day` &lt;chr&gt;,\n#   `Observed and Forecast Weather by Day` &lt;chr&gt;, …\n\n\n\n# make a data.frame with the table\nweather2 &lt;- as.data.frame(html_table(weather, fill=TRUE))\n\n# rename columns\nnames(weather2) &lt;- paste(weather2[1,], weather2[2,])\nnames(weather2)\n\n [1] \" Date\"                       \"Ob Temp (°F) Min\"           \n [3] \"Ob Temp (°F) Max\"            \"Ob Temp (°F) Avg\"           \n [5] \"Ob Wind (mi/hr) Min\"         \"Ob Wind (mi/hr) Max\"        \n [7] \"Ob Wind (mi/hr) Avg\"         \"Ob Wind (mi/hr) Gust\"       \n [9] \"Ob Wind (mi/hr) Dir\"         \"Ob Snow (in) HS\"            \n[11] \"Ob Snow (in) HN24\"           \"Ob Snow (in) SWE\"           \n[13] \"Ob Snow (in) Total Snowfall\" \"Fx Temp (°F) Min\"           \n[15] \"Fx Temp (°F) Max\"            \"Fx Wind (mi/hr) Min\"        \n[17] \"Fx Wind (mi/hr) Max\"         \"Fx Snow (in) Min\"           \n[19] \"Fx Snow (in) Max\"            \"Fx Snow (in) SWE\"           \n[21] \"Fx Rating \"                 \n\nnames(weather2)[1] &lt;- paste(\"date\")\n\n# remove rows that are now column names\nweather2 &lt;- weather2[-c(1,2),]\n\n# take a look\nglimpse(weather2)\n\nRows: 129\nColumns: 21\n$ date                          &lt;chr&gt; \"2023 03/28\", \"2023 03/27\", \"2023 03/26\"…\n$ `Ob Temp (°F) Min`            &lt;chr&gt; \"16.5\", \"16.5\", \"4\", \"6.5\", \"5\", \"12.5\",…\n$ `Ob Temp (°F) Max`            &lt;chr&gt; \"23.5\", \"23.5\", \"28\", \"22\", \"24\", \"29\", …\n$ `Ob Temp (°F) Avg`            &lt;chr&gt; \"18\", \"18\", \"15.5\", \"15\", \"14.5\", \"19.5\"…\n$ `Ob Wind (mi/hr) Min`         &lt;chr&gt; \"5.5\", \"5.5\", \"1\", \"5.5\", \"4.5\", \"8.5\", …\n$ `Ob Wind (mi/hr) Max`         &lt;chr&gt; \"20\", \"20\", \"10.5\", \"33.5\", \"39\", \"39\", …\n$ `Ob Wind (mi/hr) Avg`         &lt;chr&gt; \"9.5\", \"11.5\", \"5.5\", \"16.5\", \"22\", \"20\"…\n$ `Ob Wind (mi/hr) Gust`        &lt;chr&gt; \"42.93\", \"42.93\", \"24.54\", \"67.47\", \"61.…\n$ `Ob Wind (mi/hr) Dir`         &lt;chr&gt; \"SSE\", \"SSE\", \"SE\", \"NW\", \"NW\", \"WNW\", \"…\n$ `Ob Snow (in) HS`             &lt;chr&gt; \"212.3\", \"211.1\", \"188.6\", \"190.9\", \"190…\n$ `Ob Snow (in) HN24`           &lt;chr&gt; \"9.5\", \"18.5\", \"0\", \"0.1\", \"0\", \"0\", \"0\"…\n$ `Ob Snow (in) SWE`            &lt;chr&gt; \"0\", \"0\", \"0.01\", \"0\", \"0.05\", \"0.16\", \"…\n$ `Ob Snow (in) Total Snowfall` &lt;chr&gt; \"310.8\", \"301.3\", \"282.8\", \"282.8\", \"282…\n$ `Fx Temp (°F) Min`            &lt;chr&gt; \"17\", \"18\", \"12\", \"11\", \"11\", \"14\", \"23\"…\n$ `Fx Temp (°F) Max`            &lt;chr&gt; \"30\", \"27\", \"27\", \"21\", \"22\", \"26\", \"33\"…\n$ `Fx Wind (mi/hr) Min`         &lt;chr&gt; \"15\", \"30\", \"25\", \"25\", \"30\", \"25\", \"10\"…\n$ `Fx Wind (mi/hr) Max`         &lt;chr&gt; \"25\", \"40\", \"35\", \"35\", \"40\", \"45\", \"20\"…\n$ `Fx Snow (in) Min`            &lt;chr&gt; \"5\", \"12\", \"0\", \"0\", \"2\", \"3\", \"2\", \"0\",…\n$ `Fx Snow (in) Max`            &lt;chr&gt; \"9.5\", \"18.5\", \"1.5\", \"1.5\", \"5\", \"7\", \"…\n$ `Fx Snow (in) SWE`            &lt;chr&gt; \"0.42\", \"1.01\", \"0.01\", \"0.03\", \"0.05\", …\n$ `Fx Rating `                  &lt;chr&gt; \"CON\", \"MOD\", \"MOD\", \"MOD\", \"LOW\", \"LOW\"…\n\n# columns that are numeric should be converted back to such. They were coerced into character vectors because of the first two rows were characters.\nweather2 &lt;- weather2 %&gt;%\nmutate_at(c(2:8), as.numeric)\n\nweather2 &lt;- weather2 %&gt;%\nmutate_at(c(10:20), as.numeric)\n\n# coerce date column\nweather2 &lt;- weather2 %&gt;%\nmutate_at(1, as_date)\n\n# take a quick look\nhead(weather2)\n\n        date Ob Temp (°F) Min Ob Temp (°F) Max Ob Temp (°F) Avg\n3 2023-03-28             16.5             23.5             18.0\n4 2023-03-27             16.5             23.5             18.0\n5 2023-03-26              4.0             28.0             15.5\n6 2023-03-25              6.5             22.0             15.0\n7 2023-03-24              5.0             24.0             14.5\n8 2023-03-23             12.5             29.0             19.5\n  Ob Wind (mi/hr) Min Ob Wind (mi/hr) Max Ob Wind (mi/hr) Avg\n3                 5.5                20.0                 9.5\n4                 5.5                20.0                11.5\n5                 1.0                10.5                 5.5\n6                 5.5                33.5                16.5\n7                 4.5                39.0                22.0\n8                 8.5                39.0                20.0\n  Ob Wind (mi/hr) Gust Ob Wind (mi/hr) Dir Ob Snow (in) HS Ob Snow (in) HN24\n3                42.93                 SSE           212.3               9.5\n4                42.93                 SSE           211.1              18.5\n5                24.54                  SE           188.6               0.0\n6                67.47                  NW           190.9               0.1\n7                61.34                  NW           190.7               0.0\n8                67.47                 WNW           192.9               0.0\n  Ob Snow (in) SWE Ob Snow (in) Total Snowfall Fx Temp (°F) Min\n3             0.00                       310.8               17\n4             0.00                       301.3               18\n5             0.01                       282.8               12\n6             0.00                       282.8               11\n7             0.05                       282.7               11\n8             0.16                       282.7               14\n  Fx Temp (°F) Max Fx Wind (mi/hr) Min Fx Wind (mi/hr) Max Fx Snow (in) Min\n3               30                  15                  25                5\n4               27                  30                  40               12\n5               27                  25                  35                0\n6               21                  25                  35                0\n7               22                  30                  40                2\n8               26                  25                  45                3\n  Fx Snow (in) Max Fx Snow (in) SWE Fx Rating \n3              9.5             0.42        CON\n4             18.5             1.01        MOD\n5              1.5             0.01        MOD\n6              1.5             0.03        MOD\n7              5.0             0.05        LOW\n8              7.0             0.06        LOW\n\nglimpse(weather2)\n\nRows: 129\nColumns: 21\n$ date                          &lt;date&gt; 2023-03-28, 2023-03-27, 2023-03-26, 202…\n$ `Ob Temp (°F) Min`            &lt;dbl&gt; 16.5, 16.5, 4.0, 6.5, 5.0, 12.5, 19.0, 1…\n$ `Ob Temp (°F) Max`            &lt;dbl&gt; 23.5, 23.5, 28.0, 22.0, 24.0, 29.0, 28.5…\n$ `Ob Temp (°F) Avg`            &lt;dbl&gt; 18.0, 18.0, 15.5, 15.0, 14.5, 19.5, 23.5…\n$ `Ob Wind (mi/hr) Min`         &lt;dbl&gt; 5.5, 5.5, 1.0, 5.5, 4.5, 8.5, 7.0, 4.5, …\n$ `Ob Wind (mi/hr) Max`         &lt;dbl&gt; 20.0, 20.0, 10.5, 33.5, 39.0, 39.0, 11.5…\n$ `Ob Wind (mi/hr) Avg`         &lt;dbl&gt; 9.5, 11.5, 5.5, 16.5, 22.0, 20.0, 10.0, …\n$ `Ob Wind (mi/hr) Gust`        &lt;dbl&gt; 42.93, 42.93, 24.54, 67.47, 61.34, 67.47…\n$ `Ob Wind (mi/hr) Dir`         &lt;chr&gt; \"SSE\", \"SSE\", \"SE\", \"NW\", \"NW\", \"WNW\", \"…\n$ `Ob Snow (in) HS`             &lt;dbl&gt; 212.3, 211.1, 188.6, 190.9, 190.7, 192.9…\n$ `Ob Snow (in) HN24`           &lt;dbl&gt; 9.5, 18.5, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0,…\n$ `Ob Snow (in) SWE`            &lt;dbl&gt; 0.00, 0.00, 0.01, 0.00, 0.05, 0.16, 0.00…\n$ `Ob Snow (in) Total Snowfall` &lt;dbl&gt; 310.8, 301.3, 282.8, 282.8, 282.7, 282.7…\n$ `Fx Temp (°F) Min`            &lt;dbl&gt; 17, 18, 12, 11, 11, 14, 23, 22, 18, 23, …\n$ `Fx Temp (°F) Max`            &lt;dbl&gt; 30, 27, 27, 21, 22, 26, 33, 36, 30, 32, …\n$ `Fx Wind (mi/hr) Min`         &lt;dbl&gt; 15, 30, 25, 25, 30, 25, 10, 20, 25, 45, …\n$ `Fx Wind (mi/hr) Max`         &lt;dbl&gt; 25, 40, 35, 35, 40, 45, 20, 30, 35, 55, …\n$ `Fx Snow (in) Min`            &lt;dbl&gt; 5, 12, 0, 0, 2, 3, 2, 0, 0, 7, 3, 0, 0, …\n$ `Fx Snow (in) Max`            &lt;dbl&gt; 9.5, 18.5, 1.5, 1.5, 5.0, 7.0, 4.0, 3.0,…\n$ `Fx Snow (in) SWE`            &lt;dbl&gt; 0.42, 1.01, 0.01, 0.03, 0.05, 0.06, 0.25…\n$ `Fx Rating `                  &lt;chr&gt; \"CON\", \"MOD\", \"MOD\", \"MOD\", \"LOW\", \"LOW\"…\n\n# Quick few plots to make sure everything looks reasonable\nweather_plot &lt;- ggplot(weather2, aes(x=date, y=`Fx Snow (in) Min`)) +\n  geom_point()\nweather_plot\n\n\n\n\n\n\n\nweather_plot2 &lt;- ggplot(weather2, aes(x=date, y=`Fx Wind (mi/hr) Max`)) +\n  geom_point()\nweather_plot2\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/weather-scraping-plot.png\")\n\nUp next: Making sure the data is cleaned up after the scrape and coercion."
  },
  {
    "objectID": "posts/2023-01-07-trinity-alps-trail-run/index.html",
    "href": "posts/2023-01-07-trinity-alps-trail-run/index.html",
    "title": "Trinity Alps Trail Run",
    "section": "",
    "text": "Western White Pine Cone Illustration\n\nIntroduction\nI recently revisited one the conifer species that occur in the Miracle Mile, but by trail running in the Trinity Alps Wilderness area in the Klamath range of Northern California. I found a number of cool species, but one recognizable one was the Western White Pine (Pinus monticola). Pinus monticola is found in many of the cool trail running spots I frequent. Here is another post about another trail run with Pinus monticola.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(gpx)\nlibrary(rgbif)\n\nIn-file the trail run gps data and make a data frame to use for plotting.\n\nrun &lt;-  read_gpx('~/DATA/data/Trinity-Alps-TrailRunning-2022-10-08-route.gpx')\nsummary(run)\n\n          Length Class  Mode\nroutes    1      -none- list\ntracks    1      -none- list\nwaypoints 1      -none- list\n\nTrailRun1 &lt;- as.data.frame(run$routes)\nTrailRun1$Time &lt;- as.numeric(row.names(TrailRun1))\n\nMake a quick plot using the latitude and longitude coordinates.\n\nTR_p1 &lt;- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black', size = 2) +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTR_p1\n\n\n\n\n\n\n\n\nTake a look at the elevation profile of the run.\n\nTR_p2 &lt;- ggplot() +\n          geom_line(data = TrailRun1, aes(x = Time, y = Elevation), color = 'black', size = 2) +\n          xlab(\"Time (seconds)\") + ylab(\"Elevation (m)\")\nTR_p2\n\n\n\n\n\n\n\n\nWe can also plot the run and false color it based on the elevation.\n\nTR_p3 &lt;- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude, color = Elevation), size = 2) +\n          scale_color_continuous(limits=c(800,2800))\nTR_p3\n\n\n\n\n\n\n\n\nUsing the Latitude and Longitude coordinates of the area we can make a general area polygon to be used for a GBIF species observation query to the public database.\n\ntrinity_geometry &lt;- paste('POLYGON((-122.91 40.88, -122.87 40.88, -122.87 40.96, -122.91 40.96, -122.91 40.88))')\n\nmm_species &lt;- c(\"pinus monticola\") # can add multiple species here for larger query\n\nwhitepine_data &lt;- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = trinity_geometry)\nwhitepine_data\n\nRecords found [5] \nRecords returned [5] \nArgs [hasCoordinate=TRUE, occurrenceStatus=PRESENT, limit=10000, offset=0,\n     scientificName=pinus monticola, geometry=POLYGON((-122.91 40.88, -122.87\n     40.88, -122.87 40.96, -122.91 40.96, -122.91 40.88))] \n# A tibble: 5 × 78\n  key     scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ hosti…⁷ publi…⁸\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n1 396113… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n2 396097… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n3 338409… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n4 239748… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n5 254089… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n# … with 68 more variables: protocol &lt;chr&gt;, lastCrawled &lt;chr&gt;,\n#   lastParsed &lt;chr&gt;, crawlId &lt;int&gt;, basisOfRecord &lt;chr&gt;,\n#   occurrenceStatus &lt;chr&gt;, taxonKey &lt;int&gt;, kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;,\n#   classKey &lt;int&gt;, orderKey &lt;int&gt;, familyKey &lt;int&gt;, genusKey &lt;int&gt;,\n#   speciesKey &lt;int&gt;, acceptedTaxonKey &lt;int&gt;, acceptedScientificName &lt;chr&gt;,\n#   kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   species &lt;chr&gt;, genericName &lt;chr&gt;, specificEpithet &lt;chr&gt;, taxonRank &lt;chr&gt;, …\n\nwhitepine_coords &lt;- whitepine_data$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nPlot the observations on the California map to see the limited polygon sampled.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(whitepine_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\n\n\n\n\nPlot all of the observations using ggplot for the zoomed in area.\n\nwhitepine_plot1  &lt;- ggplot(whitepine_coords, aes(x=decimalLongitude, y = decimalLatitude)) +\n                             geom_point(color='red') + labs(title = \"MM Zone\")\nwhitepine_plot1\n\n\n\n\n\n\n\n\nCombine trail running and Western White Pine occurrence observations.\n\nrun_plot2 &lt;- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black') +\n          geom_point(data = whitepine_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nrun_plot2\n\n\n\n\n\n\n\n\nNow to see a random sampling of what other species are also in the area of the trail run.\n\ntrinity_species &lt;- occ_data(hasCoordinate = TRUE, limit = 5000,\n                         geometry = trinity_geometry)\n\ntrinity_species_coords &lt;- trinity_species$data[ , c(\"scientificName\",\"phylum\", \"order\", \"family\", \"decimalLongitude\", \"decimalLatitude\",\"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\"institutionCode\", \"references\")]  \n\nPlot the run data, White Pine data, and other species data on the same map. I changed the size of the trail running and White Pine points so they are easier to see. I also just plotted things by Phylum as to not overload the plot by doing all the species!\n\nrun_phylum_plot &lt;- ggplot() +\n        geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black', size = .75) +\n        geom_point(data = trinity_species_coords, aes(x = decimalLongitude, y = decimalLatitude, color = phylum)) +\n        geom_point(data = whitepine_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red', size = 5, shape = 19) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")\nrun_phylum_plot\n\n\n\n\n\n\n\n\nYou can see that there are various species to explore representing Arthropods (Insects, Spiders etc.), Cordates (Animals), Bisidomycota (fungi), and Tracheophyta (vascular plants)."
  },
  {
    "objectID": "posts/2023-09-21-scraping-weather-data-setup.html",
    "href": "posts/2023-09-21-scraping-weather-data-setup.html",
    "title": "Scraping Weather Data 1",
    "section": "",
    "text": "This post is the First in a series teaching data journalists how to scrape and visualize website data. See the other posts in the series Post 2, Post 3 and Post 4.\nNOTE: This is fairly advanced data analysis topic. I will write some more introductory posts when I have more time, but I wanted to share my workflow for any data journalists out there.\n\nIntroduction\nI started collaborating with the Mount Shasta Avalanche Center for a long form data journalism project looking at snow and avalanche condition forecasting with the backdrop of climate change. This adds an additional layer of uncertainty into any type of short-term forecast. Forecasters put out daily forecasts that integrate a lot of weather, snowfall, wind speed, direction, terrain, and previous snowfall information along with on the ground observational data collected from snow pits. Here is a brief summary of how to read a forecast.\nI thought this would be a good opportunity to show how you can collect, clean, and visualize your own data-sets for data journalism projects. I will be scraping the Avalanche Center’s public website to assemble an aggregated data-set of my own to ask my own questions. This is a series of posts on the topic using open-source data tools.\n\n\nDocker Containers\nDocker containers are a nice way to add some reproducibility to your data journalism workflow. While a complete introduction to docker containers is outside of the scope of this series, you can think of them as small linux computers that run single programs or data analysis packages to accomplish a specific task. You can network them together so they can talk to one another by sharing data or commands between them. The advantage of this is that once you make a docker container you can always refer back to it like a snapshot of the hardware that ran your analysis code. It will have the software installed on it that you used for an analysis. All of this can be done on a laptop to get things set-up and then transferred to the cloud if you have a large job to run. This allows you to prototype on the laptop and then spin up large cloud computers if necessary. Or you can just continue to work off your laptop. You can also share the images you have made on Docker Hub.\nFor this post I will refer to three different machines. Your HOME machine (my laptop in this case), a docker container that is running R and R Selenium (R CONTAINER), and a docker container that is running Selenium (SELENIUM CONTAINER). The two docker containers are actually just running on my laptop and sharing the laptop’s harddrive, processor, and memory. Mini-linux machines! You will see how these two containers interact to do something useful in the next post in this series, but for now we are focusing on getting it set up.\nOn your HOME machine make a directory called DockerImages. I do this to keep all the Docker files and images I make tidy. In the DockerImages directory, make another directory called RSeleniumImage. In the RSeleniumImage directory make a file called Dockerfile and populate it with the following code:\nFROM rocker/rstudio:latest\n\n## Install required libraries for RSelenium\nRUN apt-get update && apt-get install -y \\\n    libxml2-dev \\\n    libcurl4-openssl-dev \\\n    libssl-dev\n\n## Install R packages\nRUN R -e \"install.packages(c('RSelenium', 'binman', 'wdman', 'rvest'), repos='https://cloud.r-project.org/')\"\nOn your HOME machine navigate to the directory with the new docker file and build it.\ncd /HOME/DockerImages/RSeleniumImage/\ndocker build .\nFortunately there are already selenium containers already built so we can pull them onto the HOME machine to use for our project. We can then check that both images are on our HOME machine. it should look something like the commented out print out.\ndocker pull selenium/standalone-firefox:78.0\ndocker image ls\n# REPOSITORY                                       \n# r_rselenium                                     \n# selenium/standalone-firefox\nYou will be running and trouble shooting the containers from the HOME machine. Create a docker network called mynetwork. First you will run the SELENIUM CONTAINER with Firefox installed. You will name it selenium-container so you can refer to by name it while it is running. We are exposing 2 ports to this container with -p option.\ndocker network create mynetwork\n\ndocker run -d -p 4444:4444 -p 7900:7900 --network=mynetwork --name selenium-container --shm-size=\"2g\" selenium/standalone-firefox:78.0\nTo make sure the selenium-container works, point your webbrowser on the HOME machine to: http://localhost:4444 . You should get a moslty blank screen with a bit of code on it.\nNext, on the HOME machine you will start the R CONTAINER r_with_selenium container by linking it to mynetwork and exposing port 8787.\ndocker run -d --rm --network=mynetwork -p 8787:8787 --name r_with_selenium -e PASSWORD=YOURNEWPASSWORD -v /HOME/DATA/:/home/rstudio/DATA r_rselenium\nNext you will make sure that the R CONTAINER can talk to the SELENIUM CONTAINER. From the HOME machine you will connect to the running R CONTAINER and send a command to the SELENIUM CONTAINER.\ndocker exec -it r_with_selenium /bin/bash \napt-get update\napt-get install curl\ncurl http://selenium-container:4444/wd/hub # should get some JSON back if working correctly\nNow point your web browser on the HOME machine to http://localhost:8787 to enter into an R Studio session running inside the R CONTAINER. Inside the R Studio session you will type the following code to make sure that your session can talk with the SELENIUM CONTAINER. We will be using this network setup in the next post to scrape data from the avalanche website.\n\nlibrary(RSelenium)\nremDr &lt;- remoteDriver(\n  remoteServerAddr = \"selenium-container\",\n  port = 4444L,\n  browserName = \"firefox\",\n  version = \"78.0\"  # e.g., \"91.0\"\n)\n\nSys.sleep(10)  # waits for 10 seconds\nremDr$open()\n\nWow! That was a lot of abstraction. Give yourself a break and then check out the next post in this Avalanche Data Journalism series.\nIf you are done, then you want to shut down all of the containers on the HOME machine and remove the Docker network that you created for the containers to talk to one another.\ndocker stop r_with_selenium selenium-container\ndocker stop selenium-container\ndocker rm selenium-container\ndocker rm r_with_selenium\ndocker network rm mynetwork"
  },
  {
    "objectID": "posts/2023-09-22-scraping-weather-data.html",
    "href": "posts/2023-09-22-scraping-weather-data.html",
    "title": "Scraping Weather Data 2",
    "section": "",
    "text": "This post is the second in a series teaching data scraping and visualization techniques to data journalists. See the other posts in the series Post 1, Post 3 and Post 4.\n\nIntroduction\nI started collaborating with the Mount Shasta Avalanche Center for a long form data journalism project looking at snow and avalanche condition forecasting with the backdrop of climate change. This adds an additional layer of uncertainty into any type of short-term forecast. Forecasters put out daily forecasts that integrate a lot of weather, snowfall, wind speed, direction, terrain, and previous snowfall information along with on the ground observational data collected from snow pits. Here is a brief summary of how to read a forecast.\nI thought this would be a good opportunity to show how you can collect, clean, and visualize your own data-sets for data journalism projects. I will be scraping the Avalanche Center’s public website to assemble an aggregated data-set of my own to ask my own questions. This is a series of posts on the topic using open-source data tools.\nThis is a post showing how to extract data from a website and make a few plots. I chose the Mount Shasta Avalanche Center data because I monitor this everyday throughout the season to see how the avalanche forecast changes and how the snowpack is developing. I did an intro post on this topic last year, but I would like to go into more depth on extracting information from a website.\nThere is a great website scraping package that is part of the tidyverse called Rvest. Check out the Documentation. The avalanche center website has a number of selectors on it to choose which range of data you would like displayed. We will be using the Selenium package in order to be able to do that and accessing it from R via the RSelenium package. Selenium runs a minimal version of a web browser that can interact with webpages. So instead of point and clicking, we can programatically interact with the website using Selenium. I will write another post on how to set that up later, but for now, load the libraries.\n\nlibrary(RSelenium)\nlibrary(rvest)\nlibrary(tidyverse)\nlibrary(lubridate)\n\nI have started the docker container that has selenium running inside. Now with my R session I will connect to that container and open the connection to the remote driver section. Please see the last post in this series for how to set this up.\n\nremDr &lt;- remoteDriver(\n  remoteServerAddr = \"selenium-container\",\n  port = 4444L,\n  browserName = \"firefox\",\n  version = \"78.0\"  # e.g., \"91.0\"\n)\n\nremDr$open()\n\nLoad the URL that we are going to be interacting with to extract the information.\n\n# Navigate to the website\nurl &lt;- \"https://www.shastaavalanche.org/page/seasonal-weather-history-mount-shasta\"\nremDr$navigate(url)\n\nPoint your regular web browser to “https://www.shastaavalanche.org/page/seasonal-weather-history-mount-shasta” and right click anywhere on the page. Your web browser will likely have an “Inspect” option what will pull up split screen view of the webpage. The top will have the regular webpage you were viewing. The bottom will have an element view of the website. You can click around on the elements and find the names of elements that you want interact with programatically.\nNow we can programmatically select the elements on the page. I am selecting October 1, 2017 as the start of the date range and April 30, 2023 as the end of the date range. We then submit the query by clicking on that button and build in a sleep timer so that the page has time to load inside our Selenium session.\n\nmonth_dropdown &lt;- remDr$findElement(using = \"css selector\", \"select[name='start_month']\")\nmonth_dropdown$clickElement()\n\nselected_month &lt;- remDr$findElement(using = \"css selector\", \"select[name='start_month'] option[value='Oct']\")\nselected_month$clickElement()\n\nyear_dropdown &lt;- remDr$findElement(using = \"css selector\", \"select[name='start_year']\")\nyear_dropdown$clickElement()\n\nselected_year &lt;- remDr$findElement(using = \"css selector\", \"select[name='start_year'] option[value='2017']\")\nselected_year$clickElement()\n\nday_dropdown &lt;- remDr$findElement(using = \"css selector\", \"select[name='start_day']\")\nday_dropdown$clickElement()\n\nselected_day &lt;- remDr$findElement(using = \"css selector\", \"select[name='start_day'] option[value='1']\")\nselected_day$clickElement()\n\nend_month_dropdown &lt;- remDr$findElement(using = \"css selector\", \"select[name='end_month']\")\nend_month_dropdown$clickElement()\n\nselected_end_month &lt;- remDr$findElement(using = \"css selector\", \"select[name='end_month'] option[value='Apr']\")\nselected_end_month$clickElement()\n\nend_year_dropdown &lt;- remDr$findElement(using = \"css selector\", \"select[name='end_year']\")\nend_year_dropdown$clickElement()\n\nselected_end_year &lt;- remDr$findElement(using = \"css selector\", \"select[name='end_year'] option[value='2023']\")\nselected_end_year$clickElement()\n\nend_day_dropdown &lt;- remDr$findElement(using = \"css selector\", \"select[name='end_day']\")\nend_day_dropdown$clickElement()\n\nselected_end_day &lt;- remDr$findElement(using = \"css selector\", \"select[name='end_day'] option[value='30']\")\nselected_end_day$clickElement()\n\nsubmit_button &lt;- remDr$findElement(using = \"css selector\", \"button[title='Submit Query']\")\nsubmit_button$clickElement()\n\nSys.sleep(30)\n\nOnce the page is loaded inside Selenium we can read the page into R saving it as parsed_content. We then select the weather history table and extract all of those features.\n\n# make sure rvest is loaded\npage_source &lt;- remDr$getPageSource()[[1]]\n\nparsed_content &lt;- read_html(page_source)\n\n# right click on the page to see the tabl\n\nparsed_content %&gt;%\n    html_element(\".msac-wx-history-table\") %&gt;%\n    html_table()\n\nRight click on the page in your web browser and get the xpath to a specific table.\n\nxpath &lt;- \"/html/body/div[2]/main/div/article/div/table[2]\"\nweather &lt;- html_nodes(parsed_content, xpath = xpath)\nhtml_table(weather)\n\nFinally we will make a data frame with the weather data and clean it up using R functions.\n\n# make a data.frame with the table\nweather2 &lt;- as.data.frame(html_table(weather, fill=TRUE))\n\n# rename columns\nnames(weather2) &lt;- paste(weather2[1,], weather2[2,])\nnames(weather2)\nnames(weather2)[1] &lt;- paste(\"date\")\n\n# remove rows that are now column names\nweather2 &lt;- weather2[-c(1,2),]\n\n# take a look\nglimpse(weather2)\n\n# columns that are numeric should be converted back to such. They were coerced into character vectors because of the first two rows were characters.\nweather2 &lt;- weather2 %&gt;%\nmutate_at(c(2:8), as.numeric)\n\nweather2 &lt;- weather2 %&gt;%\nmutate_at(c(10:20), as.numeric)\n\n# coerce date column\nweather2 &lt;- weather2 %&gt;%\nmutate_at(1, as_date)\n\n# take a quick look\nhead(weather2)\nglimpse(weather2)\nunique(weather2$`Fx Rating `)\n# [1] \"LOW\"       \"MOD\"       \"CON\"       \"Fx Rating\" \"\"          \"HIGH\" \n\n# remove the rows that are blank or have Fx Rating - these are table formatting errors from the html\nrows_drop &lt;- c(\"Fx Rating\", \"\")\nweather3 &lt;- weather2[!(weather2$`Fx Rating ` %in% rows_drop), ]\n\n# Close the session\nremDr$close()\n\nFinally we will saved the scrapped data to an .RData file so you can access it without rerunning the code above.\n\nsave(weather3, file = \"~/DATA/data/Avalanche-Data-2017-2023.RData\")\n\nSee the other posts in the series Post 1, Post 3 and Post 4."
  },
  {
    "objectID": "posts/2024-11-15-5YearGoals.html#my-original-journal-entry-from-january-2024-lightly-edited-to-fit-this-blog-format.",
    "href": "posts/2024-11-15-5YearGoals.html#my-original-journal-entry-from-january-2024-lightly-edited-to-fit-this-blog-format.",
    "title": "5 Year Goals",
    "section": "My original journal entry from January 2024 lightly edited to fit this blog format.",
    "text": "My original journal entry from January 2024 lightly edited to fit this blog format.\n\n\n\nI was chatting with Jack about how I was having a great time working through each of my comics production books for this month’s skillathon activities and how I might just work through the rest of my art book library in the coming years in a similar manor. Spend a set amount of time with each book, do exercises, make sketchnotes and then move onto another book. Jack said if I (re)worked through all ~100 art books in this way then I would essentially have a DIY MFA. Something gelled with this idea seed. Why stop there? Why not work towards “DIY masters” degrees in all the things I am interested in as an extension the skillathon… going even deeper on topics. At the same time, Caryn and I have been working on updating our 5 year goals for 2024-2028 or where do we want to be (besides where we are…ha!) on Jan 1, 2029? Obviously things will not turn out like how I plan, but I might as well think through it as an exercise.\nWhile the general direction outlined in 2021 is still the same general direction as I have now, I add many more details and some clarity about how to integrate different components through blogging, zines, exploration and art learning."
  },
  {
    "objectID": "posts/2023-07-28-edna-fire-preprint.html",
    "href": "posts/2023-07-28-edna-fire-preprint.html",
    "title": "Fire Impacts on Pollinators Across Ecosystem Types",
    "section": "",
    "text": "The above sketch is from one of our field sites, Blue Oak Ranch Reserve. I recently blogged about a introductory fire ecology class at the Blue Oak Ranch Reserve. The reserve is part of the UC Reserve system and is one of the many sites I am collecting data at for a larger project looking at fire impacts on California ecosystems and insect pollinators. Other blog posts in the series are also available: post 2, post 3, post 4. I wrote about the reserve system in these other posts on fire data and environmental data.\nWe just finished up analyzing the research and writing up the paper. It is currently available as a pre-print here.\n\nAbstract\nWildfires are increasingly altering ecosystems, posing significant challenges for biodiversity conservation and ecosystem management. In this study, we used DNA metabarcoding to assess the response of arthropod communities to large-scale wildfires across diverse habitat types. We sampled six reserves within the University of California Natural Reserve System (UCNRS), each which was partially burned in the 2020 Lightning Complex wildfires in California. Using yellow pan traps to target pollinators, we collected arthropods from burned and unburned sites across multiple habitat types including oak woodland, redwood, scrub, chamise, grassland, forest, and serpentine habitats. We found no significant difference in alpha diversity values between burned and unburned sites; instead, seasonal variations played a significant role in arthropod community dynamics, with the emergence of plant species in Spring promoting increased pollinator richness at all sites. Compositional similarity analysis revealed that burn status was not a significant grouping factor when comparing all sites. Instead, community composition primarily varied across reserves, indicating distinct pools of arthropods structured geographically. Habitat type played a crucial role in determining the response of arthropod communities to fire. While communities in grasslands and oak woodlands exhibited recovery following burn, scrublands experienced substantial changes in community composition. Our study highlights the importance of examining community responses to wildfires across broad spatial scales and diverse habitat types. By understanding the nuanced dynamics of arthropod communities in response to fire disturbances, we can develop effective conservation strategies that promote resilience and maintain biodiversity in the face of increasing wildfire frequency and intensity driven by climate change.\nThe code repository is available here. The repository also contains instructions on how to make reproducible data science docker containers for each of the major steps in the analysis pipeline. We made the docker container with the largest number of software dependencies available on docker hub here."
  },
  {
    "objectID": "posts/2022-07-15-ucreservefires/index.html",
    "href": "posts/2022-07-15-ucreservefires/index.html",
    "title": "UC Reserve Fire Data",
    "section": "",
    "text": "A short post overlaying a few different GIS layers on one another for a project we are working on. The databases used are large so I just show the code here with one final image instead of including them in the website repository. I needed to subset the fire perimeters from the Cal Fire database and overlap them with the UC Reserve perimeters. I also needed to in-file some GPS coordinates of post fire sampling sites. I share the code below, but not the data as this project is still in progress. However, the raw data is available:\nCal Fire Data\nUC Reserve Perimeter Data\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(rgdal)\n\nsetwd(\"~/DATA/data/calfire.nosync/\")\nfire &lt;- st_read(\"fire20_1.gdb\")\nreserves &lt;- st_read(\"UC_NRS.gdb\")\n\n# subset fire data for 2020\nfire2020 &lt;- fire[fire$YEAR_ == \"2020\",]\nplot(fire2020$Shape)\nplot(reserves$Shape)\nstr(fire2020)\nstr(reserves)\n\nIntersect the reserves and 2020 fires.\n\noverlaps2020 &lt;-  lengths(st_intersects(fire2020, reserves)) &gt; 0\nfire_reserves2020 &lt;- fire2020[overlaps2020,]\nplot(fire_reserves2020$Shape, col=\"orange\")\nplot(reserves$Shape, col=\"blue\", add = TRUE)\n\nTake a look at the names of the fires that overlap and then specifically subset them for later processing.\n\nfire_reserves2020$FIRE_NAME\nriver_fire &lt;- subset(fire2020, FIRE_NAME == \"RIVER\")\nscu_complex_fire &lt;- subset(fire2020, FIRE_NAME == \"SCU COMPLEX\")\nhennessey_fire &lt;- subset(fire2020, FIRE_NAME == \"HENNESSEY\")\ndolan_fire &lt;- subset(fire2020, FIRE_NAME == \"DOLAN\")\nsnow_fire &lt;- subset(fire2020, FIRE_NAME == \"SNOW\") # did not collect field data here\n\nInfile the arthropod sampling locations and make a coordinates dataframe.\n\nsetwd(\"~/DATA/data/\")\narthro_data &lt;- read_csv(\"Post-FireMonitoring_Arthropod_SamplingLocations.csv\")\narthro_coords &lt;- data.frame(x = arthro_data$LONGITUDE, y = arthro_data$LATITUDE)\n\nI converted the data frame to a spatial object with the appropriate map projection information. This then allowed me to convert Lat/Long coordinates to the same projection that the Cal Fire and UC Reserve System perimeters data are projected in (California Albers- EPSG:3310).\n\n# make spatial dataframe with lat long coords using the RGDAL package functions\ncoordinates(arthro_coords) &lt;- ~x+y\nproj4string(arthro_coords) &lt;- CRS(\"+proj=longlat +datum=WGS84\")\nstr(arthro_coords)\n\narthro_3310 &lt;- spTransform(df, CRS(\"+init=epsg:3310\"))\narthro_3310\nstr(arthro_3310)\n\n# double check with plot\nplot(reserves$Shape, col=\"blue\")\nplot(arthro_3310, , col = \"red\", add = TRUE)\n\nConvert the object to and sf object for quick plotting. Calculate the overlays between the fire sampling site and the control sampling sites. Overlay the fire perimeter, the reserve perimeters, and the sampling sites. To make it more clear I chose the Hennessey Fire which burned across two reserve boundaries in 2020.\n\n# convert to sf package object\nfire_pts2 &lt;- st_as_sf(arthro_3310)\nstr(fire_pts2)\n\n# overlay points and fire shapes\nfire_yes = lengths(st_intersects(fire_pts2, hennessey_fire)) &gt; 0\nfire_yes\n\n# layer all the plots\nplot(hennessey_fire$Shape) # fire shape\nplot(reserves$Shape, col=\"orange\", add=TRUE) # local reserves shape\nplot(fire_pts2, pch=19, col=\"blue\", add=TRUE); # all samples\nplot(fire_pts2[fire_yes,], pch=19, col=\"red\", add=TRUE); # samples in fire\n\nIt is over-plotted in this view, but this demonstrates the idea. The Hennessey fire perimeter is shown in black, reserves in orange, reserve sampling sites within the fire perimeter in red, and sampling sites within the reserve, but outside the fire perimeter in blue."
  },
  {
    "objectID": "posts/2023-10-01-avalanche-data-animation.html",
    "href": "posts/2023-10-01-avalanche-data-animation.html",
    "title": "Scraping Weather Data 4",
    "section": "",
    "text": "This post is the fourth in a series teaching data journalists how to scrape and visualize website data. See the other posts in the series Post 1, Post 2, Post 3 and Post 4.\n\nIntroduction\nI started collaborating with the Mount Shasta Avalanche Center for a long form data journalism project looking at snow and avalanche condition forecasting with the backdrop of climate change. This adds an additional layer of uncertainty into any type of short-term forecast. Forecasters put out daily forecasts that integrate a lot of weather, snowfall, wind speed, direction, terrain, and previous snowfall information along with on the ground observational data collected from snow pits. Here is a brief summary of how to read a forecast.\nI thought this would be a good opportunity to show how you can collect, clean, and visualize your own data-sets for data journalism projects. I will be scraping the Avalanche Center’s public website to assemble an aggregated data-set of my own to ask my own questions. This is a series of posts on the topic using open-source data tools.\nThis post builds on the previous posts to make an animated data visualization of avalanche forecast variation across multiple seasons of snowfall based on the snow fall over the previous three days.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(gganimate)\n\nLoad the data, make the custom colors for plotting, and make a plot of the rolling three day average snow fall across all the seasons in the data set. Notice that this rolling average captures much of the variation in the moderate, high, and extreme snow conditions. Or to put it another way, you will likely have to have fresh snow to increase the avalanche danger across these seasons. This is a general statement because there is a lot more that goes into it of course! I hope to get more information from showing this to the avalanche forecasters.\n\nload(file = \"~/DATA/data/Avalanche-Data-2017-2023-filtered.RData\")\nls()\n\n[1] \"filtered_data\"\n\ncustom_colors &lt;- c(\"LOW\" = \"green\", \"MOD\" = \"yellow\", \"CON\" = \"orange\", \"HIGH\" = \"red\", \"EXT\" = \"black\")\n\nweather_plot5 &lt;- ggplot(filtered_data, aes(x = day_of_water_year, y = snow_avg_3, color = danger)) +\n  geom_point(shape = 18, size = 5) +\n  facet_wrap(~season, ncol = 1) +\n  scale_color_manual(values = custom_colors) +\n  scale_y_continuous(name = \"Rolling Snow Average (3 day)\") +\n  labs(title = \"\", color = \"Avalanche Danger\")\n\nweather_plot5\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/MSAC_17_23_3daySnow_AvyWarning.png\", height = 10, width = 8)\n\nNow we can use the gganimate package to take a look at how the snowfall impacts forecasted avalanche danger.\n\nanimated_plot &lt;- ggplot(filtered_data, aes(x = day_of_water_year, y = snow_avg_3, color = danger)) +\n  geom_point(shape = 18, size = 4, aes(group = day_of_water_year)) +\n  scale_color_manual(values = custom_colors) +\n  scale_y_continuous(name = \"Rolling Snow Average (3 day)\") +\n  labs(title = \"Day of Water Year: {frame_along}\", color = \"Avalanche Danger\") +\n  facet_wrap(~ season, ncol = 1) +\n  transition_reveal(day_of_water_year) +\n  shadow_mark()\n\n# View the animation\nanimated_plot\n\n# Save the animation\nanim_save(\"~/DATA/images/animated_avalanche_plot.gif\", animated_plot)\n\n\n\n\nSee the other posts in the series Post 1, Post 2 and Post 3"
  },
  {
    "objectID": "posts/2022-10-15-pyrodiversityklamathnatgeo/index.html",
    "href": "posts/2022-10-15-pyrodiversityklamathnatgeo/index.html",
    "title": "Pyrodiversity",
    "section": "",
    "text": "I am currently writing a general science article about pyrodiversity in Californian ecosystems as part of my fellowship at Berkeley Institute for Data Science . I decided to extend the idea to write a small grant to the National Geographic Society for funding a field component in the Klamath Mountain range in Northern California and Southern Oregon. The grant opportunity combines many of my current skills to tell a pyrodiversity story. The idea would be to explore areas of high, medium, and low pyrodiversity by human power starting from my house in Mount Shasta, CA and ending in Crescent City, CA. I have a few potential routes mapped out, but the one displayed below starts with a bikepacking route between Mount Shasta and Junction City, CA. The route then transitions to backpacking and takes a slightly modified version of the Bigfoot Trail. Fingers crossed for next year!\n\n\n\nFigure 1A - Project overview with four major steps. The project will take my current diverse skill set and exploration theme (1) and allow me to be mentored and learn from the National Geographic Explorer Community (2) to produce the proposed deliverables (3). I will then give back to the Explorer community by becoming a mentor and applying my open-source data science skills to collaborate with the technical teams at National Geographic (4).\nFigure 1B - A graphic representation of pyrodiversity concepts. Burn areas (orange) are represented within land areas. Overlapping fires occur over years (left to right). Examples of low pyrodiversity (few fires) to high pyrodiversity (many overlapping fires) are illustrated top to bottom.\n\n\n\nFigure 2- Inlay- Map of California (gray) with approximate outline of Klamath Mountains (black) and proposed backcountry route (blue). Zoomed in map of Klamath Mountains (black) of Northern California (gray) with proposed backcountry route (blue). Overlayed in transparent orange are the fire perimeters of the last 100 years. The deeper the orange color, the greater the number of fires for a given area. The proposed route will explore areas of high, medium and low pyrodiversity."
  },
  {
    "objectID": "posts/2024-11-30-November2024Review.html",
    "href": "posts/2024-11-30-November2024Review.html",
    "title": "November 2024 Review",
    "section": "",
    "text": "November 2024\nNovember started as a continuation of October’s external facing trend, but a snow storm and the Thanksgiving holiday turned it into an inward facing month. I had a few integration breakthroughs in how I am thinking about projects. The main one being that lifestyle businesses should be more integrated into my actual life. They both were in the day to day, but they were still separate in my mind because I started them when I was still employed and needed to compartmentalize more to get stuff done. Darmera (gallery/classroom) and Montology (art and bikes) are now more integrated in how I think about my life. It is really interesting to have had this tension/unease building ever since leaving my research job suddenly relax once I just changed the way I thought about them.\n\n\nSmall Business as Craft\nEach of these small businesses I am now approaching like a craft. Not just for what they produce, but also for the day to day operations, the accounting, and all the other little important things that I tend to ignore. The new framing is that all of these are little pieces of a larger whole that I am building. The care that I take when finishing a piece of art work should be the same care that I take in sweeping up at the end of a gallery opening or the same amount of attention payed to documenting each and every receipt rather than pushing to some unknown future. “That is future Cody’s problem!” However, this month I made them my actual problem and re-framed how to think about them. I had a bunch of tech debt, project debt, and finance paperwork debt that I decided to get in order for Montology. I created systems for dealing with each of these types of debt in the future. All of this lives inside my computer as an Obsidian vault. All of the content that I create for Montology is one and the same as my Zettlekasten. All the Darmera content (newsletters, illustrations, etc.) also lives in there. Personal and each of the business workflows had been separate, but now they are the same.\nNow I just feed the Montology Beast every day with ideas, sketchnotes, and documentation about what I did, who paid me what, and the minor business expenses. I finished 4 commissions this month so this was part of the motivation for getting all these workflows in order. I am on track to have all of my expenses covered from incidental art income sometime next year. Investing in this business (aka myself) has been a great use of funds to get supplies covered for art and then to be able to use them to create value out of paper, ink and paint using art skill. Satisfying AF when I think about that.\n\n\nNature Journaling\nI finished up the Nature Journaling teaching training classes and took notes for each. I still need to finish the assignments and get feedback on them in the next few months. We now have a few students that come to Nature Journaling regularly. I will take all the class learning and the teaching learning and condense them into my version of “How to Nature Journal”. Darmera is gearing up to start hosting plein-air/nature journaling retreats next year. The class prototyping and teaching has given me that we can run a joint workshop over a weekend switching between painting and observing/journaling. We also hope that if we can fill these it will be a more targeted way to make enough money for the business that we can hire our first employee.\n\n\nTransition Month\nNovember was very cold, mostly rainy, with some snow up higher. My fitness was a bit all over the place taking what I could get. We had a few straight weeks of precipitation so I hunkered down inside and did the bike trainer/art class combo. I learned some new lettering and layout techniques and them implemented them on my current 8 page comic.\n\n\nFriends Giving\nFriends giving with Nick and Jane. We explored a new area that was only an hour ski away from a nearby trailhead. The snow was a perfect 8 inches of powder even though it had snowed 5 days prior. We skied through a large open glade of old growth Red Firs. Old growth stands have well spaced trees (usually). I made Karaage, Caryn made salad and roasted veggies. Porters. Merriment.\nThe final community piece that I will be participating in (no more new ones!) is I joined the board of The Friends of Mount Shasta Avalanche Center. I had been talking with them for over a year and did a few art commissions for them already so I know they were good to work with.\nBroader Community: Chamber of Commerce Board Non-Profit Board Business with public classes and events (some that are free or are supplemented by grants).\n\n\nVices Removed!\nThis month I woke up one morning and just decided I was done drinking coffee. I substituted green tea that we had in the pantry to get some caffeine. For 2 days I was very sluggish. I am still in the process of weaning off caffeine entirely as my green tea supply is exhausted.\nI did not consume any alcohol for 6 months. If I ever had a infrequent craving I would just have a non-alcoholic beer. The new ones are tasty and an excellent substitute. I had a pre-planned glass of wine at my art opening, a glass with Caryn for our dating anniversary, and for Thanksgiving I had some beer with dinner. All three instances were different pre-planned scenarios where I would have consumed beer or wine without thinking about it. However, this was very deliberate and I came away from all three instances as just “meh”. “Not nearly as good as I remember.” What is interesting about this is that resetting my physiology and then doing deliberate experiments in different “normal social” drinking situations did not meet my expectations at all. It made drinking any alcohol even less appealing and scratched my curiosity itch. Back on the wagon for another long stretch.\nThese two vice habit changes save some serious cash. Craft IPAs are ~$2/beer - during the pandemic I could consume 3 beers during an evening. Yikes! If I was consuming beer every day that would be $6 per day. 6x30 = $180/month.\n2 cups of light roast coffee per day was about a $50/month habit.\nCompared to peak pandemic, at minimum I have erased $230 a month - from my monthly budget. Or to think about it in another way, my spending buffer is way up: $230x401 = $92,230 per year that does not need to be working for me if I were to retire at a very conservative 3% withdraw rate. The costs really do add up from daily habits. These former costs are now being put into my community project fund. About to donate some for Giving Tuesday.\n\nVice Update February 2025\nI still drink a small pot (2 cups) of green tea every morning to get some caffeine. It is more like a $15/month habit now.\n\n\n\nNatural Processes\nOriginally when we were opening the gallery I thought it would be more than a year before I would do a show, but now I want to have them once a year. Why not? It is my gallery after all! Natural Processes was well attended. We finally got all the mechanics working to keep people in there hanging out by setting up some tables in the classroom and having paper and pencils for people to make art. There was another larger gallery opening up the street that brought in some traffic as well. I sold a piece! This also focuses the art outside of comics and design drawing to put together something unique in a constrained timeframe. I am sure that I could spend even more time per piece, but I got what I came for on this project. I put together a show in just over a month that balanced my skillset, composition, price per piece, average audience of Darmera so far, the layout the gallery, what pieces would I actually want to hang in the studio or at home because it is very unlikely they will all sell. I was also thinking about the show as an advertisement for my watercolor and ink class (1 more non-drop-in spot open). I treated this show as the equivalent of an MFA in illustration. Onto the next project. :)."
  },
  {
    "objectID": "posts/2022-05-01-jefferypinetrailrun/index.html",
    "href": "posts/2022-05-01-jefferypinetrailrun/index.html",
    "title": "Miracle Mile Species 5 and 6",
    "section": "",
    "text": "I am continuing on my quest of checking off all the conifer species that occur in the Miracle Mile. I recently found some Jeffrey’s Pine (Pinus jeffreyi) on a trail run while on vacation in the San Bernadino mountains East of Los Angeles. This is in an area where there is also Ponderosa Pine (Pinus Ponderosa). Sometimes the species are confused with one another and can even form hybrids making identification difficult. In general the Ponderosa’s are larger trees, but have smaller cones with the pointy end (umbos) of the individual seeds facing outward. The Jeffery’s pine has larger cones with the umbos facing down or inward making them easier to handle without poking yourself. The following are some quick data queries, manipulation and plotting.\nLoad the libraries.\n\nlibrary(rinat)\nlibrary(tidyverse)\n\nLoad the trail run data and take a look at the data frame.\n\nTrailRun1 &lt;- read.csv(\"~/DATA/data/TrailRun_JefferyPine.csv\")\nglimpse(TrailRun1)\n\nRows: 2,194\nColumns: 9\n$ timestamp      &lt;chr&gt; \"2022-04-19 18:45:05\", \"2022-04-19 18:45:13\", \"2022-04-…\n$ position_lat   &lt;dbl&gt; NA, NA, NA, NA, 34.23880, 34.23873, 34.23869, 34.23868,…\n$ position_long  &lt;dbl&gt; NA, NA, NA, NA, -116.8687, -116.8686, -116.8686, -116.8…\n$ distance       &lt;int&gt; 0, 67, 72, 74, 76, 76, 80, 84, 87, 89, 91, 94, 98, 100,…\n$ altitude       &lt;dbl&gt; NA, 2112.4, 2112.6, 2112.8, 2113.0, 2113.2, 2114.0, 211…\n$ cadence        &lt;int&gt; NA, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83,…\n$ speed          &lt;dbl&gt; NA, 1.74, 1.74, 2.04, 2.04, 2.24, 2.24, 2.44, 2.44, 2.5…\n$ temperature    &lt;int&gt; NA, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,…\n$ vertical_speed &lt;dbl&gt; NA, 0.00, 0.00, -0.02, -0.02, -0.02, -0.02, -0.04, -0.0…\n\n\nMake a quick plot for the run.\n\nTrailRun_plot &lt;- ggplot(TrailRun1, aes(x = position_long, y = position_lat)) +\n                    coord_quickmap() + geom_point() +\n                    xlab(\"Longitude\") + ylab(\"Latitude\")\nTrailRun_plot\n\n\n\n\n\n\n\n\nUse the run data plot to bound the query to iNaturalist.\n\nbounds &lt;- c(34.2, -116.9, 34.25, -116.85)\npineJeff_iNat &lt;- get_inat_obs(query = \"Pinus jeffreyi\", bounds = bounds, maxresults = 1000)\npinePond_iNat &lt;- get_inat_obs(query = \"Pinus ponderosa\", bounds = bounds, maxresults = 1000)\n\nTake a quick look at the iNaturalist data frames.\n\nglimpse(pineJeff_iNat)\n\nRows: 22\nColumns: 37\n$ scientific_name                  &lt;chr&gt; \"Pinus jeffreyi\", \"Pinus jeffreyi\", \"…\n$ datetime                         &lt;chr&gt; \"2023-02-05 13:24:29 -0800\", \"2023-01…\n$ description                      &lt;chr&gt; \"\", \"\", \"\", \"Found on the ground. Lar…\n$ place_guess                      &lt;chr&gt; \"San Bernardino National Forest, Big …\n$ latitude                         &lt;dbl&gt; 34.22255, 34.21582, 34.23545, 34.2377…\n$ longitude                        &lt;dbl&gt; -116.8954, -116.8600, -116.8962, -116…\n$ tag_list                         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ common_name                      &lt;chr&gt; \"Jeffrey pine\", \"Jeffrey pine\", \"Jeff…\n$ url                              &lt;chr&gt; \"https://www.inaturalist.org/observat…\n$ image_url                        &lt;chr&gt; \"https://inaturalist-open-data.s3.ama…\n$ user_login                       &lt;chr&gt; \"ekoberle\", \"happyg\", \"orionsmcc\", \"s…\n$ id                               &lt;int&gt; 148162933, 145894058, 143681542, 1284…\n$ species_guess                    &lt;chr&gt; \"Jeffrey pine\", \"\", \"Jeffrey pine\", \"…\n$ iconic_taxon_name                &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ taxon_id                         &lt;int&gt; 48463, 48463, 48463, 48463, 48463, 48…\n$ num_identification_agreements    &lt;int&gt; 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0…\n$ num_identification_disagreements &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ observed_on_string               &lt;chr&gt; \"2023-02-05 13:24:29-08:00\", \"2023-01…\n$ observed_on                      &lt;chr&gt; \"2023-02-05\", \"2023-01-04\", \"2022-12-…\n$ time_observed_at                 &lt;chr&gt; \"2023-02-05 21:24:29 UTC\", \"2023-01-0…\n$ time_zone                        &lt;chr&gt; \"Pacific Time (US & Canada)\", \"Pacifi…\n$ positional_accuracy              &lt;int&gt; 3, 13, 357, 347, 217, 4, 4, 9, 8, 31,…\n$ public_positional_accuracy       &lt;int&gt; 3, 13, 357, 347, 217, 4, 4, 9, 8, 31,…\n$ geoprivacy                       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ taxon_geoprivacy                 &lt;chr&gt; \"open\", \"open\", \"open\", \"open\", \"open…\n$ coordinates_obscured             &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"…\n$ positioning_method               &lt;chr&gt; \"\", \"\", \"\", \"\", \"gps\", \"\", \"\", \"\", \"\"…\n$ positioning_device               &lt;chr&gt; \"\", \"\", \"\", \"\", \"gps\", \"\", \"\", \"\", \"\"…\n$ user_id                          &lt;int&gt; 172086, 4930790, 144477, 5660178, 426…\n$ user_name                        &lt;chr&gt; \"Eric Koberle\", \"Ethan Gilmore\", \"\", …\n$ created_at                       &lt;chr&gt; \"2023-02-06 05:56:44 UTC\", \"2023-01-0…\n$ updated_at                       &lt;chr&gt; \"2023-02-10 02:50:33 UTC\", \"2023-01-0…\n$ quality_grade                    &lt;chr&gt; \"research\", \"needs_id\", \"needs_id\", \"…\n$ license                          &lt;chr&gt; \"CC-BY-NC\", \"CC-BY-NC\", \"CC-BY-NC\", \"…\n$ sound_url                        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ oauth_application_id             &lt;int&gt; 3, 3, 3, 333, 2, 3, 3, 2, 2, 3, 3, 3,…\n$ captive_cultivated               &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"…\n\nglimpse(pinePond_iNat)\n\nRows: 8\nColumns: 37\n$ scientific_name                  &lt;chr&gt; \"Pinus ponderosa\", \"Pinus ponderosa\",…\n$ datetime                         &lt;chr&gt; \"2022-08-09 18:00:33 -0700\", \"2020-07…\n$ description                      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA\n$ place_guess                      &lt;chr&gt; \"San Bernardino National Forest, Big …\n$ latitude                         &lt;dbl&gt; 34.22839, 34.23914, 34.21212, 34.2251…\n$ longitude                        &lt;dbl&gt; -116.8549, -116.8876, -116.8729, -116…\n$ tag_list                         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA\n$ common_name                      &lt;chr&gt; \"Ponderosa Pine\", \"Ponderosa Pine\", \"…\n$ url                              &lt;chr&gt; \"https://www.inaturalist.org/observat…\n$ image_url                        &lt;chr&gt; \"https://inaturalist-open-data.s3.ama…\n$ user_login                       &lt;chr&gt; \"jcarrk\", \"jiggajantastic\", \"josue79\"…\n$ id                               &lt;int&gt; 130186380, 52182504, 34645641, 332225…\n$ species_guess                    &lt;chr&gt; \"\", \"ponderosa pine\", \"ponderosa pine…\n$ iconic_taxon_name                &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ taxon_id                         &lt;int&gt; 48461, 48461, 48461, 48461, 48461, 48…\n$ num_identification_agreements    &lt;int&gt; 0, 1, 2, 0, 0, 0, 0, 0\n$ num_identification_disagreements &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0\n$ observed_on_string               &lt;chr&gt; \"2022-08-09 18:00:33-07:00\", \"Mon Jul…\n$ observed_on                      &lt;chr&gt; \"2022-08-09\", \"2020-07-06\", \"2019-10-…\n$ time_observed_at                 &lt;chr&gt; \"2022-08-10 01:00:33 UTC\", \"2020-07-0…\n$ time_zone                        &lt;chr&gt; \"Pacific Time (US & Canada)\", \"Pacifi…\n$ positional_accuracy              &lt;int&gt; 6, 53, 5, NA, 3, 5, 5, 10\n$ public_positional_accuracy       &lt;int&gt; 6, 53, 5, NA, 3, 5, 5, 10\n$ geoprivacy                       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA\n$ taxon_geoprivacy                 &lt;chr&gt; \"open\", \"open\", \"open\", \"open\", \"open…\n$ coordinates_obscured             &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"…\n$ positioning_method               &lt;chr&gt; \"\", \"\", \"\", \"gps\", \"\", \"\", \"\", \"\"\n$ positioning_device               &lt;chr&gt; \"\", \"\", \"\", \"gps\", \"\", \"\", \"\", \"\"\n$ user_id                          &lt;int&gt; 5960713, 3241047, 2173678, 105431, 10…\n$ user_name                        &lt;chr&gt; \"\", \"\", \"Josue Sandoval\", \"Shaun M. M…\n$ created_at                       &lt;chr&gt; \"2022-08-10 01:00:43 UTC\", \"2020-07-0…\n$ updated_at                       &lt;chr&gt; \"2022-08-10 01:00:53 UTC\", \"2021-05-3…\n$ quality_grade                    &lt;chr&gt; \"needs_id\", \"research\", \"research\", \"…\n$ license                          &lt;chr&gt; \"CC-BY-NC\", \"CC-BY-NC\", \"\", \"CC-BY-NC…\n$ sound_url                        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA\n$ oauth_application_id             &lt;int&gt; 3, 3, 3, 2, 2, 3, 3, 3\n$ captive_cultivated               &lt;chr&gt; \"false\", \"false\", \"false\", \"false\", \"…\n\n\nPlot all the data on a California map to orient geographically where it is and to check for overlap.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(pineJeff_iNat[ , c(\"longitude\", \"latitude\")], pch = \".\", col = \"blue\", cex = 3)\npoints(pinePond_iNat[ , c(\"longitude\", \"latitude\")], pch = \".\", col = \"red\", cex = 3)\npoints(TrailRun1[ , c(\"position_long\", \"position_lat\")], pch = \".\", col = \"black\", cex = 3)\n\n\n\n\n\n\n\n\nOverlay the plots and add research grade symbols (triangle) and needs_id (circle). By default ggplot will have zoomed in on the data given the bounds. We can see that both species occur in the same general area, but there are not any direct overlaps in the research grade observations and my trial running route.\n\nrun_plot2 &lt;- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = position_long, y = position_lat), color = 'black') +\n          geom_point(data=pinePond_iNat, aes(x = longitude, y = latitude, shape = quality_grade), color = 'red', size = 5) +\n          geom_point(data=pineJeff_iNat, aes(x = longitude, y = latitude, shape = quality_grade), color = 'blue', size = 5) +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nrun_plot2\n\n\n\n\n\n\n\n\nWe have many more Ponderosa pines near Mount Shasta including one I found on another run. For this iNaturalist observation I also took a photo of the cone. If you take a look at the Ponderosa pine observations you can find mine via my username (rjcmarkelz).\n\nbounds2 &lt;- c(40.194, -124.4323, 42.0021, -120) # Northern California Bounds\nPondPineNor_iNat &lt;- get_inat_obs(query = \"Pinus ponderosa\", bounds = bounds2, maxresults = 100)\nPondPineNor_iNat$user_login # Look for rjcmarkelz\n\n  [1] \"michael_long\"     \"michael_long\"     \"michael_long\"    \n  [4] \"kristay58\"        \"monicole\"         \"kristendimas\"    \n  [7] \"loantaka\"         \"cmccarron\"        \"matthewchovanec\" \n [10] \"chief_shiitake\"   \"symbiiotica\"      \"cmccarron\"       \n [13] \"luca_hickey\"      \"luca_hickey\"      \"mike-potts\"      \n [16] \"paulette99\"       \"paulette99\"       \"mugwortdr\"       \n [19] \"jessicadav\"       \"cmccarron\"        \"kristymorrow\"    \n [22] \"emily_jackson\"    \"emily_jackson\"    \"linda-s-carter\"  \n [25] \"alleneli\"         \"avidhiker\"        \"carexobnupta\"    \n [28] \"connorcochrane\"   \"luca_hickey\"      \"northgondwana\"   \n [31] \"alleneli\"         \"morbidius\"        \"steph_mo\"        \n [34] \"kristymorrow\"     \"ukiahhaiku\"       \"grmidnight\"      \n [37] \"ecline\"           \"damontighe\"       \"radamisprime\"    \n [40] \"morbidius\"        \"shuckabone\"       \"amkatros\"        \n [43] \"roxannereiners\"   \"max_forster\"      \"alan_rockefeller\"\n [46] \"alan_rockefeller\" \"alan_rockefeller\" \"alleneli\"        \n [49] \"jamesjarrett00\"   \"jamesjarrett00\"   \"madroneone\"      \n [52] \"luca_hickey\"      \"luca_hickey\"      \"steph_mo\"        \n [55] \"steph_mo\"         \"brane_dood\"       \"meadowlarkmerlin\"\n [58] \"biologystuff\"     \"sedgequeen\"       \"madroneone\"      \n [61] \"michaelkauffmann\" \"cmccarron\"        \"carexobnupta\"    \n [64] \"carexobnupta\"     \"jim22lawrence\"    \"dgrimmphd\"       \n [67] \"dgrimmphd\"        \"john_virzi_hort\"  \"danielkennedy\"   \n [70] \"ekgrijalva\"       \"danielkennedy\"    \"brendanswift\"    \n [73] \"greenfieldlouis\"  \"luca_hickey\"      \"hkibak\"          \n [76] \"gentilcore\"       \"gentilcore\"       \"tallianna\"       \n [79] \"chris_earle\"      \"liuelliot2187\"    \"brennanpopovic\"  \n [82] \"pikabombadier\"    \"frankdaluddung\"   \"dgrimmphd\"       \n [85] \"dgrimmphd\"        \"dgrimmphd\"        \"drew_meyer\"      \n [88] \"gcwarbler\"        \"k-bot\"            \"luca_hickey\"     \n [91] \"luca_hickey\"      \"sirhikesalot\"     \"drew_meyer\"      \n [94] \"justin426\"        \"luca_hickey\"      \"luca_hickey\"     \n [97] \"luca_hickey\"      \"luca_hickey\"      \"samuel_monteon\"  \n[100] \"lydia_365\"       \n\n\nFilter and select the image_url so we can compare the size and physical attributes of the cones.\n\nPondPineNor_iNat %&gt;% filter(user_login == \"rjcmarkelz\") %&gt;% select(image_url)\n\n[1] image_url\n&lt;0 rows&gt; (or 0-length row.names)\n\npineJeff_iNat %&gt;% filter(user_login == \"rjcmarkelz\") %&gt;% select(image_url)\n\n[1] image_url\n&lt;0 rows&gt; (or 0-length row.names)\n\n\nJeffery’s Pine with the larger (hand for scale) cone with the umbos pointed in: \nPonderosa Pine with the smaller (hand for scale) cone with the umbos pointed out:"
  },
  {
    "objectID": "posts/2021-05-15-mlk-cycling-nature/index.html",
    "href": "posts/2021-05-15-mlk-cycling-nature/index.html",
    "title": "MLK Shoreline iNaturalist data",
    "section": "",
    "text": "MLK Shoreline and iNaturalist Observations\nFor the last few years I commuted to work most days by bicycle along the Martin Luther King Jr. Regional Shoreline Park in Oakland, CA. This will be a series of data science posts exploring personal data collected by my smart watch and publicly available weather, nature and biodiversity data collected in this park. It is my hope that this will show into the brain of how a data scientist thinks, learns, asks questions, creates models, and visualizes data from right in their back yard through a series of posts. This is an intro post pulling in the data and doing some basic data exploration and visualizations.\nWe can start by loading a few libraries to make data manipulation and visualization easier.\n\nlibrary(tidyverse)\nlibrary(rinat)\nlibrary(lubridate)\nlibrary(leaflet)\n\nSet a bounding box around the park and subset some of the observations from the database that are “research” grade. Fortunately, this area is located in the San Francisco Bay Area with many professional and advanced amateur biologists around making observations. This park is also a popular spot for bird watching.\n\nbounds &lt;- c(37.72794, -122.23864,37.767032, -122.196754)\nmlk_bio &lt;- get_inat_obs(bounds = bounds, maxresults = 1000, quality = \"research\")\n\nInspect the data structure. At time of writing there are 5395 observations and 36 columns of data. We can see that there are various pieces of data that we would want to start taking a deeper look including: Scientific Name, the datatime of the observation, the latitude and longitude coordinates of the observation, associated image (image_url), and whether the observation is licensed as a CC for creative commons, to name a few. We also have a column of “user_login” data so we can see how many observations are contributed by different users.\n\ndim(mlk_bio)\n\n[1] 1000   37\n\nnames(mlk_bio)\n\n [1] \"scientific_name\"                  \"datetime\"                        \n [3] \"description\"                      \"place_guess\"                     \n [5] \"latitude\"                         \"longitude\"                       \n [7] \"tag_list\"                         \"common_name\"                     \n [9] \"url\"                              \"image_url\"                       \n[11] \"user_login\"                       \"id\"                              \n[13] \"species_guess\"                    \"iconic_taxon_name\"               \n[15] \"taxon_id\"                         \"num_identification_agreements\"   \n[17] \"num_identification_disagreements\" \"observed_on_string\"              \n[19] \"observed_on\"                      \"time_observed_at\"                \n[21] \"time_zone\"                        \"positional_accuracy\"             \n[23] \"public_positional_accuracy\"       \"geoprivacy\"                      \n[25] \"taxon_geoprivacy\"                 \"coordinates_obscured\"            \n[27] \"positioning_method\"               \"positioning_device\"              \n[29] \"user_id\"                          \"user_name\"                       \n[31] \"created_at\"                       \"updated_at\"                      \n[33] \"quality_grade\"                    \"license\"                         \n[35] \"sound_url\"                        \"oauth_application_id\"            \n[37] \"captive_cultivated\"              \n\n\nThere are photos included with a majority of the observations. Let’s take a look. \n\n\n\nBarn Swallow\n\n\n\n\n\nNorthern Mockingbird\n\n\nMake a quick plot of the data without a map overlay just to see what it looks like colored by large taxonomic groupings.\n\nmlk_bio_P1  &lt;- ggplot(mlk_bio, aes(x=longitude, y = latitude, color = iconic_taxon_name)) +\n       geom_point() + labs(color = \"Taxon\", title = \"MLK Shoreline iNaturalist Observations\")\nmlk_bio_P1\n\n\n\n\n\n\n\n\nThis is a popular birding spot, so one might expect there to be an over representation of bird (Aves) observations. Just how overrepresented are the Aves? A quick plot to take a look. Wow!\n\nmlk_bio_P2  &lt;- ggplot(mlk_bio, aes(x = iconic_taxon_name)) + stat_count() +\n                    scale_x_discrete(guide = guide_axis(angle = 45))\nmlk_bio_P2\n\n\n\n\n\n\n\n\nTake a look at the data with the Open Maps overlay to see the outline of the water front and the various roads and bridges where observers might be located.\n\nmlk_bio %&gt;% leaflet() %&gt;% addTiles() %&gt;%\naddMarkers(~longitude, ~latitude)\n\n\n\n\n\nDefinitely over plotted, but will deal with that in another post. Until then!"
  },
  {
    "objectID": "posts/2015-11-18-Trello.html",
    "href": "posts/2015-11-18-Trello.html",
    "title": "Introduction to Trello for Project Management",
    "section": "",
    "text": "Motivation\nThis quick post is an example of my scientific and collaboration work flow using the free features of Trello. I have tried many different ways of organizing ideas and implementing GTD. Email is NOT a good way to organize projects, especially long term ones. Elaborate tag systems can help, but I found that it is more hassle than it is worth when there are other tools available. For a while I used The Secret Weapon. Even if you do not use TSW system you should still take a look at these videos to get into that mindset. However, I was spending a lot of time sending emails to people instead of creating new things. Trello is a much better option because it adds a great collaboration component along with a visual way to organize projects. It is browser based and I recommend that you use Chrome because it has some nice Add-ons. Here is a rapid introduction to my work flow with ideas taken from GTD and TSW.\n ##### FIGURE 1: Trello data has a hierarchy going Organizations –&gt; Boards –&gt; Lists –&gt; Cards. Figure 1 is looking at a board I made for this tutorial.\n\nHere is where all the boards you are associated with are located.\nSearch board for specific items or data.\nOpen-source Trello time tracking app Plus\nAlerts. Will turn red when someone messages you or there is a change is made to a project you are “watching”. More on watching later.\nBoards are organized into Lists.\nIndividual Cards are attached to Lists and can be moved around between Lists.\nCards can have many things associated with them including due dates, people working on them, attachments etc. More on this in Figure 2.\nMy general work flow is to have Lists consisting of GOALS, TO DO, DOING, DONE, and ONGOING. Cards move from right to left for each day. If it is a one off task then it gets moved to DONE and eventually archived. If it is part of a larger project then it gets moved to ONGOING when completed because the card might be used again for the same project. Cards only go into DOING if you actively working on them. This helps me focus and use the time tracking for this task. It is also a good time to block incoming email and other distractions so you can single-task.\n\n ##### FIGURE 2: When you click on a card it flips it over for more details on the “back” of the card.\n\nMembers associated with the card. Excellent for collaboration and responsibility for to-do items on the card.\nColor labels to help visually orient you in boards with many cards.\nDue dates. These can sink with google calendar.\nCard description. Usually I keep this sparse.\nChecklists. Shows progress for each item. Cards can have multiple checklists.\nPlus time tracking for each card. Click this to start timer working on this card.\nComments. Update progress post working on the tasks associated with this card. I generally include what I did and what should be done the next hour of work on this project. This helps when picking the project back up after a while. Attach items (.csv, images, papers, etc.) to the card using your hard drive, Dropbox, Google Drive, or from a weblink. Integrates youtube videos for example.\nReferring to cards within boards with the link to the card. Also useful is an email address for each card. Attach that address when dealing with email and it will forward to the card.\nComments are great for communicating because you can tag people by their user name.\nAll the items on this card are tracked. Not only comments, but also movements between lists.\n\n ###### FIGURE 3\n\nClick on the menu bar where you will see a history of the entire board along with some options.\nAdd members to the board.\nYou can filter the cards you see by their color tag. This helps if it gets too crazy on a board. This is where you add the calendar integration and card aging power ups.\n\n\n\n\nFIGURE 4 Here is a reduced view of my personal project board.\n\nPlus time tracking. Click here for time spent on each board, reports, and all these other awesome features of how you spend your time.\nView the board as a calendar with all the due dates displayed.\nTiming is only on for current task: Trello Tutorial on my Website card.\nCard aging. A nice visual way to see what projects you have not touched for a while. This feature helps when reviewing goals and prioritizing the week.\n\n ###### FIGURE 5: This is what a collaborative board looks like. This is my undergrad’s lab notebooks and is organized a little differently than my personal work flow. Digital is nice because you can search the content. At the end of the quarter paper notebooks are scanned and attached to the notebook cards. This is where Trello really shines because it is flexible in communication and what can be associated with each card. For example, I take pictures of ideas in notebooks and white boards to post to Trello with some key words that make these ideas easily indexed.\n\nIndividual student lab notebooks.\nCollaborative learning projects we are working on.\nAnnouncements for goals, expectations, etc.\nResources. Comes in handy when new undergrad joins to get them up to speed quickly.\nGrants and longer term goals.\n\n\nBackups\nI backup my trello data once a week into a private repository using this script\n\n\nFile Sharing\nWe have joint Box accounts through our university for file sharing. No need to attach huge items to cards. Just link them to shared storage. These shared folders are also where all the boards are backed up and version controlled.\n\n\niOS Support\nTrello has an iOS App that I use to check up on things, send small messages, and add notes on the go.\n\n\nDecember 3, 2015 Update\nYou can also integrate Trello with Slack. Slack allows easy (free) access to github repositories. Currently you have to pay for that using Trello.\nMike Covington Pointed me to another Chrome plug-in, Elegantt, for nice visual summaries of project time-lines, overviews, and 100 foot views of projects.\nWhen researching slack integration I came across this post for managing REALLY large projects using Trello. It describes many of the same things above but for a much larger organization. Worth a read."
  },
  {
    "objectID": "posts/2024-02-16-Darmera-Art-Studio.html",
    "href": "posts/2024-02-16-Darmera-Art-Studio.html",
    "title": "Darmera Studios",
    "section": "",
    "text": "Darmera\nI co-founded a gallery/classroom/studio space in downtown Dunsmuir, CA called Darmera Studios with my fine-art friend Davis Elliott. Darmera is an art studio dedicated to the natural world and community.\nWe will open our doors May 4, 2024. Sign-up for our newsletter containing information about gallery shows, classes, workshops, and events.\nDarmera has three main spaces. The gallery space is in the front facing Dunsmuir Ave. The middle space is a classroom for the various art classes and retreats we will be hosting. The back warehouse space is for our art studios.\nWe have been working diligently on the remodel every weekend. Enjoy a few images of the process below you should also follow us on Instagram - @darmera.studio for the entire remodel journey.\n\n\n\nFraming out one of the gallery walls.\n\n\n\nCody adding the last layer of primer coat to the classroom.\n\n\n\nDavis milling a Sugar Pine log for trim and studio benches. Just look at the beautiful stack of wood drying in the back studio warehouse space. The beams in the foreground were milled by Davis a few years ago. We are using them as a post and a bench in the gallery.\n\n\n\nClose-up of the milled post."
  },
  {
    "objectID": "posts/2023-09-23-summarizing-weather-data.html",
    "href": "posts/2023-09-23-summarizing-weather-data.html",
    "title": "Scraping Weather Data 3",
    "section": "",
    "text": "This post is the third in a series teaching data journalists how to scrape website data, clean it up, and do some exploratory visualizations with it. See the other posts in the series Post 1, Post 2, and Post 4.\n\nIntroduction\nI started collaborating with the Mount Shasta Avalanche Center for a long form data journalism project looking at snow and avalanche condition forecasting with the backdrop of climate change. This adds an additional layer of uncertainty into any type of short-term forecast. Forecasters put out daily forecasts that integrate a lot of weather, snowfall, wind speed, direction, terrain, and previous snowfall information along with on the ground observational data collected from snow pits. Here is a brief summary of how to read a forecast.\nI thought this would be a good opportunity to show how you can collect, clean, and visualize your own data-sets for data journalism projects. I will be scraping the Avalanche Center’s public website to assemble an aggregated data-set of my own to ask my own questions. This is a series of posts on the topic using open-source data tools.\nThis post takes the scraped data from previous post and starts to make visual summaries of the data.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(zoo)\n\nINFILE DATA HERE\n\nload(file = \"~/DATA/data/Avalanche-Data-2017-2023.RData\")\nls()\n\n[1] \"weather3\"\n\n\nThe\n\nunique(weather3$`Fx Rating `)\n\n[1] \"LOW\"  \"MOD\"  \"CON\"  \"HIGH\" \"NONE\" \"EXT\" \n\nweather3$danger &lt;- as.factor(weather3$`Fx Rating `)\n\n# Define the desired order for factor levels\ndesired_order &lt;- c(\"LOW\", \"MOD\", \"CON\", \"HIGH\", \"EXT\")\n\n# Reorder the factor variable according to the desired order\nweather3$danger &lt;- factor(weather3$danger, levels = desired_order)\n\n\n# Quick few plots to make sure everything looks reasonable\nweather_plot &lt;- ggplot(weather3, aes(x=date, y=`Fx Snow (in) Min`)) +\n  geom_point()\nweather_plot\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/weather-scraping-plot.png\")\n\ncustom_colors &lt;- c(\"LOW\" = \"green\", \"MOD\" = \"yellow\", \"CON\" = \"orange\", \"HIGH\" = \"red\", \"EXT\" = \"black\")\n\nweather_plot2 &lt;- ggplot(weather3, aes(x=date, y=`Fx Wind (mi/hr) Max`, color = danger)) +\n  geom_point(shape = 5, size = 4) + scale_color_manual(values = custom_colors)\nweather_plot2\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/weather-scraping-plot-danger.png\")\n\nNow we are going to use the zoo package to calculate rolling averages of snow fall and wind - two important interacting components for creating avalanche conditions. Experiment a bit with the window width if you like. I think that a three day average for the amount of snow fall over the past 24 hours is a good metric.\n\n# # make sure library zoo is loaded\nweather3$snow_avg_3 &lt;- rollapply(weather3$`Ob Snow (in) HN24`, width = 3,\n                                 FUN = mean, align = \"left\", fill = NA)\nweather3$snow_avg_5 &lt;- rollapply(weather3$`Ob Snow (in) HN24`, width = 5,\n                                 FUN = mean, align = \"left\", fill = NA)\nweather3$wind_avg_5 &lt;- rollapply(weather3$`Ob Wind (mi/hr) Avg`, width = 5,\n                                 FUN = mean, align = \"left\", fill = NA)\nweather3$wind_avg_3 &lt;- rollapply(weather3$`Ob Wind (mi/hr) Avg`, width = 3,\n                                 FUN = mean, align = \"left\", fill = NA)\n\n\nweather_plot3 &lt;- ggplot() +\n                 geom_point(data = weather3,\n                            aes(x = date, y=snow_avg_3,\n                                color = danger), shape = 18, size = 4) +\n                 scale_color_manual(values = custom_colors) +\n                 scale_y_continuous(name = \"Snow Avg 3 days\",) +\n                 labs(title = \"\",\n                      color = \"Avalanche Danger\")\nweather_plot3\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/MSAC_3daySnow_AvyWarning.png\", height = 10, width = 8)\n\nweather_plot4 &lt;- ggplot() +\n                 geom_point(data = weather3,\n                            aes(x = date, y=wind_avg_3),\n                            color = \"azure4\") +\n                 geom_point(data = weather3,\n                            aes(x = date, y=snow_avg_3,\n                            color = danger), shape = 18, size = 4) +\n                 scale_color_manual(values = custom_colors) +\n                 scale_y_continuous(name = \"3 day Wind (mi/hr) Avg\",\n                           sec.axis = sec_axis(~.,\n                           name = \"Rolling Average Snow 3 day Accumulation\")) +\n                 labs(title = \"\",\n                      color = \"Avalanche Danger\")\nweather_plot4\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/MSAC_3daySnowWind_AvyWarning.png\", height = 10, width = 8)\n\nIn California the snow season starts when the rain historically starts to fall consistently in October and goes through the end of April of the following year. Let’s partition up this entire data set to reflect the winter seasons.\n\nweather3 &lt;- weather3 %&gt;%\n  mutate(season = case_when(\n    between(date, as.Date(\"2017-10-01\"), as.Date(\"2018-04-30\")) ~ \"Season17-18\",\n    between(date, as.Date(\"2018-10-01\"), as.Date(\"2019-04-30\")) ~ \"Season18-19\",\n    between(date, as.Date(\"2019-10-01\"), as.Date(\"2020-04-30\")) ~ \"Season19-20\",\n    between(date, as.Date(\"2020-10-01\"), as.Date(\"2021-04-30\")) ~ \"Season20-21\",\n    between(date, as.Date(\"2021-10-01\"), as.Date(\"2022-04-30\")) ~ \"Season21-22\",\n    between(date, as.Date(\"2022-10-01\"), as.Date(\"2023-04-30\")) ~ \"Season22-23\"\n  ))\n\n# Make the seasons span the years\nweather3 &lt;- weather3 %&gt;%\n  mutate(\n    water_year = ifelse(month(date) %in% 1:9, year(date), year(date) + 1),\n    day_of_water_year = as.integer(difftime(date, as.Date(paste0(year(date), \"-10-01\")), units = \"days\")) + 1\n  )\n\nweather3$day_of_water_year[weather3$day_of_water_year &lt;= 0] &lt;- weather3$day_of_water_year[weather3$day_of_water_year &lt;= 0] + 365 + as.integer(leap_year(weather3$date[weather3$day_of_water_year &lt;= 0]))\n\n\nweather3$season &lt;- as.factor(weather3$season)\nfiltered_data &lt;- weather3 %&gt;% filter(day_of_water_year &lt; 205 & day_of_water_year &gt; 50)\n\nPlot the new filtered dataset.\n\nweather_plot4 &lt;- ggplot(filtered_data, aes(x = day_of_water_year, y = snow_avg_3, color = danger)) +\n  geom_point(shape = 18, size = 5) +\n  facet_wrap(~season, ncol = 1) +\n  scale_color_manual(values = custom_colors) +\n  scale_y_continuous(name = \"Rolling Snow Average (3 day)\") +\n  labs(title = \"\", color = \"Avalanche Danger\")\nweather_plot4\n\n\n\n\n\n\n\n\nSave the data for the next post.\n\nsave(filtered_data, file = \"~/DATA/data/Avalanche-Data-2017-2023-filtered.RData\")\n\nSee the other posts in the series Post 1, Post 2 and Post 4."
  },
  {
    "objectID": "posts/2022-08-15-trailrunningtrainingdata/index.html",
    "href": "posts/2022-08-15-trailrunningtrainingdata/index.html",
    "title": "Heart Rate Data Analysis",
    "section": "",
    "text": "This analysis is based on a my personal exercise data so it is just a description to make the plots without the actual data existing in the website repository. I will do another post on how to make this dataset from exercise watch data at another time.\n\nTrail Running Data\nWe will be using the tidyverse and lubridate packages today to explore this dataset. Load the packages.\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\nLoad the combined dataset into the R session.\n\nload(\"MergedFitnessAug2022.RData\")\n\nThe exercise watch I use has the ability to detect heart rate and it works fairly well. Here I create a new column of data that breaks up the heart rate information into different zones roughly corresponding to different physiological states. These zones are defined by physiological testing outlined by The Uphill Athlete.\n\nmerged_fitness$HRzone &lt;- cut(merged_fitness$heart_rate,c(0,120,155,163,174, 188, 200))\nlevels(merged_fitness$HRzone) &lt;- c(\"R\",\"Z1\",\"Z2\",\"Z3\",\"Z4\",\"Z5\")\n\nConvert the dataframe into a tibble which is a tidyverse dataframe that has some additional properties to make it easier to examine what is going on.\n\nmerged_fitness &lt;- as_tibble(merged_fitness)\n\nSubset the large exercise dataframe to just include Trail Running as an activity. Make a quick plot of the heart rate zone data.\n\nTrailRun1 &lt;- subset(merged_fitness, activity == \"TrailRunning\")\np1 &lt;- ggplot(TrailRun1, aes(x=heart_rate, fill = HRzone)) +\n    geom_histogram()\np1\n\n\nI trained very seriously for the Headwaters Trail Ultra starting in early 2022. To take a look at how much time I spent in each heart rate zone and what altitude I trained at, I made a data subset for the training period. You can see that I spent most of my time either in Z1 or Z2/Z3 for training as outlined in the Uphill Athlete training plans. A bulk of my cardiovascular training is spent below 155 beats per minute (Zone 1 Threshold), with some harder workouts in higher heart rate zones (Zone 2/3) and occasionally in Zone 4. A bulk of my recovery workouts were hiking or easy mountain biking so they are not captured in this view of my exercise data. You can also see that a majority of my exercise is at ~1225-1250 m, or around the elevation that I live.\n\ntrailRun_2022 &lt;- TrailRun1 %&gt;% filter(timestamp &gt; ymd_hms(\"2022-01-01 01:28:14\") & timestamp &lt; ymd_hms(\"2022-06-20 01:28:14\"))\np2 &lt;- ggplot(trailRun_2022, aes(x=heart_rate, fill = HRzone)) +\n       geom_histogram() +\n       scale_x_continuous(name=\"Heart Rate (Beats Per Minute)\", limits=c(0, 200)) +\n       scale_y_continuous(name=\"Count\", limits=c(0, 62000))\np2\n\n\n\np3 &lt;- ggplot(trailRun_2022, aes(x=altitude)) +\n       geom_histogram() +\n       scale_x_continuous(name=\"Altitude (m)\", limits=c(0, 2500)) +\n       scale_y_continuous(name=\"Count\", limits=c(0, 75000))\np3\n\n\nTo show a few different types of work outs, I make some additional data subsets to make quick plots. Here I subset specific Zone 1, Zone 1/2/3, and a long hard Zone 3 efforts.\n\ntrailRun_Z1 &lt;- trailRun_2022 %&gt;%\nfilter(timestamp &gt; ymd_hms(\"2022-06-05 01:28:14\") & timestamp &lt; ymd_hms(\"2022-06-06 01:28:14\"))\n\ntrailRun_Z2 &lt;- trailRun_2022 %&gt;%\nfilter(timestamp &gt; ymd_hms(\"2022-03-01 01:28:14\") & timestamp &lt; ymd_hms(\"2022-03-02 01:28:14\"))\n\ntrailRun_Z3 &lt;- trailRun_2022 %&gt;%\nfilter(timestamp &gt; ymd_hms(\"2022-07-08 01:28:14\") & timestamp &lt; ymd_hms(\"2022-07-10 01:28:14\"))\n\nThe Zone 1 workout was a long workout in the Klamath Mountains descending down into the Trinity River Headwaters Basin and then back out to meet up with the PCT. This is also the run where we found some large patches of Cobra Lilies. I am also making a vector of colors so that they will remain consistent across the following plots and match the original colors in the Heart Rate Histogram above.\n\ncols3 &lt;- c(\"R\" = \"#F8766D\",  \"Z1\" = \"#B79F00\", \"Z2\" = \"#00BA38\", \"Z3\" = \"#00BFC4\", \"Z4\"= \"#619CFF\", \"Z5\" = \"#F564E3\", \"NA\" = \"grey50\")\n\ntrailRun_Z1$seconds &lt;- as.numeric(rownames(trailRun_Z1))\np4 &lt;- ggplot(trailRun_Z1, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Heart Rate (Beats Per Minute)\") +\n      scale_color_manual(values = cols3)\np4\n\n\n\np5 &lt;- ggplot(trailRun_Z1, aes(x=seconds,  y=altitude, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Altitude (m)\") +\n      scale_color_manual(values = cols3)\np5\n\n\nThe following run is mix of heart rate zones. I have a long warm up followed by a fast climb. I recover on the way down from the climb and then have a fairly steady Zone 2 workout back up the road to the start of the run.\n\ntrailRun_Z2$seconds &lt;- as.numeric(rownames(trailRun_Z2))\np6 &lt;- ggplot(trailRun_Z2, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Heart Rate (Beats Per Minute)\") +\n      scale_color_manual(values = cols3)\np6\n\n\n\np7 &lt;- ggplot(trailRun_Z2, aes(x=seconds,  y=altitude, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Altitude (m)\") +\n      scale_color_manual(values = cols3)\np7\n\n\nThis final workout was a hard one! The run was 28.87 km (~18 miles) with 1306 m (4285 feet) of gain/loss. I averaged 166 beats per minute for over 3 hours. I was mostly in heart rate zone 3 with some time in zone 2 and zone 4. On the way down I was feeling very uncomfortable, but kept up the intensity to make sure I set a personal record on this route and would not have to retry it this season. This was my final hard training run before tapering for the Headwaters Trail Ultra. I knew I was ready for the race after this run!\n\ntrailRun_Z3$seconds &lt;- as.numeric(rownames(trailRun_Z3))\np8 &lt;- ggplot(trailRun_Z3, aes(x=seconds,  y=heart_rate, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Heart Rate (Beats Per Minute)\") +\n      scale_color_manual(values = cols3)\np8\n\n\n\np9 &lt;- ggplot(trailRun_Z3, aes(x=seconds,  y=altitude, col=HRzone)) +\n      geom_point() +\n      scale_x_continuous(name=\"Time (Seconds)\") +\n      scale_y_continuous(name=\"Altitude (m)\") +\n      scale_color_manual(values = cols3)\np9"
  },
  {
    "objectID": "posts/2021-08-25-ComicBookColoring.html",
    "href": "posts/2021-08-25-ComicBookColoring.html",
    "title": "Digital Comic Book Coloring Process",
    "section": "",
    "text": "Comics Coloring Class\nI recently finished a comic book coloring class taught by Chris Sotomayer with special guest instructor/critic Marissa Louise through Comics Experience. Soto is not only a top working talent, but is also a great no non-sense teacher. The class came with a large selection of donated line art from all the major publishers to color “test pages” or entire books.\nThis post is really only touching some of the major points discussed in the course. I learned through improving my page over the course, but learned a great deal more listening to the critiques of other student work. Many of the students were fairly advanced and chose pages with multiple light sources, colored lights from laser blasts, moonlight scenes, and shots from hell (literally). This class was amazing to say the least.\nI was a new user of Clip Studio Paint (CSP) when I started this class. Getting comfortable with CSP added to the learning curve. I made many simple errors due to my ignorance of the details of this program that compounded, but I figured it all out for the final image through multiple rounds of critiques. I am happy with the final page. Enjoy the process!\n\n\n\nImage Choice\n\nLine art by Robert Atkins and Clayton Brown - IDW G.I. JOE 105\nI chose this image to color because it most closely fit with the type of outdoor adventure art that I wanted to continue making. I liked that the page was center line composition of two characters running through a desert landscape towards a military base that included two long shots and two medium shots. This page represents simple visual storytelling and I wanted to see how color could enhance a simple story.\n\n\n\nSet-up Clip Studio Paint\nWhen working digitally I had three layers. The inks were on their own layer over the top of a color layer that was on top of a white background. I set the ink layer opacity to about 60% to be able to follow/trace the lines when doing the flats. Also, setting all the tools that you will be working with to no anti-aliasing. This setting will ensure no blending of pixels, just stark pixel color transitions for a finished flat that is set up for the next steps. I made a mistake with one of tools as you will see below.  \n\n\n\nPanels\nTo start digital coloring you first define the panels with a solid color. You will gradually cut this solid panel shape into the smaller color shapes in the flatting process. By having the panel background a different color from the background of the page (white in this case), you can do shape or color selection in the flatting stage more easily and track your progress as the panel color gradually gets smaller with each new defined shape. \n\n\n\nFlats\nThe point of flatting is to get all the major objects that will be different colors in the final image separated from one another and the background. Flatting takes a long time and double that for me because I needed to re-flat (see below). Flatting starts with the large shapes in the foreground and then moves to background (or visa-versa) depending on the panel. After the page is flatted, the process becomes easy to select by color and make large changes all at once. \nThere should just be simple colors and stark color transitions when you zoom in on a properly flatted page. In the following image, there are blended pixels on the edges between colors. This is a huge problem if you want to select entire color sections for the down stream processes because these blended pixels will not get selected. I could not figure out what was going wrong with my page, until I did a test area to reproduce my process and found it was the fill bucket tool. \nOpps! I also forgot uncheck the anti-aliasing on the fill bucket tool! \nI ended up re-flatting the entire page as that was easier than fixing. Lesson learned. Much better. \n\nFinished flat\nI was unsure at this point if I wanted the two characters to be in the same base camouflage color scheme so I flatted them as separate colors. This image also shows that as long as the colors for each of the flatted shapes are different it does not matter too much what they are. I am sure if you are drawing similar characters in similar environments over multiple pages, you could save yourself some time by flatting in the colors trying to match more closely what the final panel will look like. \n\n\n\n\nColor Studies\nOnce the flatting is done properly it is easier to do color and value studies by selecting the shapes and filling with the paint bucket. The paint bucket was especially helpful when doing the camouflage uniforms, the backpacks of the soldiers, the large shapes of the sky, and the rock background. By focusing only on the large shapes you could do even more quick color studies.\nI wanted the base colors to reflect commonly seen camouflage patterns and somewhat natural landscape colors even if these two things were not aligned for the purpose of camouflage (matching the environment perfectly). I tried a split-complementary three color scheme and a tetrad (double compliment) four color scheme. I also experimented with different values and atmospheric effect in the sky. I will have a follow-up post on the color theory behind these choices and other options.\n\nSplit Complementary Color Scheme\n\n\n\nimage\n\n\n\n\nTetrad Color Scheme\n\n\n\nimage\n\n\n\n\n\n\nValue Study\nNext was a pure value study with a range of values from 20-80% leaving the white (0%) for the page backgrounds and the black (100%) for the inks. At this stage there is a lot of zooming way out from the image or squinting to blur all the detail and make sure that the characters and environment shapes “read” as separate just based on their value. \n\n\n\nCombination of Value and Color First Attempt\nWhen completing the value study, I accidentally made the white background not white! I could not see this on my digital screen. It was white as far as I was concerned because locally it was the whitest value. All colors are relative!\nDuring the critique for this week the background pinks were a little too pink making this have a “Valentines Day Card” vibe. G.I. JOE Valentines day cards were a thing when I was a kid, but this was not my color intention, so I needed to fix it. It was also pointed out that “STAT BG” in the second panel meant static background. This was a note to the inker to copy the background from panel one, but in this version it did not get completed. \n\n\n\nRefinement\nI muted the pink hues and warmer colors in general and figured out how to cut and duplicate the background from the inks. I also adjusted the character colors/values to increase the contrast with the background (using a lot of the squinting technique). \nNext I made some adjustments to the black line art in the background to further increase the contrast. The background line art was shifted from black to a very dark version of the base color of the object. This reduces the local contrast of the line art and the object (e.g. mesas). This line art adjustment also helps the background fade more because the details are less visible simulating atmospheric interference when looking at a real landscape. However, after this line art adjustment it became less clear what the viewer should be focusing on in the first two panels. The combination of the background dropping away and the middle ground and foreground being approximately the same values made it confusing for the eye. I think this is a fascinating effect. Balanced images can be thrown off by small tweeks with unintended consequences. \n\n\n\nFinal Polish\nI darkened the foreground rocks and it instantly gives the first two panels a frame around the characters and a clear foreground, middle ground and background. This effect is just the reverse of the atmospheric interference I was trying to achieve by lightening the the inks in the background. At the same time the darker pink/purple in foreground further reduces the “Valentines Day Card Vibe”. Next I lightened the areas around the boots with some “dust” to add to the effect. Finally, I cleaned up the dark edge of the page on the right that was left over from scanning the inks and removed the artists names. Finished page.\n\n\n\nimage"
  },
  {
    "objectID": "posts/2023-07-14-explorer-observations-1.html",
    "href": "posts/2023-07-14-explorer-observations-1.html",
    "title": "Explorer Observation Toolkit - 1",
    "section": "",
    "text": "When I am out training by hiking or trail running I often come across animal prints on the trail. Unsurprisingly, there is an entire discipline of field biology that quantifies animal sign (prints, scat, paths, runs, broken twigs). These animal indicators are collectively called spoor. The trails and fire roads that I do a lot of exploring on are also highways for other animals because they are already clear. In the winter there are prints left in the snow. In the spring there are puddles that pick up prints. In the dry summers and fall, the dustier parts of the trail act as good substrates for picking up prints. Tracking is an all season activity!\nThere are a number of resources on ground level tracking of animals I have read through over the years. This is the first a series of short posts on the topic.\nI have the goal of finding spoor for all of the large carnivores in the area:\n\nblack bear (Ursus americanus)\ncougar (Puma concolor)\nbobcat (Lynx rufus)\ncoyote (Canis latrans)\ngrey wolf (Canis lupis)\ngrey fox (Urocyon cinereoargenteus)\nSierra Nevada red fox (Vulpes vulpes necator)\n\nI would like to expand this list to all of the major mammals in the area outlined in “A Field Guide to Animal Tracks and Scat of California” (2012) by Elbroch, Kresky, Evans."
  },
  {
    "objectID": "posts/2023-08-02-artsciencehack-2.html",
    "href": "posts/2023-08-02-artsciencehack-2.html",
    "title": "Art Science Hackathon v2.0",
    "section": "",
    "text": "Concept\nFor the second iteration of the ArtScienceHack in 2016, we decided to bring our art, design, science, engineering, and data skills together to work on a single project for 48 hours. We had very minimal exposure to the processing language prior to starting this, but I had experience building things in many other languages. Processing is a good first language to learn for designers and artists so we started there.\nRead more about the first ArtScienceHack here.\n\n\nGoals\nRapidly learn the basics of processing and make an interactive model of plant growth that takes human movement as input to the model.\n\n\nOutcomes\nOverall the hackathon was a success. We had an interactive model of plant growth that had a fundamental trade-off function built in. This trade-off is visualized as the root:shoot ratio using hand control through the hacked xbox connect controller.\n\nArtScienceHack-v-2.0 Plant Growth Model Xbox Connect Hack\n\nCode available here."
  },
  {
    "objectID": "posts/2022-01-20-rmarkdown-comic-script.html",
    "href": "posts/2022-01-20-rmarkdown-comic-script.html",
    "title": "Generic Markdown Comic Script",
    "section": "",
    "text": "A quick post to outline how I create simple comic scripts using markdown and then render them to a PDF. This is loosely based off of the Comics Experience Example Script with some modifications for markdown specific syntax like page-breaks. I like to have each comic page on it’s own printed page for editing. This allows room to thumbnail ideas directly on the scripts to workout storytelling ideas.\n\nRendering PDFs using rmarkdown\nlibrary(knitr)\nlibrary(rmarkdown)\nsetwd(\"path/to/markdown/file/directory\")\nlist.files()\nrender(\"comic-script.md\")\n\n\nrmarkdown formatted comic script example below\n---\ntitle: \"Title with version number: v6.1.1\"\nauthor: Author Name\ndate: January 20, 2022\nheader-includes:\n- \\usepackage{fancyhdr}\n- \\pagestyle{fancy}\n- \\fancyhead[CO,CE]{STORY NAME -NAME NAMERSON}\n- \\fancyfoot[CO,CE]{Copyright 2022 - NAME NAMERSON - email@email.com}\n- \\fancyfoot[LE,RO]{\\thepage}\noutput: pdf_document\n---\n\n# Background\nSTORY SENTENCE -One sentence summary.\n\nCHARACTER 1 BIO - What do they want in the pages?\n\nCHARACTER 2 BIO- What do they want in the pages?\n\n\n# Story Synopsis\n1 paragraph summary of the action/events of the story. Keep it dry and to the point. First sentence is the first page and the last sentence is the last page.\n\n# Contact Info\n**Your Name**\n\nemail@email.com\n\n[www.codymarkelz.com](www.codymarkelz.com)\n\n\n\n\\pagebreak\n\n# PAGE ONE- SIX PANELS\nOne sentence page summary.\n\n## PANEL 1\nPanel description of single action, dialogue, sound effects SFX.\n\n## PANEL 2\nPanel description of single action, dialogue, sound effects SFX.\n\n1. **CHARACTER 1**: statement and dialogue.\n\n## PANEL 3\nPanel description of single action, dialogue, sound effects SFX.\n\n1. **CHARACTER 1**: statement and dialogue.\n\n## PANEL 4\nPanel description of single action, dialogue, sound effects SFX.\n\n## PANEL 5\nPanel description of single action, dialogue, sound effects SFX.\n\n1. **CHARACTER 1**: dialogue!\n\n## PANEL 6\nPanel description of single action, dialogue, sound effects SFX.\n\n1. **CHARACTER 2**: **winded** dialogue!\n\n**SFX** WHOOOMPF!\n\n\n\n\\pagebreak\n\n#  PAGE TWO- THREE PANELS\nOne sentence page summary.\n\n## PANEL 1\nPanel description of single action, dialogue, sound effects SFX.\n\n## PANEL 2\nPanel description of single action, dialogue, sound effects SFX.\n\n## PANEL 3\nPanel description of single action, dialogue, sound effects SFX."
  },
  {
    "objectID": "posts/2022-09-30-DSxD-Sketchnote.html",
    "href": "posts/2022-09-30-DSxD-Sketchnote.html",
    "title": "DSxD Sketchnote",
    "section": "",
    "text": "Data Science by Design (DSxD) Reconnect Meeting Sketchnote\nThis fall, Data Science by Design (DSxD) hosted a Reconnect Meet-Up for previous participants of other meetings to get together again. The DSxD community is really diverse in interest and background. Since the first DSxD creator conference this has been one of my favorite online communities to interact with (mostly through Slack). There is always something interesting being shared there and I recently started attending the DSxD book club.\nThe sketchnote represents many of the major ideas discussed during the reconnect event. The illustration is wide ranging because DSxD topics and participants are wide ranging. The portion in the bottom left corner was my favorite. The idea was to map data and sketch with it using all of our senses. This section was led by multi-talented Max Graze. Overall, I really like being a part of such a delightful and creative community."
  },
  {
    "objectID": "posts/2024-09-05-AlpineHutCareTaker.html",
    "href": "posts/2024-09-05-AlpineHutCareTaker.html",
    "title": "Mount Shasta Alpine Hut Caretaker",
    "section": "",
    "text": "This spring I got connected with a few members of the local chapter of the Sierra Club Foundation. This is the non-profit branch of the Sierra Club. The Sierra Club owns a large chunk of land (720 acres) on Mount Shasta that contains an alpine hut on it. The Shasta Alpine Hut (Formally Horse Camp Hut) recently celebrated it’s 100th year in 2022. The Shasta Alpine Hut is used a basecamp in the late spring and early summer for climbers attempting Mount Shasta at 14,179 ft (4,322 m). The history of the Alpine hut goes back as far as the hut has existed. There have been many caretakers over the years and the job has evolved just as much over that timeframe. If you visit Mount Shasta City, you can go to the Mount Shasta Museum to see a cool display of the history of the hut and caretakers.\nFor me this was a perfect opportunity to spend weekend mornings and early afternoons in the alpine managing the hut, talking to tourists, working on trails, cleaning the bathrooms, hiking around, doing art, nature journaling, meditating, reading about alpine ecology and somehow getting paid to do all of this! A dream job!\nI have a number of alpine ecology observations and nature journal pages to share in upcoming posts."
  },
  {
    "objectID": "posts/2024-12-30-December2024Review.html#december-2024",
    "href": "posts/2024-12-30-December2024Review.html#december-2024",
    "title": "December 2024 Review",
    "section": "December 2024",
    "text": "December 2024\nWhat a great month to end the year on. There is something that is always retrospective about the end of the year. New beginnings. Hopefully you already started those beginnings! It is easier to see if you will stick with it if you are already doing it. If it is a good idea then you should just figure out how to start doing it in the smallest way possible to move it forward. I had a lot of time to contemplate integrate the lessons from the year (next post) and revamp my 5 year plans.\nI finished up an 8 page comic (Tarmo) and shared it with friends and family. It is one many partially completed projects that could be completed at any time once the motivation strikes. My art friend DS and I sat on a video call while each worked on finishing up an unfinished comic. There was some chatting, but mostly just like working in the same office and sharing the results. Tarmo is my honorary Finnish name from my postdoc friends which roughly translates to energy. I am having fun putting this character through the ringer. I want him to be gritty as fuck in all his adventures.\nI started a new training program this month (various stats). I did the first three weeks and am now in the recovery/integration week. At the end of each week I am physically tired and looking forward to my rest day (Monday) where I just do art, think , read, cook and roll out. Our trail running crew had a Jingle Jog/potlock hosted by the matriarch of the group. It was miserable conditions, but everyone was in good spirits. I utilized my evolved thick hair to keep me warm when soaking wet and then heading up in elevation to snow-line. The early season snow provided a nice base for nordic skiing. I did a number of 20 km days, 1 30 km, and a 50 km day. It is going to be a great season having these Zone 1 (Z1) workouts already in the exercise base bank.\nCaryn and I did our annual back country ski to get a Christmas Tree. We harvest one that is just small enough for me to carry back through the forest on skis. Hence our continued fascination with “Charlie Brown” trees. We also spent a warmer afternoon winterizing the house. We were not prepared for the early season snow so I needed it melt a bit before getting on the roof to remove any remaining leaves and acorns. We also did our 2x/year chimney sweep.\nThe holidays messed up the class schedule a bit, but provided some time off of teaching weekly classes (watercolor/ink and nature journaling 3x each). I sold one art piece at the opening last month, but sold three more this month. It feels good because one of each of the categories is going to go on someones wall, including one in Philadelphia (visiting for the holidays).\nSocially, Caryn and I attended 4 friend dinners and are going to participate in a space themed murder mystery tonight for NYE. My character is a two headed “Beeble Brayn” loosely based off Beeblebrox from Hitchhikers Guide. My second head is a sock puppet made out of a threadbare cycling sock. In my role on the non-profit board, I volunteered for a movie night and for Giving Tuesday."
  },
  {
    "objectID": "posts/2025-03-30-ArizonaNatureJournalRetreat.html",
    "href": "posts/2025-03-30-ArizonaNatureJournalRetreat.html",
    "title": "Arizona Nature Journaling Retreat",
    "section": "",
    "text": "Sonoran Desert Nature Journaling Retreat\nAt the end of March and into the first week of April I attended a Field Arts Bootcamp put on by Roseann and Jonathan Hansen. Roseann Hanson is such an inspiring artist, writer, explorer, teacher and entrepreneur.\nAravaipa Canyon Ranch was out of cell reception and did not have internet access. This immediately made our group of about 20 much more intimate. Throughout the retreat I got to have a meaningful conversation 1:1 or small group conversation with all the other participants. I learned just as much from other participants as I did from the mini-workshops. Overall, I would highly recommend a retreat with Roseann!\n\n\n\nThe largest game changer for my personal art process was learning about Lexington Gray Noodler’s Ink from Irme. She let me use some of the ink in a new refillable TWSBI Eco fountain pen. I ran the pen dry in a few days! I had been using Platinum Black Carbon Ink for all my inking. I still love this ink, but the gray ink makes the line contrast a value shift lighter allowing you to still add a dark black to an illustration for additional effect. The Noodler’s ink also stains and dries almost immediately with no reactivation when doing watercolor washes.\nWe went on many hikes around the ranch and I was able to get away for a few trail runs on the endless ranching roads and washes.\nThe trip was so fun and inspiring. I got to spend 1.5 days in Tucson rambling around on foot seeking out art stores, parks, public art, and of course tacos!\nI made a 16 page mini-zine after the trip based on my field sketches. The original zine illustration pages ended up in our 1 Year Anniversary Show at Darmera\nA few pages from my 3.5x5.5 sketchbook.\n\n\n\n\n\n\n\n\n\nI will do a more comprehensive write-up soon"
  },
  {
    "objectID": "posts/2023-01-01-mount-eddy-trail-run/index.html",
    "href": "posts/2023-01-01-mount-eddy-trail-run/index.html",
    "title": "Mount Eddy Trail Run",
    "section": "",
    "text": "Foxtail Pine Cone Illustration\n\nIntroduction\nMy partner and I recently revisited one the conifer species that occur in the Miracle Mile, but by trail running up to the top of Mount Eddy (9,037 ft; 2,754 m) in the Klamath Range. The final sub-alpine zone near the top of the mountain is a large grove of Foxtail Pine (Pinus balfouriana). I paid another visit to that same grove in another recent post, but did not go up to the higher elevations above 8000 ft.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(gpx)\nlibrary(rayshader)\nlibrary(rgbif)\nlibrary(data.table)\nlibrary(maps)\n\nIn-file the trail run gps data and make a data frame to use for plotting.\n\nrun &lt;-  read_gpx('~/DATA/data/mount_eddy_trail_run.gpx')\nsummary(run)\n\n          Length Class  Mode\nroutes    1      -none- list\ntracks    1      -none- list\nwaypoints 1      -none- list\n\nTrailRun1 &lt;- as.data.frame(run$routes)\nTrailRun1$Time &lt;- as.numeric(row.names(TrailRun1))\n\nMake a quick plot using the latitude and longitude coordinates.\n\nTR_p1 &lt;- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black', size = 2) +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nTR_p1\n\n\n\n\n\n\n\n\nTake a look at the elevation profile of the run.\n\nTR_p2 &lt;- ggplot() +\n          geom_line(data = TrailRun1, aes(x = Time, y = Elevation), color = 'black', size = 2) +\n          xlab(\"Time (seconds)\") + ylab(\"Elevation (m)\")\nTR_p2\n\n\n\n\n\n\n\n\nWe can also plot the run and false color it based on the elevation. We can pass this plot to the plot_gg() function in the rayshader package to make a 3D plot of the run. The code for that is not run on the website because it takes too long to render, so I am showing the rendered snapshot as an external image instead.\n\nTR_p3 &lt;- ggplot() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude, color = Elevation), size = 2) +\n          scale_color_continuous(limits=c(800,2800))\nTR_p3\n\n\n\n\n\n\n\n# Not run for website rendering purposes, but you should!\n# plot_gg(TR_p3, width = 15, height = 15, multicore = TRUE, scale = 1000,\n#         zoom = .7, theta = 10, phi = 20, windowsize = c(3000, 3000))\n# Sys.sleep(0.2)\n# render_snapshot(filename = \"mt-eddy-run-elevation-plot3.png\", clear = TRUE)\n\n\nUsing the Latitude and Longitude coordinates of the area we can make a general area polygon to be used for a GBIF species observation query to the public database.\n\nnorcal_geometry &lt;- paste('POLYGON((-122.6 41.35, -122.6 41.25, -122.4 41.25, -122.35 41.25, -122.35 41.35, -122.6 41.35))')\n\nmm_species &lt;- c(\"pinus balfouriana\") # can add multiple species here for larger query\n\nfoxtail_data &lt;- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 10000,\n                   geometry = norcal_geometry)\nfoxtail_data\n\nRecords found [74] \nRecords returned [74] \nArgs [hasCoordinate=TRUE, occurrenceStatus=PRESENT, limit=10000, offset=0,\n     scientificName=pinus balfouriana, geometry=POLYGON((-122.6 41.35, -122.6\n     41.25, -122.4 41.25, -122.35 41.25, -122.35 41.35, -122.6 41.35))] \n# A tibble: 74 × 124\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ hosti…⁷ publi…⁸\n   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1 41657… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 2 41657… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 3 44002… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 4 43998… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 5 44000… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 6 44001… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 7 43999… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n 8 44004… Pinus …    41.3   -122. cdc    50c950… 28eb1a… 997448… 28eb1a… US     \n 9 44049… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n10 44363… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… 28eb1a… US     \n# … with 64 more rows, 114 more variables: protocol &lt;chr&gt;, lastCrawled &lt;chr&gt;,\n#   lastParsed &lt;chr&gt;, crawlId &lt;int&gt;, basisOfRecord &lt;chr&gt;,\n#   occurrenceStatus &lt;chr&gt;, taxonKey &lt;int&gt;, kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;,\n#   classKey &lt;int&gt;, orderKey &lt;int&gt;, familyKey &lt;int&gt;, genusKey &lt;int&gt;,\n#   speciesKey &lt;int&gt;, acceptedTaxonKey &lt;int&gt;, acceptedScientificName &lt;chr&gt;,\n#   kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   species &lt;chr&gt;, genericName &lt;chr&gt;, specificEpithet &lt;chr&gt;, taxonRank &lt;chr&gt;, …\n\nfoxtail_coords &lt;- foxtail_data$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nPlot the observations on the California map to see the limited polygon sampled.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(foxtail_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\n\n\n\n\nPlot all of the observations using ggplot for the zoomed in area.\n\nfoxtail_plot1  &lt;- ggplot(foxtail_coords, aes(x=decimalLongitude, y = decimalLatitude)) +\n                             geom_point(color='red') + labs(title = \"MM Zone\")\nfoxtail_plot1\n\n\n\n\n\n\n\n\nCombine trail running and foxtail pine occurrence observations.\n\nrun_plot2 &lt;- ggplot() +\n          coord_quickmap() +\n          geom_point(data = TrailRun1, aes(x = Longitude, y = Latitude), color = 'black') +\n          geom_point(data=foxtail_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n          xlab(\"Longitude\") + ylab(\"Latitude\")\nrun_plot2"
  },
  {
    "objectID": "posts/2023-07-21-explorer-exercise-2.html",
    "href": "posts/2023-07-21-explorer-exercise-2.html",
    "title": "Explorer Fitness - 2",
    "section": "",
    "text": "As part of the explorer fitness program I have developed, there is a heavy emphasis on elevation gain and loss. During the last few summers, our local trail running group has been meeting on Wednesdays after work for a progressively harder hill running workout, and this fits in perfectly. Everyone does the same out-and-back route, but we go up at our own pace. After reaching the pre-agreed stopping point, we wait for everyone and then do a slower social run on the way down. The workout changes location every few weeks to keep things fresh, but it also allows the participants to compare efforts across different locations.\nAbove is a graph of a hill climb workout. I did a light warm-up for 15 minutes, followed by waiting around for the other participants to show up at the start (Zone 1-3). I like to have gone through all the heart rate zones that I will be utilizing during the workout as a proper warm-up. In this case, the workout was mostly a lactate threshold pace (upper end of Zone 3). For the nerds out there, it is the pace at which my body can still clear out the blood lactate (~2 mmol/L). This level is right on the border between Zone 3 (Yellow) and Zone 4 (Orange). For me, the lactate threshold is spending time above 172-174 bpm heart rate. While I can and do go higher than that threshold, I use Zone 4 sparingly, as that is when blood lactate rapidly builds up. In the case of the hill climb workout, I went into Zone 4 a number of times on particularly steep or technical sections, but always slowed down after to get back below the threshold so I could maintain the overall Zone 3 pace for longer.\nOverall, I am happy with this effort. I climbed 2100 feet in 40 minutes. This beats my previous time on this route from last season by over 3 minutes.\n\nThis is the second in a series of posts on explorer fitness. The first post in the series is here.\nI have previously posted about training here and the Crested Cara Cara birds I saw on one of my shorter runs here."
  },
  {
    "objectID": "posts/2022-02-01-uc-reserve-data-1/index.html",
    "href": "posts/2022-02-01-uc-reserve-data-1/index.html",
    "title": "UC Reserve System Environmental Data",
    "section": "",
    "text": "A short post on keeping small datasets in a data directory on my site, infiling the data, and then manipulating it.\nThe UC Reserve System has a many data sources including species lists. For this post I used the Plant Species List Excel File compiled by Brian P. Haggerty and Susan J. Mazer of UC Santa Barbara. I did a little data cleaning on this multi-tabbed spreadsheet.\n\nlibrary(tidyverse)\neco_data &lt;- read.csv(\"~/DATA/data/reserve-eco-data.csv\")\n\nTake a quick look at how the data is structured.\n\nglimpse(eco_data)\n\nRows: 36\nColumns: 11\n$ UC.Natural.Reserve                        &lt;chr&gt; \"Año Nuevo Island Reserve (s…\n$ X..Unique.Species..excluding.ssp....var.. &lt;int&gt; 0, 42, 55, 87, 150, 159, 170…\n$ X..Taxa.including.ssp....var.             &lt;int&gt; 0, 45, 72, 88, 151, 162, 173…\n$ Reserve.Size..ha.                         &lt;int&gt; 10, 18624, 8, 11, 69, 22, 24…\n$ Elevation.Low..m.                         &lt;int&gt; 0, 0, 0, 0, 0, 1250, 21, 0, …\n$ Elevation.High..m.                        &lt;int&gt; 13, 742, 2, 15, 12, 4012, 58…\n$ Elevation.Range..m.                       &lt;int&gt; 13, 742, 2, 15, 12, 2762, 37…\n$ Precipitation..cm.                        &lt;int&gt; 50, 50, 22, 62, 77, 32, 46, …\n$ Temperature.Low...C.                      &lt;chr&gt; \"4\", \"10\", \"9\", \"12\", \"6\", \"…\n$ Temperature.High...C.                     &lt;chr&gt; \"24\", \"22\", \"25\", \"15\", \"24\"…\n$ X                                         &lt;chr&gt; \"24\", \"22\", \"25\", \"15\", \"24\"…\n\n\nData clean up and header labeling.\n\neco_data &lt;- eco_data[1:10]\nnames(eco_data)[1:10] &lt;- paste(c(\"reserve\", \"unique\", \"taxa\", \"size\", \"elevation_low\", \"elevation_high\", \"elevation_range\",\"precip\", \"temp_low\", \"temp_high\"))\nnames(eco_data)\n\n [1] \"reserve\"         \"unique\"          \"taxa\"            \"size\"           \n [5] \"elevation_low\"   \"elevation_high\"  \"elevation_range\" \"precip\"         \n [9] \"temp_low\"        \"temp_high\"      \n\neco_data$temp_high &lt;- as.numeric(eco_data$temp_high)\n\nThe classic precipitation vs. temperature ecological plot.\n\nclassic &lt;- ggplot(eco_data, aes(x=temp_high, y = precip)) +\ngeom_point() +\nscale_x_continuous(name=\"High Temp (C)\") +\nscale_y_continuous(name=\"Precipitation (mm)\")\nclassic\n\n\n\n\n\n\n\n\nAnother quick plot.\n\nelevation_plot1 &lt;- ggplot(eco_data, aes(x=elevation_range, y = unique)) +\ngeom_point() +\nscale_x_continuous(name=\"Elevation Range (m)\") +\nscale_y_continuous(name=\"Number of Unique Species\")\nelevation_plot1\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/post_thumbnails/reserve_elevation_species.png\")"
  },
  {
    "objectID": "posts/2024-08-29-NatureJournalTeacherTraining.html",
    "href": "posts/2024-08-29-NatureJournalTeacherTraining.html",
    "title": "Montology Zines - Nature Journaling",
    "section": "",
    "text": "I started the Mount Shasta Nature Journaling Club a few years ago, but we are now getting back into the groove of offering regular meet-ups. Darmera Studios started offering weekly donations based meet-ups at for Nature Journaling every Sunday from 3:30-5:30. It has been really fun to focus on developing curiosity based methods that incorperate pictures, words and numbers.\nTo get even better at teaching ecology/plant biology, I am enrolled in the Wild Wonder Foundation’s Nature Journaling Teacher Training Program. All of my notes from the program (like the rubric sketchnote above), will be available for a free download or a few dollars to have a physical copy to offset printing costs.\nAs part of the program I am developing some activities that are custom to the Mount Shasta/Dunsmuir/Weed/McCloud bioregion relating to fire, fire recovery, and rare plants.\nMore to come in the upcoming posts!"
  },
  {
    "objectID": "posts/2023-05-05-fire-ecology-class-1.html",
    "href": "posts/2023-05-05-fire-ecology-class-1.html",
    "title": "Fire Ecology Class - 1",
    "section": "",
    "text": "Last month I co-taught a class on California Fire Ecology at the Blue Oak Ranch Reserve. The reserve is part of the UC Reserve system and is one of the many sites I am collecting data at for a larger project looking at fire impacts on California ecosystems and insect pollinators. I wrote about the reserve system in these other posts on fire data and environmental data.\nThe class was part of a larger course title Biogeography of the Bay Area taught by Andy Gottscho at Merrit College in Oakland, CA. The students were diverse in age, background and reason for attending, but a majority of the students were taking this class as an elective for a certificate in sustainability. The course has a number of readings that the students complete each week and then they meet in a different location around the Bay Area to talk about biogeographic topics such as ecology, geology, genetics, climate and evolution.\nFor my section I took a new teaching approach. I illustrated the students a series of three zines that contained all of the lecture notes and major concepts on fire, ecology, Blue Oak Reserve, plants and insects. We hiked around the reserve and I stopped in places where I noticed that one of the concepts could be taught. As an example, thick brush on part of a steep hillside versus grass in an open for how fire might behave in these two different micro habitats. The thick brush would burn hotter and ignite itself as the flames moved uphill easier. Fire would spread in the grass and could be spread very quickly by additional wind.\nThe next three posts will delve into the details of basic fire science and fire ecology utilizing the illustrations in the zines to tell the story of fire in the Blue Oak Ranch Reserve.\nAs a teaser, here are the three covers of the zines:"
  },
  {
    "objectID": "posts/2022-06-01-edward-stuhl-wildflowers/index.html",
    "href": "posts/2022-06-01-edward-stuhl-wildflowers/index.html",
    "title": "Edward Stuhl Wildflowers",
    "section": "",
    "text": "I have been working on identifying and painting various local wildflowers from the book Mount Shasta Wild Flowers A Field Guide featuring the water color paintings of Edward Stuhl. Stuhl was an artist and mountaineer that gradually painted 189 plants over a 50 year career exploring the greater Mount Shasta area. All of his paintings are available to view online at CSU Chico here. I was interested in what sort of publicly available observation data there was for some of the more rare species. I downloaded the original list here, and made a few quick formatting edits to get it ready to pull into R.\nLoad the libraries.\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rgbif)\nlibrary(data.table)\n\nPull in the data, take a quick look, and make a character vector of the species names for the GBIF query.\n\nshasta_plants &lt;- read_excel(\"~/DATA/data/mount.shasta.plant.list.edit.xlsx\")\n\nhead(shasta_plants)\n\n# A tibble: 6 × 5\n  ID           Family           Genus       species    `subspecies or variety`\n  &lt;chr&gt;        &lt;chr&gt;            &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;                  \n1 Ferns_Allies Dennstaedtiaceae Pteridium   aquilinum  var. pubescens         \n2 Ferns_Allies Dryopteridaceae  Polystichum scopulinum &lt;NA&gt;                   \n3 Ferns_Allies Equisetaceae     Equisetum   arvense    &lt;NA&gt;                   \n4 Ferns_Allies Equisetaceae     Equisetum   hyemale    ssp. affine            \n5 Ferns_Allies Ophioglossaceae  Botrychium  pinnatum   &lt;NA&gt;                   \n6 Ferns_Allies Ophioglossaceae  Botrychium  pumicola   &lt;NA&gt;                   \n\ndim(shasta_plants)\n\n[1] 482   5\n\nshasta_plants$query &lt;- as.character(paste(shasta_plants$Genus, shasta_plants$species))\nshasta_species &lt;- shasta_plants$query\nhead(shasta_species)\n\n[1] \"Pteridium aquilinum\"    \"Polystichum scopulinum\" \"Equisetum arvense\"     \n[4] \"Equisetum hyemale\"      \"Botrychium pinnatum\"    \"Botrychium pumicola\"   \n\n\nMake a polygon to query from within and run a GBIF query iterating through the shasta_species character vector. The query takes a while for building this webpage, so I am going to just load the result instead to list the objects. If you want to run the query uncomment the following few lines.\n\nmt_shasta_geometry &lt;- paste('POLYGON((-122.600528 41.551515, -122.001773 41.551515, -122.001773 41.252791, -122.600528 41.252791, -122.600528 41.551515))')\n\n# shasta_all &lt;- occ_data(scientificName = shasta_species, hasCoordinate = TRUE, limit = 100,\n#                   geometry = mt_shasta_geometry)\n\nload(\"~/DATA/data/Stuhl_Shasta_species_GBIF.RData\")\nls()\n\n[1] \"mt_shasta_geometry\" \"shasta_all\"         \"shasta_plants\"     \n[4] \"shasta_species\"    \n\n\nIterate through the GBIF query list and pull out the latitude and longitude of each observation and bind them all together.\n\nshasta_species_coords_list &lt;- vector(\"list\", length(shasta_species))\nnames(shasta_species_coords_list) &lt;- shasta_species\n\nfor (x in shasta_species) {\n  coords &lt;- shasta_all[[x]]$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\")]\n  shasta_species_coords_list[[x]] &lt;- data.frame(cbind(species = x, coords))\n}\n\nspecies_coord_df &lt;- rbindlist(shasta_species_coords_list, fill = T)\nhead(species_coord_df)\n\n               species decimalLongitude decimalLatitude occurrenceStatus\n1: Pteridium aquilinum        -122.3233        41.28727          PRESENT\n2: Pteridium aquilinum        -122.3304        41.31041          PRESENT\n3: Pteridium aquilinum        -122.0664        41.27251          PRESENT\n4: Pteridium aquilinum        -122.0780        41.28300          PRESENT\n5: Pteridium aquilinum        -122.3066        41.27987          PRESENT\n6: Pteridium aquilinum        -122.4471        41.44342          PRESENT\n\n\nMake a quick plot of the data removing the legend or it will overwhelm the plot with the large number of species.\n\nspecies_p1  &lt;- ggplot(species_coord_df, aes(x=decimalLongitude, y = decimalLatitude, color = species)) +\n                geom_point() +\n                labs(x = \"Longitude\", y = \"Latitude\", title = \"Mount Shasta Plant Species Observations\") + theme(legend.position=\"none\")\nspecies_p1\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/stuhl_species.png\")\n\nA lifetime of exploration just in my general area! I hope to share more paintings of the same species as I am out and about around Mount Shasta."
  },
  {
    "objectID": "posts/2021-04-26-gbif-miracle-mile-species/index.html",
    "href": "posts/2021-04-26-gbif-miracle-mile-species/index.html",
    "title": "Miracle Mile Conifer Species",
    "section": "",
    "text": "Introduction\nOverall, my research aims to understand how environmental factors, like wild fires, influence biodiversity. One of the most used databases for measuring biodiversity is the Global Biodiversity Information Facility GBIF. This is post is a brief introduction of how to use GBIF, using the example of mapping a few conifer species in California.\n\nLoad the libraries\n\nlibrary(rgbif)\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(maps)\nlibrary(leaflet)\n\n\n\n\nPart 1 -Mapping one species\nUsing the R package function occ_data() request data from the GBIF database with the species name, selecting the observations that have a coordinate, and limiting the query to 10000 observations.\n\npinus_balfouriana &lt;- occ_data(scientificName = \"Pinus balfouriana\", hasCoordinate = TRUE, limit = 1000)\n\nInspect the data structure.\n\nsummary(pinus_balfouriana)\n\n     Length Class  Mode\nmeta   4    -none- list\ndata 124    tbl_df list\n\n\nThere are many different groups that contribute data to GBIF. Make sure you cite them accordingly so we can continue to have a great stream of species occurrence data. As a a few examples this species has curated research grade observations from iNaturalist and many from the Humboldt State University.\n\nhead(gbif_citation(pinus_balfouriana), 2)\n\nWarning: gbif_citation() for occ_search() and occ_data() is deprecated. \nUse rgbif::occ_download() or rgbif::derived_dataset() instead.\n\n\n[[1]]\n&lt;&lt;rgbif citation&gt;&gt;\n   Citation: iNaturalist contributors, iNaturalist (2023). iNaturalist\n        Research-grade Observations. iNaturalist.org. Occurrence dataset\n        https://doi.org/10.15468/ab3s5x accessed via GBIF.org on 2023-03-29..\n        Accessed from R via rgbif (https://github.com/ropensci/rgbif) on\n        2023-03-29\n   Rights: http://creativecommons.org/licenses/by-nc/4.0/legalcode\n\n[[2]]\n&lt;&lt;rgbif citation&gt;&gt;\n   Citation: Rancho Santa Ana Botanic Garden (2023). RSA - California Botanic\n        Garden Herbarium. Occurrence dataset https://doi.org/10.15468/0yosx9\n        accessed via GBIF.org on 2023-03-29.. Accessed from R via rgbif\n        (https://github.com/ropensci/rgbif) on 2023-03-29\n   Rights: http://creativecommons.org/licenses/by-nc/4.0/legalcode\n\n\nTake a look at what types of data are collected.\n\nhead(names(pinus_balfouriana$data))\n\n[1] \"key\"              \"scientificName\"   \"decimalLatitude\"  \"decimalLongitude\"\n[5] \"issues\"           \"datasetKey\"      \n\n\nThe default GBIF query returns 126 columns of data. We do not have time to go through all of them for a single post so I will subset some important ones for some exploratory plotting purposes. Here I subset the Latitude and Longitude coordinates that we will use for mapping, if the species does occur (important for modeling in future posts), how uncertain the observation is in meters, and the references for the observation.\n\npinus_balfouriana_coords &lt;- pinus_balfouriana$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n\"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"references\")]\n\n\n# check out how the data is structured\nhead(pinus_balfouriana_coords)\n\n# A tibble: 6 × 5\n  decimalLongitude decimalLatitude occurrenceStatus coordinateUncertai…¹ refer…²\n             &lt;dbl&gt;           &lt;dbl&gt; &lt;chr&gt;                           &lt;dbl&gt; &lt;chr&gt;  \n1            -118.            36.5 PRESENT                             4 https:…\n2            -118.            36.5 PRESENT                             4 https:…\n3            -118.            36.5 PRESENT                            NA https:…\n4            -123.            41.2 PRESENT                            11 https:…\n5            -118.            36.5 PRESENT                            65 https:…\n6            -118.            36.5 PRESENT                            47 https:…\n# … with abbreviated variable names ¹​coordinateUncertaintyInMeters, ²​references\n\nsummary(pinus_balfouriana_coords)\n\n decimalLongitude decimalLatitude occurrenceStatus  \n Min.   :-123.3   Min.   :35.92   Length:1000       \n 1st Qu.:-118.4   1st Qu.:36.45   Class :character  \n Median :-118.4   Median :36.58   Mode  :character  \n Mean   :-118.8   Mean   :37.04                     \n 3rd Qu.:-118.3   3rd Qu.:36.62                     \n Max.   :-118.0   Max.   :42.01                     \n                                                    \n coordinateUncertaintyInMeters  references       \n Min.   :    2                 Length:1000       \n 1st Qu.:    5                 Class :character  \n Median :   19                 Mode  :character  \n Mean   : 2234                                   \n 3rd Qu.:  185                                   \n Max.   :28534                                   \n NA's   :777                                     \n\n# pinus_balfouriana_coords$decimalLongitude # remove this row of bad data\npinus_balfouriana_coords &lt;- slice(pinus_balfouriana_coords, -(278))\n\n\n# two map functions... be clear! There are a few map functions with these different libraries loaded.\n#?map()\nmaps::map(database = \"state\", region = \"california\")\npoints(pinus_balfouriana_coords[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"red\", cex = 3)\n\n\n\n\n\n\n\n\nSubset our search to only Northern California\n\nmm_geometry &lt;- paste('POLYGON((-124.4323 42.0021, -121.5045 42.0021, -121.5045 40.194, -124.4323 40.194, -124.4323 42.0021))')\n\n\npinus_balfouriana_NC &lt;- occ_data(scientificName = \"Pinus balfouriana\", hasCoordinate = TRUE, limit = 1000,\n                     geometry = mm_geometry )\nhead(pinus_balfouriana_NC)\n\n$meta\n$meta$offset\n[1] 0\n\n$meta$limit\n[1] 300\n\n$meta$endOfRecords\n[1] TRUE\n\n$meta$count\n[1] 151\n\n\n$data\n# A tibble: 151 × 125\n   key    scien…¹ decim…² decim…³ issues datas…⁴ publi…⁵ insta…⁶ publi…⁷ proto…⁸\n   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1 39470… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 2 39474… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 3 39472… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 4 39612… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 5 38729… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 6 38734… Pinus …    41.2   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 7 39609… Pinus …    40.9   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 8 40548… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n 9 38736… Pinus …    41.3   -123. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n10 39471… Pinus …    41.3   -122. cdc,c… 50c950… 28eb1a… 997448… US      DWC_AR…\n# … with 141 more rows, 115 more variables: lastCrawled &lt;chr&gt;,\n#   lastParsed &lt;chr&gt;, crawlId &lt;int&gt;, hostingOrganizationKey &lt;chr&gt;,\n#   basisOfRecord &lt;chr&gt;, occurrenceStatus &lt;chr&gt;, taxonKey &lt;int&gt;,\n#   kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;, classKey &lt;int&gt;, orderKey &lt;int&gt;,\n#   familyKey &lt;int&gt;, genusKey &lt;int&gt;, speciesKey &lt;int&gt;, acceptedTaxonKey &lt;int&gt;,\n#   acceptedScientificName &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;,\n#   family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;, genericName &lt;chr&gt;, …\n\npinus_balfouriana_NC_coords &lt;- pinus_balfouriana_NC$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nPlot the data in a few different ways to see if there is anything strange.\n\nplot(pinus_balfouriana_NC_coords$decimalLongitude, pinus_balfouriana_NC_coords$decimalLatitude) # examine the data\n\n\n\n\n\n\n\npinus_balfouriana_NC_coords %&gt;% leaflet() %&gt;% addTiles() %&gt;%\naddMarkers(~decimalLongitude, ~decimalLatitude)\n\n\n\n\n\n\n\nPart 2- Map Multiple species\nFirst test the workflow with only a few species then do entire batch.\n\n# The test is commented out. Uncomment to test first.\n# mm_species &lt;- c(\"Pinus balfouriana\", \"pinus albicaulis\", \"pinus monticola\") # uncomment to run small test version\n\n# Entire miracle mile species set\nmm_species &lt;- c(\"Pinus balfouriana\", \"pinus albicaulis\", \"pinus monticola\", \"pinus jeffreyi\", \"pinus ponderosa\", \"pinus contorta\", \"pinus lambertiana\", \"abies concolor\", \"abies magnifica\", \"abies lasiocarpa\", \"picea engelmannii\", \"picea breweriana\", \"tsuga mertensiana\", \"pseudotsuga menziesii\", \"taxus brevifolia\", \"calocedrus decurrens\", \"juniperus communis\", \"juniperus occidentalis\")\n\nmm_all &lt;- occ_data(scientificName = mm_species, hasCoordinate = TRUE, limit = 1000,\n                   geometry = mm_geometry)\nsummary(mm_all)\n\n                       Length Class  Mode\nPinus balfouriana      2      -none- list\npinus albicaulis       2      -none- list\npinus monticola        2      -none- list\npinus jeffreyi         2      -none- list\npinus ponderosa        2      -none- list\npinus contorta         2      -none- list\npinus lambertiana      2      -none- list\nabies concolor         2      -none- list\nabies magnifica        2      -none- list\nabies lasiocarpa       2      -none- list\npicea engelmannii      2      -none- list\npicea breweriana       2      -none- list\ntsuga mertensiana      2      -none- list\npseudotsuga menziesii  2      -none- list\ntaxus brevifolia       2      -none- list\ncalocedrus decurrens   2      -none- list\njuniperus communis     2      -none- list\njuniperus occidentalis 2      -none- list\n\nmm_species_coords_list &lt;- vector(\"list\", length(mm_species))\nnames(mm_species_coords_list) &lt;- mm_species\n\nfor (x in mm_species) {\n  coords &lt;- mm_all[[x]]$data[ , c(\"decimalLongitude\", \"decimalLatitude\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n  mm_species_coords_list[[x]] &lt;- data.frame(species = x, coords)\n}\n\n\nUsing the rbindlist() function from the data.frame package to take all of the species observations from a list to a large data.frame. The columns are the species name, the latitude and longitude coordinates, whether or not there was an observation, if there is any uncertainty about how accurate the GPS coordinate was, what platform the observation was made on, and the specific reference for the observation. Make sure you cite the references so we can keep these rich data streams coming!\n\ntree_df &lt;- rbindlist(mm_species_coords_list, fill = T)\ndim(tree_df)\n\n[1] 6643    7\n\nhead(tree_df)\n\n             species decimalLongitude decimalLatitude occurrenceStatus\n1: Pinus balfouriana        -122.7895        41.21823          PRESENT\n2: Pinus balfouriana        -122.7896        41.21239          PRESENT\n3: Pinus balfouriana        -122.4852        41.31694          PRESENT\n4: Pinus balfouriana        -122.8140        41.20379          PRESENT\n5: Pinus balfouriana        -122.7933        41.24757          PRESENT\n6: Pinus balfouriana        -122.7887        41.21986          PRESENT\n   coordinateUncertaintyInMeters institutionCode\n1:                            11     iNaturalist\n2:                            NA     iNaturalist\n3:                            15     iNaturalist\n4:                           258     iNaturalist\n5:                             4     iNaturalist\n6:                             8     iNaturalist\n                                           references\n1: https://www.inaturalist.org/observations/120244204\n2: https://www.inaturalist.org/observations/122764637\n3: https://www.inaturalist.org/observations/123619404\n4: https://www.inaturalist.org/observations/123747109\n5: https://www.inaturalist.org/observations/124097026\n6: https://www.inaturalist.org/observations/124337645\n\n\nJust take a quick look at the raw observations plotted by latitude and longitude.\nPlot all of the species on the California map.\n\nmaps::map(database = \"state\", region = \"california\")\npoints(tree_df[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", col = \"blue\", cex = 3)\n\n\n\n\n\n\n\n\nPlot all of the species using ggplot in case you want to visualize the species with something a bit fancier.\n\nmm_species_plot1  &lt;- ggplot(tree_df, aes(x=decimalLongitude, y = decimalLatitude, color = species)) +\n       geom_point() + labs(color = \"Species\", title = \"MM Zone\")\nmm_species_plot1\n\n\n\n\n\n\n\n\nThere is a lot more you can do for GBIF, but these notes should help for the purpose of mapping species occurrence. Now that the data is somewhat organized we can start doing some proper data cleaning and exploratory data analysis in a future post."
  },
  {
    "objectID": "posts/2022-11-01-trailrunzine/index.html",
    "href": "posts/2022-11-01-trailrunzine/index.html",
    "title": "Adventure Zines",
    "section": "",
    "text": "I have been making zines, or content for zines, while out and about. Here are a few recent examples for a trail run zine. I carry either a mechanical pencil and a blank zine made on rite-in-the-rain paper for rainy/snowy days or a regular piece of printer paper with a good technical pen. I cut out a piece of hard plastic coated cardboard that came as packaging for my running poles. I use this as a hard back to write on and attach the zine paper to it with a small clip. These go into my running vest until I find something on the trail I would like to capture. When I return home, I fill in some color with other pens or details based on photo references.\nIf you are interested in folding some of your own printer paper zines check out this helpful youtube tutorial.\nHere is how one of the trail running zines looks like unfolded.\n\n\n\n\nWater-proof paper vs. #20 printer paper\n\nRite-in-the-rain paper\nI had a grand plan to make zines out of Rite-in-the-rain paper. I have some of their notebooks and have used them extensively for field work. They are excellent for written notes and journaling, but much less so for art in my opinion. Rite paper is more expensive per sheet and I had to special order it. The paper works in most conditions, but the need for a pencil can be limiting as it is difficult to keep it from smearing the exposed sides of the zine while running. Using harder lead was one option, but it still smears. I have tried various technical pens and brushes with this paper, but do not like the results. The ink of the pens tend to sit on top of the paper without soaking in. This makes them more prone to smudging even after ample time to dry. Overall the feel of the paper is just not that good for this application and my large list of favorite drawing tools.\n\n\nRegular # 20 printer paper for the win!\nCheap and available at most drug or box stores, 20 pound (or greater), printer paper is a good option for a lightweight carry while out on runs. I just place the pre-folded zine, backing, and writing implement inside plastic bag when not in use. This paper is fine for 90% of conditions I plan to be out in and works with more pens.\nRite-in-the-rain paper (blue) vs. #20 printer paper (green) smudge comparison after 1 minute.\n\n\n\nHappy trails running and/or making adventure Zines!"
  },
  {
    "objectID": "posts/2022-12-07-baja-species-2/index.html",
    "href": "posts/2022-12-07-baja-species-2/index.html",
    "title": "Baja Species 2",
    "section": "",
    "text": "Introduction\nThe Crested caracara’s I talked about in my last post are sitting on top of a Giant Cardon Cacti (Pachycereus pringlei). I wanted to take a look to see if the cacti were as widely distributed in the area as the Caracaras.\n\nLoad the libraries\n\nlibrary(rgbif)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\nSubset our search to only Southern Baja Sur.\n\nbaja_geometry &lt;- paste('POLYGON((-112.632285206 22.4136232805, -109.1001807138 22.4136232805, -109.1001807138 25.4259663625, -112.632285206 25.4259663625, -112.632285206 22.4136232805))')\n\ncacti &lt;- occ_data(scientificName = \"Pachycereus pringlei\", hasCoordinate = TRUE, limit = 10000,\n                     geometry = baja_geometry )\n\ncacti_coords &lt;- cacti$data[ , c(\"decimalLongitude\", \"decimalLatitude\",\n \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\",\n  \"institutionCode\", \"references\")]\n\nI subset the larger dataset to just zoom in on Mexico and plot the appoximate location where my observation was.\n\ncacti_obs &lt;- data.frame(decimalLongitude = c(-110.18917658541324), decimalLatitude = c(23.369598786877447))\n\nworld_maps &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nmexico &lt;- subset(world_maps, name == \"Mexico\")\n\nggplot(data = mexico) +\n                geom_sf() +\n                geom_point(data = cacti_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red')\n\n\n\n\n\n\n\n\nZoom into the Baja penninsula and plot all the points. There have been many observations of both the Giant Cardon Cacti and the Crested caracara all over the general region I visited.\n\ntheme_set(theme_bw())\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = cacti_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue') +\n        geom_point(data = cacti_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red')\n\n\n\n\n\n\n\nggplot(data = mexico) +\n        geom_sf() +\n        geom_point(data = cacti_coords, aes(x = decimalLongitude, y = decimalLatitude), color = 'blue') +\n        geom_point(data = cacti_obs, aes(x = decimalLongitude, y = decimalLatitude), color = 'red') +\n        coord_sf(xlim = c(-115, -109), ylim = c(22.5, 27), expand = TRUE) +\n        xlab(\"Longitude\") + ylab(\"Latitude\")\n\n\n\n\n\n\n\nggsave(\"~/DATA/images/cardon-cacti-map.png\")"
  },
  {
    "objectID": "posts/2024-06-25-PyroscapesIssue1.html",
    "href": "posts/2024-06-25-PyroscapesIssue1.html",
    "title": "Montology Zines - Pyroscapes Issue 1.0",
    "section": "",
    "text": "Issue 1.0 - Adventure and Observational Gear\nAs wildfires become more common in the everyday lives of Californians, Cody seeks to increase awareness of how the natural fire cycle in California affects ecosystems, especially “pyrodiversity,” the fire variability across our landscapes. The Pyroscapes project focuses on the natural history of fire in California with an emphasis on the Cascade and Klamath Mountain ranges in Northern California. The unique geology, geography, climate, plant, and animal species in these mountain ranges all contribute to the area having large areas of high pyrodiversity stemming from its complicated fire history. While the rapid increase in environmental data could lead to more insights into how ecosystems work, there is also a disconnect from human-level observations that are crucial for our intuitive understanding of nature. This project aims to explore and reinforce the connection between large scale environmental datasets and human scale observation.\nLeveraging his background as a biologist, data scientist, and backcountry explorer, Cody links together ground level observations of writing, photos, and illustrations to satellite imagery, remote sensing data, and geospatial models. In this series, he explores backcountry areas of high, medium, and low pyrodiversity under human power by trail running, hiking, bikepacking, and backpacking. Incorporating observational data into scientific expeditions has a long tradition. This project continues that tradition by merging modern data analysis tools with old school explorer journal entries for a fresh look at how fire influences California ecosystems.\nIn this issue Cody discusses his gear quiver along observational training principles for natural history exploration. The combination of these skills is essential for good backcountry exploration across California’s wild pyroscapes.\n\nMontology Studios creates illustrated Zines and media around the theme of mountains and culture. Think of this Zine as a cross between National Geographic, punk rock, adventure, natural history and data science. Each zine has a specific sub-theme. Some previous themes have been trail running, fire ecology, adventure vans, and frugality.\nSign up for the newsletter to learn how to pre-order or check out the Etsy Shop to purchase copies of previous issues of the zine."
  },
  {
    "objectID": "posts/2022-10-25-ADSA-Sketchnote.html",
    "href": "posts/2022-10-25-ADSA-Sketchnote.html",
    "title": "ADSA Meeting Sketchnote",
    "section": "",
    "text": "Academic Data Science Alliance (ADSA) Career Workshop Sketchnote\nThe Academic Data Science Alliance (ADSA) and US Research Software Engineer Association (US-RSE) hosted a fall workshop on career tracks. The group was really committed and we wrote a rough draft of a book during a two day workshop! The goal was to identify the problems and write a handbook for data scientists or software engineers pursuing careers within academia. Contributions by Data Scientists and Software Engineers are often critical for projects to be completed and maintained after publication, but there currently is not a good career track model within academia to maintain talent.\nThe sketchnote I illustrated above shows the major workflow of the meeting. We had an introduction and problem definitions at the top and then broke out into smaller groups to tackle the 8 chapters (Intro, Need, Position, etc.) of the forthcoming book. The moderators ensured there was near immediate feedback sessions and time for incorporating comments and feedback. The workshop was run like a 2 day academic paper writing session with rapid critical feedback. After the first session, everyone was feeling a bit weary to get feedback that quickly. In the end though, it was the perfect way to write a draft of a book in 2 days!"
  },
  {
    "objectID": "posts/2023-03-17-ImageXD.html",
    "href": "posts/2023-03-17-ImageXD.html",
    "title": "ImageXD Meeting Sketchnotes",
    "section": "",
    "text": "I participated, lead some sessions, and did some live sketchnote taking at ImageXD-2023. Below is the write-up I did for BIDS. If you are interested in sketchnotes, checkout my sketchnote portfolio.\nResearchers from across domains (XD) that use imaging data participated in ImageXD 2023. The two day workshop brought together imaging experts from diverse fields such as medical, biodiversity, machine learning, and software development. Each day had a blend of talks in the morning with “unconference” breakout working groups that were decided daily based on overlapping interests and questions formed and posted as part of a community question board.\nCheck out a detailed write-up by our co-sponsor Academic Data Science Alliance (ADSA): ImageXD Write-up\nBelow are some live sketchnotes of the event that I captured:\n\n\n\nDay 1 talk sketchnotes outline major ideas in the talks that were given by Sharmila Majumdar - UCSF professor and Director of the Center of Intelligent Imaging, Sara Beery - Assistant Professor at MIT and Visiting Researcher at Google on wildlife computer vision, Catherine Nakalembe - Africa Program Director for NASA Harvest and Assistant Professor at the University of Maryland’s Department of Geographical Sciences on food security, and Stéfan van der Walt - Researcher at UC Berkeley and Founder of scikit-image.\n\n\n\nSimilar to Day 1, Day 2 talk sketchnotes outline major ideas in the talks given by Dan Chitwood - plant biologist and Assistant Professor in the Departments of Horticulture and Computational Mathematics, Science & Engineering at Michigan State University on leaf shape morphometrics, Harry Chao - Assistant Professor of Computer Science & Engineering at The Ohio State University on training machine learning models for feature detection, and Kira Evans- Software Engineer at the Chan Zuckerberg Initiative on the Napari image processing Python package.\nThank you to the ImageXD sponsors: Chan Zuckerberg Initiative Alfred P. Sloan Foundation"
  },
  {
    "objectID": "posts/2021-03-15-tidy-data-intro.html",
    "href": "posts/2021-03-15-tidy-data-intro.html",
    "title": "Cycling Commuting Data 1",
    "section": "",
    "text": "Cycle Commuting Data\nFor the last few years I commuted to work most days by bicycle along the Martin Luther King Jr. Regional Shoreline Park park in Oakland, CA. This will be a series of data science posts exploring personal data collected by my smart watch and publicly available weather, nature and biodiversity data. It is my hope that this will show into the brain of how a data scientist thinks, learns, asks questions, creates models, and visualizes data from right in their back yard.\nWe will be using the tidyverse package today to explore this dataset. Load the package.\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(leaflet)\nI will do another post on how to make this dataset from exercise watch data at another time.\nHere is the base dataset we will be working with.\nload(\"MLK-park-commute.RData\")\nTo do some exploratory data analysis, let’s visualize some of the dataframe columns to get a feel for what the data represents. First I like to take a look at the data structure and get a feel for the variables.\nls()\nhead(commute)\ndim(commute)\nsummary(commute)\nConvert the dataframe into a tibble which is a tidyverse dataframe that has some additional properties to make it easier to examine what is going on.\ncommute &lt;- as_tibble(commute)\nhead(commute)\nPassing data around and filtering instead of creating new dataframes for everything is one of the features of tidyverse that I like the best. It is a different way of thinking that becomes more intuitive over time. Below I take the commute tibble pass it to filter to grab a specific single date. filter() then passes the filtered data to leaflet which plots the latitude and longitude data on an Openmaps popup in the browser.\ncommute %&gt;% filter(date(commute$datetime) == \"2018-08-29\") %&gt;%\nleaflet() %&gt;% addTiles() %&gt;%\naddPolylines(~lon, ~lat, color = 'blue', opacity = 1, weight = 10)\n\n\n\nMLK-shoreline-commute\n\n\nspeed_plot &lt;- ggplot(commute, aes(x=speed.kmh)) +\n  geom_histogram()\nspeed_plot\nggsave(\"speed-commute-plot.png\")\n\nThe watch that I have has the ability to detect heart rate and it works fairly well if your wrist is not moving around compared to the much more accurate heart rate strap. Here I create a new column of data that breaks up the heart rate information into different zones roughly corresponding to different physiological states. These zones are defined by\ncommute$HRzone &lt;- cut(commute$hr.bpm,c(0, 105, 150, 160, 174, 188, 200))\nlevels(commute$HRzone) = c(\"R\",\"Z1\",\"Z2\",\"Z3\",\"Z4\",\"Z5\")\nLet’s take a look at the heart rate data. First plotting a histogram.\nbpm_plot &lt;- ggplot(commute, aes(x=hr.bpm)) +\n  geom_histogram()\nbpm_plot\nggsave(\"heart-rate-commute-bpm_plot.png\")\n\nLet’s add the heart rate zone information as color and then do some axis labeling and clean up.\nbpm_plot2 &lt;- ggplot(commute, aes(x=hr.bpm, fill = HRzone)) +\n       geom_histogram() +\n       scale_x_continuous(name=\"Heart Rate (Beats Per Minute)\", limits=c(0, 200)) +\n       scale_y_continuous(name=\"Count\", limits=c(0, 80000))\nbpm_plot2\nggsave(\"heart-rate-commute-bpm_plot2.png\")\n\nYou can see in the figure above that I spent most of my commuting time in low Z1 or the recovery heart rate zone. It was harder to do Z1-Z3 workouts on the commuting bike because I often had to go directly into meetings after a quick shower. This was frustrating at first, but I grew to love the slower pace and over the few years got to observe some amazing tidal changes, bird migrations, wildflower blooms, sunrises and sunsets along the MLK shoreline. More on the natural history of the area in the subsequent posts."
  },
  {
    "objectID": "posts/2023-05-26-plants-insects.html",
    "href": "posts/2023-05-26-plants-insects.html",
    "title": "Fire Ecology Class - 4",
    "section": "",
    "text": "Animals that can move faster than a fire can move out of the burn zone and reestablish next to it.\n\n\n\n\nFire impacts arthropods differently depending on where they live and what part of their life cycle they are in at the time of the fire. If they are adults that can fly they can move versus being in a larval or juvenile stage where they might die in the fire.\n\n\n\n\nVariables contributing to seeds germinating post fire. The seed bank can vary in size depending on the fire history of an area. Each fire wipes out some of the seed bank and more frequent fires can completely wipe out the seed bank.\n\n\n\n\nPlants are sessile meaning they cannot move and must tolerate environmental variables. In general fire adapted plants protect the meristems by growing above ground fires or by having the meristems away from the more combustible parts (i.e. closer to the ground or underground). Fire adapted trees also protect themselves with thicker bark much closer to the ground that can burn, but not catch the rest of the tree on fire.\n\n\n\n\nMajor fire ecosystems across California that border human population density include grasslands, oak-woodlands, and chaparral. These are widely distributed across the state. In general, grasslands have short (S) fire cycles, oak-woodlands have medium (M) fire cycles and chaparral have (L) fire cycles.\n\n\n\n\nA few drought tolerant and “fire safe” plants that you can plant in most areas away from your house.\n\n\n\n\nCheatgrass is an invasive grass contributing to more frequent fires in some ecosystems where it has established itself. It grows in dense clusters that out compete the native vegetation and creates fire bridges between vegetation that do not occur naturally (i.e. in sparse sagebrush ecosystems)."
  },
  {
    "objectID": "posts/2023-07-07-explorer-exercise-1.html",
    "href": "posts/2023-07-07-explorer-exercise-1.html",
    "title": "Explorer Fitness - 1",
    "section": "",
    "text": "Illustration of the training hill next to our Casita from my travel sketchbook. Note, the person is not to add scale, they were part of a different illustration in my sketchbook. The hill was a 1/3 of a mile climb.\nThis will be the first in a series of posts on explorer fitness. I have previously posted about training here and the Crested Cara Cara birds I saw on one of my shorter runs here.\nThis training run served multiple goals, which is why I am using it as an example. Last year, my personal goal was to achieve 300,000 ft of elevation gain and loss throughout the year using human power. During my week-long stay in Baja California Sir, Mexico, I found myself near a short but steep hill next to our Casita. This hill provided an opportunity to gain and lose elevation in the middle of the desert while having the safety of water and food supply at the Casita.\nThe following image represents the workout from a heart rate perspective. I define the heart rate zones according to the book “Training for the Uphill Athlete.”\nFrom my trained perspective, the heart rate zones break down as follows:\n\n120-155 - Zone 1 - Nose breathing pace, all-day pace\n156-162 - Zone 2 - Avoid if possible, too hard for Zone 1, too easy for Zone 3\n163-173 - Zone 3 - 1.5-hour pace for me, or many shorter bursts\n174-184 - Zone 4 - Shorter HARD efforts\n185-195 - Zone 5 - Pushing max pace/effort\n\n\nDuring each repetition while ascending, I was in Zone 3, and then I quickly recovered on the way down, moving through Zone 2 into Zone 1 repeatedly. After this intense effort, I achieved my yearly goal a few days later with a few smaller efforts."
  },
  {
    "objectID": "posts/2022-09-01-shastasketchersdrinkanddraw/index.html",
    "href": "posts/2022-09-01-shastasketchersdrinkanddraw/index.html",
    "title": "Shasta Sketchers",
    "section": "",
    "text": "I have been meeting up with Dustin Bonivert at least once a week to do some live sketching, chat about art process, and taste some micro-brews. We decided to make our meet-ups a community event once a month hosted at a few businesses in town that sell craft beer. To find out more about upcoming events please visit our group at Shasta Sketchers.\nIf you like my sketches you can check out the sketchbook section of my art portfolio website or follow me on instagram codymarkelz.\nI put together a flier based on some of the live sketches I did at these businesses.\n\n\n\nHere are some other sketches I made on-sight at Deadwood Supply Co.."
  },
  {
    "objectID": "posts/2024-05-05-Darmera-Art-Studio-Open.html",
    "href": "posts/2024-05-05-Darmera-Art-Studio-Open.html",
    "title": "Darmera Studios Opening",
    "section": "",
    "text": "Gallery Opening\nWe opened the gallery to the public yesterday. The opening had nearly 100 people come through! We were so excited about the turn out. “Life By The River” featured art from 13 artists across painting, illustration, mixed media, photography and sculpture. The image of the show is a painting by Davis Elliott titled: “September (Tribute to Bragwyn)”.\nDarmera has three main spaces. The gallery space is in the front facing Dunsmuir Ave. The middle space is a classroom for the various art classes and retreats we are be teaching. The back warehouse space is for our art studios.\nSign-up for our newsletter containing information about gallery shows, classes, workshops, and events.\nFollow us on Instagram - @darmera.studio"
  },
  {
    "objectID": "art/HeadwatersPoster2025.html",
    "href": "art/HeadwatersPoster2025.html",
    "title": "Headwaters Trail Run Poster",
    "section": "",
    "text": "A commission for the 2025 Headwaters Trail Run Race. The poster features the diversity of pine cones that are present throughout the Headwaters course. The cones are arranged in the pyramid shape representing the relative elevation band the species inhabits.\nFrom top to bottom, left to right:\n\nWhite Bark Pine (Pinus albicaulis)\nShasta Red Fir (Abies magnifica var. shastensis)\nFoxtail Pine (Pinus balfouriana)\nWestern White Pine (Pinus monticola)\nLodgepole Pine (Pinus contorta)\nIncense Cedar (Calocedrus decurrens)\nJeffery Pine (Pinus jeffreyi)\nPacific Yew (Taxus brevifolia)\nWhite Fir (Abies concolor var. lowiana)\nKnobcone Pine (Pinus attenuata)\nPort Orford Cedar (Chamaecyparis lawsoniana)\nDouglas Fir (Pseudotsuga menziesii)\nPonderosa Pine (Pinus ponderosa)\nSugar Pine (Pinus lambertiana)\n\nI ran this race on a slightly different course in 2022. You can read about it in this post: Headwaters Run. I plan on running this race again this year."
  },
  {
    "objectID": "art/UBI-Sketchnotes.html",
    "href": "art/UBI-Sketchnotes.html",
    "title": "UBI Sketchnotes",
    "section": "",
    "text": "You can read more about the class here: UBI Class Blog Post.\nYou can checkout a published zine with all of my sketchnote illustrations: Bike Wrench Issue 1"
  },
  {
    "objectID": "art/PCT-jack-alana-din-map.html",
    "href": "art/PCT-jack-alana-din-map.html",
    "title": "PCT Map",
    "section": "",
    "text": "PCT Northern California\nMy friends hiked most of the PCT Southbound with a baby!\nPublished illustrations for the book “You Carry the Tent, I’ll Carry the Baby: One Family’s Journey on the Pacific Crest Trail”"
  },
  {
    "objectID": "art/PCT-jack-alana-din-Washington.html",
    "href": "art/PCT-jack-alana-din-Washington.html",
    "title": "PCT Book Northern California",
    "section": "",
    "text": "PCT Northern California\nMy friends hiked most of the PCT Southbound with a baby!\nPublished illustrations for the book “You Carry the Tent, I’ll Carry the Baby: One Family’s Journey on the Pacific Crest Trail”"
  },
  {
    "objectID": "art/run.html",
    "href": "art/run.html",
    "title": "Run",
    "section": "",
    "text": "Comic book art for local trail ultra-run. Read more about the race here.\n\n\n\n\n\nCaryn trail running up to Horse Camp (2420m, 7950 ft) on Mount Shasta.\n\n\n\n\n\nCaryn trail running on the PCT with Mount Shasta in the background.\n\n\n\n\n\nTrail running in the Northern Cascades, WA and a view of our adventure van (NSBG) gear garage under our bed."
  },
  {
    "objectID": "art/bikepacking-rig.html",
    "href": "art/bikepacking-rig.html",
    "title": "Bikepacking Rig",
    "section": "",
    "text": "Bike packing bike set-up"
  },
  {
    "objectID": "art/IllustratorBagWebRes.html",
    "href": "art/IllustratorBagWebRes.html",
    "title": "Illustrator Bag",
    "section": "",
    "text": "The story behind how this bag was made: Field Illustrator Bag Post"
  },
  {
    "objectID": "art/PCT-jack-alana-din-Oregon.html",
    "href": "art/PCT-jack-alana-din-Oregon.html",
    "title": "PCT Book Oregon",
    "section": "",
    "text": "PCT Northern California\nMy friends hiked most of the PCT Southbound with a baby!\nPublished illustrations for the book “You Carry the Tent, I’ll Carry the Baby: One Family’s Journey on the Pacific Crest Trail”"
  },
  {
    "objectID": "art/caryn-MTB-Moab.html",
    "href": "art/caryn-MTB-Moab.html",
    "title": "Caryn Biking Moab",
    "section": "",
    "text": "Bike packing bike set-up."
  },
  {
    "objectID": "science/PhD_projects.html",
    "href": "science/PhD_projects.html",
    "title": "PhD Projects",
    "section": "",
    "text": "PhD Dissertation Projects\nDuring graduate school I was interested in doing a mixture of field, molecular, computational, and engineering projects. Thanks in part to the freedom afforded by a NSF Graduate Research Fellowship, I designed research projects to answer open questions in the climate change literature that incorporated these four components. Here is a copy of my dissertation.\n\n\nAbstract\nThe balance between photosynthetic carbon dioxide (CO2) assimilation and respiratory CO2 release influence plant growth, crop yields, and the ability of terrestrial ecosystems to offset ~2-3 Gt CO2 yr -1 of anthropogenic emissions. Rising atmospheric CO2 concentration ([CO2]) this century will impact plant photosynthesis and respiration with consequences for plant productivity in natural and agro-ecosystems. The capacity of all plants to grow and ecosystems to store carbon in elevated [CO2] can be dependent on interactions with water, nutrients, and plant developmental processes. The purpose of this thesis is to address fundamental knowledge gaps in understanding plant responses to the interaction between elevated [CO2] with water, nitrogen (N), and leaf developmental programs: (1) determine what is the mechanistic response of maize C4 photosynthesis to a three way interaction between atmospheric [CO2], N availability and drought utilizing the unique capabilities of a Free Air CO2 Enrichment (FACE) field experiment; (2) determine the transcriptional reprogramming of leaf respiration in response to growth in elevated [CO2] and variable N supply using Arabidopsis thaliana and a custom built gas exchange system; (3) determine when in leaf development the transcriptional reprogramming of respiration occurs in response to elevated [CO2] by studying the detailed developmental timelines and molecular events of leaf growth in A. thaliana. The knowledge gaps addressed in this work will help inform crop improvement and models that predict future ecosystem function and global food supply in the face of a changing climate.\n\n\nElevated [CO2], Nitrogen Availability, and Drought in Maize\nC4 plants, like maize, make up some of the most valued crops and important keystone species in subtropical grassland ecosystems. In C4 plants, CO2 is converted into a four carbon acid and pumped from the mesophyll cells into the bundle sheath cells where it is re-released near the site of RUBISCO. This mechanism makes C4 photosynthesis an efficient way for the plants to fix carbon used in growth processes. C4 plants are theoretically not suppose to have a stimulation in photosynthetic carbon assimilation when grown in elevated [CO2] because of this CO2 concentrating mechanism. In this paper I designed a field experiment to test the interaction of elevated [CO2] and nitrogen availability on maize growth, carbon assimilation and development. I found that elevated [CO2] did not provide a benefit to carbon assimilation or growth in either nitrogen treatment early in the field season. A late season drought allowed me to test what the effects of water availability had on these interactions. By merging the field data with a model of C4 photosynthesis I showed that drought made photosynthetic capacity sensitive to elevated [CO2] and that low nitrogen availability exaggerated this difference. paper\n\n\nFIGURE 1: Photosynthetic modeling combining field and lab gas exchange data showing CO2 by nitrogen interaction only in drought conditions. Summary of A/ci response curves and CO2 supply functions for maize grown at ambient [CO2] (Panels A and C, dashed lines) and elevated [CO2] (Panels B and D, solid lines) as well as high N (black lines) and limiting N (grey lines) during non-drought conditions (panels A and B) or drought conditions (panels C and D). Stomatal limitation (SL) to carbon assimilation was also calculated for each treatment.\n\n\n\nElevated [CO2], Nitrogen Availability, and Respiration- in Arabidopsis thaliana\nPlant respiration is a very important component of plant growth and global carbon cycle, but less studied compared to photosynthesis. This is especially true for night-time dark respiration. There was a great deal of confusion in the literature about whether growth in elevated [CO2] would increase, decrease, or not change the dark respiration rates of plants. After conducting a literature review on the topic I found that various papers were not consistent in how they quantified respiration and there appeared to be evidence for an interaction between elevated [CO2] and nitrogen availability on plant respiration. I wanted to understand the molecular mechanisms of this interaction so I chose to work with Arabidopsis thaliana because of the suite of molecular and genetic tools available. The problem with using A. thaliana was that there was no standard equipment to measure leaf respiration in a plant this small so I designed a custom respiration system (see below) in order to very accurately quantify leaf respiratory CO2 efflux. This new chamber, allowed me show that the elevated [CO2] did stimulate leaf respiration regardless of nitrogen availability, but the response was dampened in the limiting nitrogen condition. This finding was supported biochemically and from gene expression micro-array data. paper\n\n\nFIGURE 2: Molecular support for biochemical and physiological increase in respiration in elevated [CO2]. This figure is a graphical summary of genes encoding components of the TCA cycle and mitochondrial electron transport chain that responded to elevated [CO2] during midnight (top) or midday (bottom) and limiting N (left) or ample N (right). Each blue (positive percentage change) and yellow (negative percentage change) represents the mean percentage change of a unique transcript that responded significantly (P &lt; 0.05) to elevated [CO2].\n\n\n\nElevated [CO2], Leaf Development, and Respiration in Arabidopsis thaliana\nAs leaves develop they gradually transition from being a sink tissue to a source tissue. Sink tissues rely on transport of carbon and other nutrient resources from mature source tissues in order to maintain high growth rates through this developmental transition. A majority of the elevated [CO2] literature had focused on mature tissues. I was curious if the stimulation in respiration rates that I observed in mature tissues were also occurring in younger tissues. The answer to this question has important implications to how plant respiration is modeled in whole plant growth models. I found that as leaves grew and became source tissues the stimulation in leaf respiration in elevated [CO2] increased. This finding was also supported biochemically and from gene expression data. This developmental gradient in respiratory response makes sense in that the mature tissue is best able to incorporate the CO2 into sugars and that more of that carbohydrate is being respired at night to fuel the whole plant growth stimulation in elevated [CO2]. paper\n\n\nFIGURE 3: Graph showing the developmental dependency of the leaf respiration response to elevated [CO2]. Midnight dark respiration rates (R) of leaf 10 of Arabidopsis thaliana grown at ambient [CO2] (370 ppm) or elevated [CO2] (750 ppm), at 23, 24 (Expanding) or 29, 30 and 31 (Mature) days after germination. Scale bar = 1 cm."
  },
  {
    "objectID": "science/engineering.html",
    "href": "science/engineering.html",
    "title": "Engineering Projects",
    "section": "",
    "text": "Arabidopsis growth imaging system\nCo-designed and co-developed part of the software to quantify Arabidopsis 2D and 3D growth for thousands of individuals simultaneously.\nAn_2017\nAn_2016\n\n\n\nSingle leaf Arabidopsis respiration\nDesigned and built the hardware and software for accurately quantifying single leaf respiration rates.\nMarkelz_2014a\nMarkelz_2014b\n\n\n\nLICOR 6400 chamber head\nDesigned customs chamber head to accurately quantify soybean leaf dark respiration in the field.\nGillespie_2012\n\n\n\nIndividual fruitfly respiration while on methamphetamine\nModified the hardware from the single leaf chamber to accurately quantify differences in individual fruit fly respiration rates that had been treated with or without methamphetamine.\nWalters_2012"
  },
  {
    "objectID": "science/undergraduate_projects.html",
    "href": "science/undergraduate_projects.html",
    "title": "Undergraduate Research Projects",
    "section": "",
    "text": "Senior Distinction Project\nThesis Title: How will elevated [CO2] alter soil and plant water status of the C3-crop soybean and the C4-crop maize? Advisors: Dr. Donald Ort and Dr. Andrew Leakey\nThis work was published as part of the following paper: Future carbon dioxide concentration decreases canopy evapotranspiration and soil water depletion by field-grown maize- Hussain et al. 2013\n\n\n\nSoybean nitrogen metabolism under elevated [CO2]\nElemental nitrogen analysis and microarray data visualization from soybean leaves grown at ambient or elevated [CO2]. Advisor: Dr. Andrew Leakey\n\n\n\nBehavioral Ecology of Social Insects\nThis research was focused on characterizing task interference behavior in the fungal growing ant colonies Atta cephalotes. I manipulated waste management activities within the nest of laboratory colonies to study task preference within the colonies’ divisions of labor. Advisor: Dr. Sam Beshers\n\n\n\nMicrolepedoptera of Illinois Hill Prairies\nField collection and organization of micro-lepidoptera samples from hill prairie sites along a Illinois River Basin transect. Advisors: Dr. Terry Harrison and Dr. May Berenbaum"
  },
  {
    "objectID": "science/artsciencehack.html",
    "href": "science/artsciencehack.html",
    "title": "Hackathons - ArtScienceHack v1.0 + v2.0",
    "section": "",
    "text": "Concept\nI have two really good friends that are both professional designers/artists living in Chicago. Every year over the holiday break we would discuss how fun it would be to do a collaborative project, but never got around to doing one because of our busy schedules. This year we planned a few months in advance to have a hackathon style four day work session between Christmas and New Years. We wanted to move as quickly as possible and make as many ideas happen as possible in our short time frame. We discussed all of the different data sets that I had as part of various research projects and the ones that turned out to be most appealing were the high-throughput plant imaging data sets.\n\n\nCrew\nJohnny Clark is an architect and designer currently working for Jordan Mozer. The Mozer firm’s was our home base for creativity, industrial grade internet, and organic shape object art inspiration. Matt Harlan is a freelance designer and screen printing guru. Matt also works on this awesome architecture zine called soiled. And myself.\n\n\nArabidopsis thaliana architectural forms\nI just learned Rhino about four hours earlier so this was a successful visualization of an Arabidopsis growth time series. This is a mosaic of the steps in constructing this city. As part of another project in the lab I have thousands of Arabidopsis timelapse images. I quickly modified some other code for a quick python script to binerize the plant relative to the background and then quantified plant area in each successive image. The height of the buildings correspond to the difference in rosette size from the previous timepoint. Then I got to really have fun and make a skyline and city in the shape of one of the plant outlines. Moving around the city that I had just made was really trippy especially when doing it from a 6 foot tall person perspective. The upper right is a view from the skydeck of a building. Johnny helped me make the surface transparent to give it a glass coffeetable feel. I think overall this project might help me pass Architecture 101.\n\nArabidopsis City visualization using rosette growth data:\n\n\n\n\n\nBrassica rapa architectural forms\nFor another lab project I am doing some 3D reconstructions of Brassica rapa. I have loads of this kind of data, but thought it would be nice to see what an artist’s perspective might use the data for. First things first, it was much too dense to load into memory so we randomly sampled the point cloud and made some wire frames by nearest neighbor searches. The renderings are simple and elegant. Then Johnny took it to the next level with a Rhino plugin called Grasshopper to produce the metaball renderings and octree representations of the data. A free plugin that might make the cost of Rhino worth it.\n\nThe original 3D data of a brassica plant:\n\n\n\nBrassica rapa sparse proximity structure:\n\n\n\nBrassica rapa metaball space structure:\n\n\n\n\n\nArtSciencHack - v2.0\n\nConcept\nFor the second iteration of the ArtScienceHack in 2016, we decided to bring our art, design, science, engineering, and data skills together to work on a single project for 48 hours. We had very minimal exposure to the processing language prior to starting this, but I had experience building things in many other languages. Processing is a good first language to learn for designers and artists so we started there.\n\n\nGoals\nRapidly learn the basics of processing and make an interactive model of plant growth that takes human movement as input to the model.\n\n\nOutcomes\nOverall the hackathon was a success. We had an interactive model of plant growth that had a fundamental trade-off function built in. This trade-off is visualized as the root:shoot ratio using hand control through the hacked xbox connect controller.\n\nArtScienceHack-v-2.0 Plant Growth Model Xbox Connect Hack:\n\nCode available here."
  },
  {
    "objectID": "science/science_communications.html",
    "href": "science/science_communications.html",
    "title": "Sci-Comm Projects",
    "section": "",
    "text": "Academic Data Science Alliance (ADSA) Career Workshop Sketchnote\nThis project consists of managing content creation for the Berkeley Institute for Data Science (BIDS) through social media, email newsletters, and annual reports. This project extends my research at Environmental Change Fellowship research at BIDS through the creation of a series of long-form articles that include infographics, data visualizations and illustrations aimed at a general scientific audience. Additionally, I am collaborating with BIDS affiliated scientists to make research summaries in the form of sketchnotes, visual abstracts and short articles aimed at a general science audience to help fulfill broader impacts goals of grants. Additionally, attending professional data science meetings and doing live sketchnotes like the one pictured above.\nAs part of this role I am co-hosting a series of workshops for graduate students and post-docs on the use of Quarto on static document publishing and reproducible data analysis for environmental and data journalism projects."
  },
  {
    "objectID": "science/biodiversity_fire.html",
    "href": "science/biodiversity_fire.html",
    "title": "Berkeley Institute for Data Science",
    "section": "",
    "text": "This project is part of a fellowship in Global Change Research at the Berkeley Institute of Data Science (BIDS).\nAs we enter an era of unprecedented amounts of data, we also face the defining challenge of our age - global environmental change. From automated environmental sensors to satellite imaging to emerging DNA technologies, the data that describes the world around us will aid us in how we approach the many challenges of a changing climate. By harnessing this data we can develop data science tools that allow us to predict, and further define how we as a society can respond and mitigate the effects of climate change.\nMy main project is developing a multi-level modeling framework that incorporates environmental variables, satellite data, historical species observations, and environmental DNA (eDNA) data across fire regimes in Californian ecosystems. The collated data sets and resulting modeling framework will enable researchers to better understand the impact of historical and recent fire on arthropod communities in sites across the University of California Natural Reserve System. We hope that this framework will be able to be applied to other open questions regarding fire and biodiversity. This is a unique project that is rooted in basic research but provides a framework for interoperability between different data types. The project outcomes will be disseminated through a research blog and tutorials, science communications through illustrations and zines, open-source code, and open publications.\n\n\n\n\nHolmquist AJ, Markelz RJC, Martinez CC, Gillespie RG (2024). The importance of habitat type and historical fire regimes in arthropod community response following large-scale wildfires. Global Change Biology (30:1). paper\nOpen-source data pipeline for analysis: The code repository is available here. The repository also contains instructions on how to make reproducible data science docker containers for each of the major steps in the analysis pipeline. We made the docker container with the largest number of software dependencies available on docker hub here.\nData Science by Design (DSxD) Anthology Volume 2: Our Environment. Fire Zine published in printed anthology. Learn more here\nBook Chapter Co-author and Back Cover Illustration - Van Tuyl, Steve (Ed.). (2023). Hiring, Managing, and Retaining Data Scientists and Research Software Engineers in Academia: A Career Guidebook from ADSA and US-RSE. Zenodo. https://doi.org/10.5281/zenodo.8274378\nTeaching: Field fire ecology at Merrit Community College using zines and illustrations. I recently blogged about a introductory fire ecology class at the Blue Oak Ranch Reserve. The reserve is part of the UC Reserve system and is one of the many sites I am collecting data at for a larger project looking at fire impacts on California ecosystems and insect pollinators. Other blog posts in the series are also available: post 2, post 3, post 4. I wrote about the reserve system in these other posts on fire data and environmental data.\nCollated data resources page: Fire Data Resources.\n\n\n\n\n\nPyrodiversity of the Klamath Mountains\n\nExtend research findings through blog posts about fire in California’s Klamath Mountain Range that will be recombined to make up a feature length general science article. Other products: data visualization, data storytelling, science zines\nWildland Urban Interface in California - fire science and climate impacts. Products: data visualization, data storytelling, science zines\nPost-fire impacts on aquatic insect biodiversity - Products: data visualization, data storytelling, science zines\n\nEveryday Data Visualization Initiative\n\nCreate an open-source book (using www.quarto.org), code, and graduate/postdoc training workshops centered around collecting, summarizing, modeling, and visualizing data that is collected from common devices and applications.\nPersonal data source examples include fitbit/apple watch movement data, geotagged meta-data of images on phones, and social media network data.\nPublicly available data would include weather, climate, traffic, or map data.\nEach lesson will be written as a series of blog posts for content creation and shared through social media channels as they are developed.\n\n\n\n\n\nCiera Martinez, Biodiversity and Environmental Sciences Lead, BIDS\nRosemary Gillespie, Professor, Environmental Science, Policy, and Management\nDavid Ackerly, Dean, College of Natural Resource\nKarthik Ram, Senior Research Data Scientist, BIDS\nAccenture Applied Intelligence, to fully harness the data landscape and expertise available. Through independent fellowships, Accenture supports BID’s research and educational objectives in data science with current foci on environment and energy, ethical AI, and social justice."
  },
  {
    "objectID": "science/biodiversity_fire.html#project-overview",
    "href": "science/biodiversity_fire.html#project-overview",
    "title": "Berkeley Institute for Data Science",
    "section": "",
    "text": "This project is part of a fellowship in Global Change Research at the Berkeley Institute of Data Science (BIDS).\nAs we enter an era of unprecedented amounts of data, we also face the defining challenge of our age - global environmental change. From automated environmental sensors to satellite imaging to emerging DNA technologies, the data that describes the world around us will aid us in how we approach the many challenges of a changing climate. By harnessing this data we can develop data science tools that allow us to predict, and further define how we as a society can respond and mitigate the effects of climate change.\nMy main project is developing a multi-level modeling framework that incorporates environmental variables, satellite data, historical species observations, and environmental DNA (eDNA) data across fire regimes in Californian ecosystems. The collated data sets and resulting modeling framework will enable researchers to better understand the impact of historical and recent fire on arthropod communities in sites across the University of California Natural Reserve System. We hope that this framework will be able to be applied to other open questions regarding fire and biodiversity. This is a unique project that is rooted in basic research but provides a framework for interoperability between different data types. The project outcomes will be disseminated through a research blog and tutorials, science communications through illustrations and zines, open-source code, and open publications.\n\n\n\n\nHolmquist AJ, Markelz RJC, Martinez CC, Gillespie RG (2024). The importance of habitat type and historical fire regimes in arthropod community response following large-scale wildfires. Global Change Biology (30:1). paper\nOpen-source data pipeline for analysis: The code repository is available here. The repository also contains instructions on how to make reproducible data science docker containers for each of the major steps in the analysis pipeline. We made the docker container with the largest number of software dependencies available on docker hub here.\nData Science by Design (DSxD) Anthology Volume 2: Our Environment. Fire Zine published in printed anthology. Learn more here\nBook Chapter Co-author and Back Cover Illustration - Van Tuyl, Steve (Ed.). (2023). Hiring, Managing, and Retaining Data Scientists and Research Software Engineers in Academia: A Career Guidebook from ADSA and US-RSE. Zenodo. https://doi.org/10.5281/zenodo.8274378\nTeaching: Field fire ecology at Merrit Community College using zines and illustrations. I recently blogged about a introductory fire ecology class at the Blue Oak Ranch Reserve. The reserve is part of the UC Reserve system and is one of the many sites I am collecting data at for a larger project looking at fire impacts on California ecosystems and insect pollinators. Other blog posts in the series are also available: post 2, post 3, post 4. I wrote about the reserve system in these other posts on fire data and environmental data.\nCollated data resources page: Fire Data Resources.\n\n\n\n\n\nPyrodiversity of the Klamath Mountains\n\nExtend research findings through blog posts about fire in California’s Klamath Mountain Range that will be recombined to make up a feature length general science article. Other products: data visualization, data storytelling, science zines\nWildland Urban Interface in California - fire science and climate impacts. Products: data visualization, data storytelling, science zines\nPost-fire impacts on aquatic insect biodiversity - Products: data visualization, data storytelling, science zines\n\nEveryday Data Visualization Initiative\n\nCreate an open-source book (using www.quarto.org), code, and graduate/postdoc training workshops centered around collecting, summarizing, modeling, and visualizing data that is collected from common devices and applications.\nPersonal data source examples include fitbit/apple watch movement data, geotagged meta-data of images on phones, and social media network data.\nPublicly available data would include weather, climate, traffic, or map data.\nEach lesson will be written as a series of blog posts for content creation and shared through social media channels as they are developed.\n\n\n\n\n\nCiera Martinez, Biodiversity and Environmental Sciences Lead, BIDS\nRosemary Gillespie, Professor, Environmental Science, Policy, and Management\nDavid Ackerly, Dean, College of Natural Resource\nKarthik Ram, Senior Research Data Scientist, BIDS\nAccenture Applied Intelligence, to fully harness the data landscape and expertise available. Through independent fellowships, Accenture supports BID’s research and educational objectives in data science with current foci on environment and energy, ethical AI, and social justice."
  },
  {
    "objectID": "science/teaching.html",
    "href": "science/teaching.html",
    "title": "Science Teaching and Mentoring",
    "section": "",
    "text": "In an age of information abundance, the university is now a place where students come to learn active strategies for navigating this sea of information in a scientifically literate way. Through my experience I have found that one of the best ways for students to achieve this goal is to have a safe environment centered around projects where asking questions and thinking critically are encouraged. Scientific discovery is not achieved in a vacuum. Science is a social activity based on communicating ideas and structuring arguments supported by evidence. However, science is often not taught in an interactive way, but in a passive way. Biology is a particularly bad offender of teaching material as a long string of facts to be memorized. As a graduate student and a postdoc, I have used and refined many project-based learning strategies to engage students of different age groups, skill levels, and class sizes. I consider teaching and mentoring to be successful when students become more scientifically literate and/or gain the tools necessary to pursue their chosen careers in science or related fields.\nMentoring students on independent research projects is the most rewarding teaching experience because the project can be designed and individualized for the learning and career goals of the student. My approach is to ask for a one-year minimum commitment, allowing time for mentorship and for skill development. Students first learn the big picture view of science that includes how to read a scientific paper and perform a small literature review. At the same time, I help students design a short experiment to answer a simple question and collect a small dataset. This dataset is used to start teaching programming and data analysis as soon as possible because it takes the longest for students to learn. During weekly meetings students use a white board to explain their project and progress to myself and the other undergraduates that I mentor. This exercise has the students teaching one another about their projects and prepares the students to present a talk or poster at the undergraduate research conference. This research year takes students through the scientific process from question to experimental design to data analysis and interpretation to writing and presentation. After the first year, students are usually interested in staying for longer and then we write up their preliminary results as part of an undergraduate research fellowship to NSF or ASPB. This approach has successfully trained seven undergraduates and technicians that have gone on to scientific graduate programs.\nThrough my teaching and mentoring I have found that programming, data analysis, and data visualization are all necessary skills missing from most biology curriculum. An intro class on this topic is challenging to teach because in addition to learning new biological topics, students must also learn a new programming language. At UC Davis, I developed part of an open-source genomics lab class that teaches undergraduate biology students these skills. The course was taught using Linux virtual machines that ran off of portable USB drives allowing students to make mistakes and explore data sets without fear of crashing servers. Students also learned how to use Git for version control and www.github.com for collaboration and turning in assignments. The module that I created was on genetic networks. After a brief intro lecture each day, the students worked through an interactive online tutorial that taught the basics of network and graph theory. The students were then challenged to apply what they learned towards analyzing, visualizing and interpreting a large RNA-seq data set. This module emphasized the usefulness of applying mathematical abstractions and concepts towards understanding biological systems. Setting small programming goals designed to answer increasingly complex biological questions on real data sets is an effective way to teach computer science and bioinformatics in the same course. For example, a student in the class used her new skills to analyze a large sequencing dataset as part of her senior research project.\nI was a teaching assistant for the undergraduate-level general education class, Global Warming, Biofuels, and Food, which had 75 students at University of Illinois. Halfway through the semester, the instructor could no longer continue, so I stepped up to take over lecturing. This offered a unique opportunity for me to create and deliver lectures for a large lecture hall, and receive feedback on the student’s conceptual understanding during small-group discussion sections. For this course, I made the university wide “List of Teachers Ranked Excellent” based on student evaluations and received the Outstanding Teaching Award from the Department of Plant Biology. This opportunity sharpened my lecture preparation and delivery to focus on the important concepts by providing examples from the scientific literature or popular science articles.\nAs a teaching assistant for the graduate level class at University of Illinois, Plants and Global Change, I led or participated in two unique project-based learning approaches which engaged students and taught them course material in innovative ways: podcast development and formal debates. The podcast assignment aimed to teach science communication skills and to improve students’ knowledge of the topic area. Small student groups chose recent high-impact papers in the climate change literature as a focus of their podcast, and conducted literature reviews. I created tutorials on podcast recording and editing using the open-source audio editing software, Audacity. The students used this tutorial to record in-person or Skype interviews with the author, and add intro music and background information. This mixed media approach was a favorite with the students because they learned how media, other than writing, can be used to communicate important scientific ideas. These types of creative projects will be incorporated as part of future teaching opportunities that actively engage students beyond textbooks. This early content and methods were used as the precursor to the Audible Ecoscience podcast database project.\nAnother successful project-based teaching method used in this graduate-level course was a formal, parliamentary-style debate for scientifically contentious issues. After learning related material in lectures, teams of students were assigned to formalize arguments for or against a scientific proposition under the guidance of debate coaches, who were experts in the field. Debate topics included the role of human activity in climate change, and the potential for cellulosic biofuels to mitigate environmental impacts of fossil fuel use. I moderated the debates as a gavel-wielding judge in a powdered wig, preventing the debate from going over time or off topic. Students were personally invested, and so became well-versed, in their side of the debate, and they enjoyed the theatrics. These debates became so popular that students, postdocs, and professors who were not enrolled in or teaching the class would attend the debates and pose questions to the teams. The podcast and the debate were active learning exercises that engaged the students to work in teams, communicate science to a general audience, and make scientific arguments based on the literature. It is not only the volume of material that can be fit into a semester course, but also the quality of critical thinking and student engagement that determines their ability to comprehend the subject matter."
  },
  {
    "objectID": "science/plants-iview.html",
    "href": "science/plants-iview.html",
    "title": "Plants iView - Middle School Science",
    "section": "",
    "text": "Teaching a lesson at the Pollinatarium\n\nPlants iView\nI led a group of Illinois Plant Biology graduate students in creating middle school plant science curriculum to fit into an afterschool program at Urbana Middle School. As a group we wrote two successful grants to secure funding from the ASPB Educational Foundation Grant and the Illinois Public Engagement Grant for this project. This platform is still in use as a major outreach project for the Illinois Department of Plant Biology. All of the course materials, teacher discussion forum, and student blogs can be accessed through the Plants iView website. We made sure that the lessons met national and Illinois specific educational standards for grades 6-8. The graduate students then taught all the lessons for the program.\n\n\nPlants iView High-Throughput Phenotyping, Raspberry Pi, Computer Vision\nA new module for Plants iView emphasizing quantitative biology and experimental design for 7th graders. Students set up Raspberry Pi Camera rigs to take time-lapse photos of Arabidopsis plants growing in control or drought conditions. Learning the basics of computer vision and plotting students were able to interpret the plant growth data to see if their hypotheses were supported. It was great working with Jennifer Quebedeaux on this module.\n\n\n\n\nQuantitative biology by 7th graders at Champaign, IL Unit 4 School District"
  },
  {
    "objectID": "montology/MechE.html",
    "href": "montology/MechE.html",
    "title": "MechE",
    "section": "",
    "text": "Mechanical Engineering (MechE) I am working through my DIY undergraduate and masters curriculum to learn mechanical engineering basics and design through bicycles. So far, so good. It helps to make explainer sketchnotes, write what I learned, and then try to explain it to someone. Enter the graphic novel characters. A piece I rewrote in the graphic novel script is that they studied some MechE in college and they use a bikepacking bike for their main mode of transportation through the mountains. They are now my classmates. How do they talk to one another when they are learning? How do they talk to me? How do they talk to the two other character types?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Pyroscapes Presentation\n\n\n\nVizThink\n\nnature journal\n\nnature\n\nadventure\n\nillustration\n\ntalk\n\nwatercolor\n\nink\n\nmontology\n\nscience\n\nfire\n\npyroscapes\n\ndata viz\n\n\n\nPublic Talk at Mt. Shasta Sisson Museum\n\n\n\n\n\nOct 27, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nShasta Alpine Hut\n\n\n\nillustration\n\ncomic\n\nnature\n\nnature journal\n\npen\n\nink\n\nwatercolor\n\nLBET\n\n\n\nObservations\n\n\n\n\n\nSep 15, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nShasta Alpine Hut Map\n\n\n\nillustration\n\ncommission\n\nalpine\n\nhut\n\ndigital\n\nmontology\n\ncartography\n\nmap\n\nLBET\n\nVizThink\n\n\n\nLogo and Map Commission\n\n\n\n\n\nAug 15, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nRed Green Color Blind\n\n\n\ntrail run\n\nadventure\n\nroute\n\nillustration\n\nmontology\n\n\n\n3 Peak Adventure Trail Run\n\n\n\n\n\nJul 15, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nHeadwaters Trail Run + Poster\n\n\n\nillustration\n\ncommission\n\nwatercolor\n\nink\n\nmontology\n\n\n\n56 km Ultra-Run\n\n\n\n\n\nJun 25, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nDarmera Anniversary Art Show\n\n\n\nIllustration\n\ngallery\n\ndarmera\n\nstudio\n\n\n\n1 Year Anniversary\n\n\n\n\n\nMay 10, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nCody Markelz - Field Illustration Bag\n\n\n\nIllustration\n\nsewing\n\nart bag\n\nfield illustrator\n\nwatercolor\n\nadventure\n\nplein-air\n\nbike art\n\n\n\nIllustrator Field Bag\n\n\n\n\n\nApr 27, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nArizona Nature Journaling Retreat\n\n\n\nIllustration\n\nnature journal\n\nfield illustrator\n\ndesert\n\ncacti\n\ntrail run\n\nwatercolor\n\nink\n\n\n\nIllustrated Review\n\n\n\n\n\nApr 5, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nTrail Running Comic\n\n\n\nIllustration\n\nwatercolor\n\nink\n\ncomics\n\ntrail run\n\nfield illustrator\n\n\n\nTraditional Media Comic Process\n\n\n\n\n\nFeb 28, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nJanuary 2025 Review\n\n\n\nIllustration\n\nreview\n\nproject\n\nskiing\n\n\n\nIllustrated Review\n\n\n\n\n\nJan 30, 2025\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nDecember 2024 Review\n\n\n\nIllustration\n\nreview\n\nproject\n\nskiing\n\n\n\nIllustrated Review\n\n\n\n\n\nDec 30, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\n2025 Goals\n\n\n\ndarmera\n\nmontology\n\nart\n\nscience\n\nadventure\n\nillustration\n\nzine\n\nwatercolor\n\nink\n\nnature journal\n\nadventure\n\ngoals\n\n\n\n2025-2030 Goals Revised\n\n\n\n\n\nDec 15, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 2024 Review\n\n\n\ndarmera\n\nstudio\n\ngallery\n\nclassroom\n\nart\n\nscience\n\nadventure\n\nillustration\n\nzine\n\npinecones\n\nwatercolor\n\nink\n\nnature journal\n\ncomposition\n\npaper cutter\n\n\n\nIllustrated Review\n\n\n\n\n\nNov 30, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\n5 Year Goals\n\n\n\ndarmera\n\nmontology\n\nart\n\nscience\n\nadventure\n\nillustration\n\nzine\n\nwatercolor\n\nink\n\nnature journal\n\nadventure\n\ngoals\n\n\n\n2025-2030\n\n\n\n\n\nNov 15, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nNatural Processes\n\n\n\ndarmera\n\nstudio\n\ngallery\n\nclassroom\n\nart\n\nscience\n\nadventure\n\nillustration\n\nzine\n\npinecones\n\nwatercolor\n\nink\n\nnature journal\n\ncomposition\n\npaper cutter\n\n\n\nGallery Art Show\n\n\n\n\n\nOct 25, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMontology - Year 39\n\n\n\nmontology\n\nadventure\n\njournal zine\n\nzine\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\ndata journalism\n\nexplore\n\n\n\nIllustrated Journal Zine\n\n\n\n\n\nOct 6, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMontology - Year 38\n\n\n\nmontology\n\nadventure\n\njournal zine\n\nzine\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\ndata journalism\n\nexplore\n\n\n\nIllustrated Journal Zine\n\n\n\n\n\nOct 5, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMount Shasta Alpine Hut Caretaker\n\n\n\nzine\n\nteaching\n\nresearch\n\necology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nnature journal\n\nhiking\n\ndata journalism\n\ntrail run\n\nalpine\n\nalpine ecology\n\n\n\nAlpine Nature Journaling\n\n\n\n\n\nSep 9, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMontology Zines - Nature Journaling\n\n\n\nzine\n\nteaching\n\nresearch\n\nfire\n\necology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nnature journal\n\nhiking\n\nfire ecology\n\ndata journalism\n\nfire runner\n\n\n\nNature Journal Teaching Zine\n\n\n\n\n\nAug 29, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMontology Zines - Bike Wrench Issue 1.0\n\n\n\nzine\n\nmontology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nsketchnotes\n\nbicycles\n\nmechanic\n\nbike\n\nwrench\n\nsuspension\n\nwheel\n\n\n\n–Published\n\n\n\n\n\nJul 8, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMontology Zines - Pyroscapes Issue 1.0\n\n\n\nzine\n\nteaching\n\nresearch\n\nfire\n\necology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nnature journal\n\nhiking\n\nfire ecology\n\ndata journalism\n\nfire runner\n\n\n\n–Published\n\n\n\n\n\nJun 25, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nDarmera Studios Opening\n\n\n\ndarmera\n\nstudio\n\ngallery\n\nclassroom\n\nart\n\nscience\n\nadventure\n\nillustration\n\nzine\n\n\n\n– Art Gallery - Classroom - Studio\n\n\n\n\n\nMay 5, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nCertified Fox Suspension Technician + DT Swiss Wheelbuilder\n\n\n\nzine\n\nmontology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nsketchnotes\n\nbicycles\n\nmechanic\n\nbike\n\nwrench\n\nsuspension\n\nwheel\n\n\n\n–United Bicycle Institute Advanced Certifications\n\n\n\n\n\nApr 25, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMontology Zines\n\n\n\nmontology\n\ndarmera\n\nstudio\n\ngallery\n\nclassroom\n\nart\n\nscience\n\nadventure\n\nillustration\n\nzine\n\nnature journal\n\nteaching\n\ndata visualization\n\nfire runner\n\n\n\n– Adventure Zine Company\n\n\n\n\n\nMar 1, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nDarmera Studios\n\n\n\ndarmera\n\nstudio\n\ngallery\n\nclassroom\n\nart\n\nscience\n\nadventure\n\nillustration\n\nzine\n\n\n\n– Art Gallery - Classroom - Studio\n\n\n\n\n\nFeb 16, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nNotorious SBG\n\n\n\nNSBG\n\nvan\n\nad-VAN-ture\n\nadventure\n\nillustration\n\nzine\n\n\n\n– Adventure Van\n\n\n\n\n\nFeb 1, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nFire Impacts on Pollinators Across Ecosystem Types\n\n\n\nresearch\n\nfire\n\necology\n\nscience\n\nvisualization\n\nillustration\n\npollinators\n\narthropods\n\neDNA\n\nzine\n\nfire runner\n\n\n\n– Our paper was published\n\n\n\n\n\nJan 16, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMount Shasta Summit Pass Data\n\n\n\ndata\n\nmeta-data\n\nresearch\n\njournalism\n\ndata journalism\n\navalanche\n\nski touring\n\nback country skiing\n\nsearch and rescue\n\nmount shasta\n\n\n\n–Visualizing Search and Rescue Data\n\n\n\n\n\nJan 5, 2024\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nProfessional Bicycle Mechanic\n\n\n\nzine\n\nmontology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nsketchnotes\n\nbicycles\n\nmechanic\n\nbike\n\nwrench\n\nsuspension\n\nwheel\n\n\n\n–United Bicycle Institute Pro Class\n\n\n\n\n\nDec 20, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nFire Impacts on Pollinators Across Ecosystem Types\n\n\n\nresearch\n\nfire\n\necology\n\nscience\n\nvisualization\n\nillustration\n\npollinators\n\narthropods\n\neDNA\n\nzine\n\nfire runner\n\n\n\n– Our paper was accepted!\n\n\n\n\n\nNov 20, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nScraping Weather Data 4\n\n\n\nweather\n\ndata\n\nscraping\n\nwebsite\n\nmeta-data\n\nresearch\n\njournalism\n\ndata journalism\n\navalanche\n\nski touring\n\nback country skiing\n\n\n\n–Avalanche Data Animation\n\n\n\n\n\nOct 1, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nExplorer Fitness - 4\n\n\n\nGIS\n\ndata\n\nexercise\n\nquantified self\n\nheart rate\n\ncardio\n\ntraining\n\nadventure\n\nexplore\n\nfitness\n\nfire runner\n\nexplorer fitness\n\ndata journalism\n\n\n\nHeart Rate Zone Training 4\n\n\n\n\n\nSep 28, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nScraping Weather Data 3\n\n\n\nweather\n\ndata\n\nscraping\n\nwebsite\n\nmeta-data\n\nresearch\n\njournalism\n\ndata journalism\n\navalanche\n\nski touring\n\nback country skiing\n\n\n\n–Visualizing Weather Data\n\n\n\n\n\nSep 23, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nScraping Weather Data 2\n\n\n\nweather\n\ndata\n\nscraping\n\nwebsite\n\nmeta-data\n\nresearch\n\njournalism\n\ndata journalism\n\navalanche\n\nski touring\n\nback country skiing\n\n\n\n–Avalanche Website Data Scraping\n\n\n\n\n\nSep 22, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nScraping Weather Data 1\n\n\n\nweather\n\ndata\n\nscraping\n\nwebsite\n\nmeta-data\n\nresearch\n\njournalism\n\ndata journalism\n\navalanche\n\nski touring\n\nback country skiing\n\n\n\n–Docker Container Set-up\n\n\n\n\n\nSep 21, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nExplorer Fitness - 3\n\n\n\nGIS\n\ndata\n\nexercise\n\nquantified self\n\nheart rate\n\ncardio\n\ntraining\n\nadventure\n\nexplore\n\nfitness\n\nfire runner\n\nexplorer fitness\n\ndata journalism\n\n\n\nHeart Rate Zone Training 2\n\n\n\n\n\nSep 1, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nAcademic Data Science Career Guide\n\n\n\nresearch\n\nBIDS\n\nscicomm\n\nscience\n\ndata science\n\ncommunications\n\nvisualization\n\nillustration\n\ncontent creation\n\nscicomm portfolio\n\nsketchnotes\n\ndesign\n\nADSA\n\nUS-RSE\n\n\n\n–Book Published\n\n\n\n\n\nAug 18, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nExplorer Planning Toolkit - 1\n\n\n\nfire runner\n\nultra-running\n\necology\n\nscicomm\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nnature journal\n\nexercise\n\nexplore\n\nquantified-self\n\nheart rate\n\nplanning\n\n\n\nThe Route\n\n\n\n\n\nAug 11, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nArt Science Hackathon v2.0\n\n\n\nartsciencehack\n\noutreach\n\ndesign\n\nvisualization\n\nart\n\ndata\n\nsculpture\n\nscience\n\nexplore\n\nxbox kinect\n\n\n\n–Design Experiments With Data\n\n\n\n\n\nAug 2, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nFire Impacts on Pollinators Across Ecosystem Types\n\n\n\nresearch\n\nfire\n\necology\n\nscience\n\nvisualization\n\nillustration\n\npollinators\n\narthropods\n\neDNA\n\nzine\n\n\n\n– Our pre-print is up!\n\n\n\n\n\nJul 28, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nExplorer Fitness - 2\n\n\n\nexercise\n\nexplore\n\nvisualization\n\nquantified-self\n\nheart rate\n\nexplorer fitness\n\ndata journalism\n\nfire runner\n\n\n\nHeart Rate Zone Training\n\n\n\n\n\nJul 21, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nExplorer Observation Toolkit - 1\n\n\n\ntracking\n\nnature observation\n\necology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nnature journal\n\nfire runner\n\n\n\nTracking Observational Techniques 1\n\n\n\n\n\nJul 14, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nExplorer Fitness - 1\n\n\n\nexercise\n\nexplore\n\nvisualization\n\nquantified self\n\nheart rate\n\nexplorer fitness\n\ndata journalism\n\nillustration\n\nfire runner\n\n\n\nHeart Rate Zone Training\n\n\n\n\n\nJul 7, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nCyanotype Printing\n\n\n\nzine\n\nteaching\n\nvisualization\n\nillustration\n\n\n\nPrinting using the Sun’s UV\n\n\n\n\n\nJun 30, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nData Science by Design (DSxD) - Fire Zine\n\n\n\nzine\n\nteaching\n\nresearch\n\nfire\n\necology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\n\n\n–My first published artwork in “Our Environment” is out!\n\n\n\n\n\nJun 21, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nFire Ecology Class - 4\n\n\n\nzine\n\nteaching\n\nresearch\n\nfire\n\necology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nnature journal\n\nhiking\n\nfire ecology\n\ndata journalism\n\nfire runner\n\n\n\n–Teaching Fire Ecology Through Zines 4\n\n\n\n\n\nMay 26, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nFire Ecology Class - 3\n\n\n\nzine\n\nteaching\n\nresearch\n\nfire\n\necology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nnature journal\n\nhiking\n\nfire ecology\n\ndata journalism\n\nfire runner\n\n\n\n–Teaching Fire Ecology Through Zines 3\n\n\n\n\n\nMay 19, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nFire Ecology Class - 2\n\n\n\nzine\n\nteaching\n\nresearch\n\nfire\n\necology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nnature journal\n\nhiking\n\nfire ecology\n\ndata journalism\n\nfire runner\n\n\n\n–Teaching Fire Ecology Through Zines 2\n\n\n\n\n\nMay 8, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nFire Ecology Class - 1\n\n\n\nzine\n\nteaching\n\nresearch\n\nfire\n\necology\n\nscicomm\n\nscicomm portfolio\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\nnature journal\n\nhiking\n\nfire ecology\n\ndata journalism\n\nfire runner\n\n\n\n–Teaching Fire Ecology Through Zines 1\n\n\n\n\n\nMay 1, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nImageXD Meeting Sketchnotes\n\n\n\nresearch\n\nBIDS\n\nscicomm\n\nscience\n\ndata science\n\ncommunications\n\nvisualization\n\nillustration\n\ncontent creation\n\nscicomm portfolio\n\nsketchnotes\n\ndesign\n\nADSA\n\nimage data\n\nImageXD\n\n\n\n–Live Meeting Sketchnotes and Summary\n\n\n\n\n\nMar 17, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nBIDS Illustration\n\n\n\nproject management\n\nresearch\n\nBIDS\n\nscicomm\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\ncontent creation\n\nscicomm portfolio\n\nurban sketching\n\n\n\n–Building Illustration for Event\n\n\n\n\n\nFeb 23, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nScience Communications Manager\n\n\n\nproject management\n\nresearch\n\nBIDS\n\nscicomm\n\nscience\n\ncommunications\n\nvisualization\n\nillustration\n\ncontent creation\n\n\n\n–Professional SciComm, Illustration, DataViz Projects\n\n\n\n\n\nFeb 15, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Obsidian - 3\n\n\n\nproject management\n\nresearch\n\ntools\n\nobsidian\n\n\n\n–Personal Obsidian Knowledge Workflow\n\n\n\n\n\nFeb 1, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nTrinity Alps Trail Run\n\n\n\nspecies distribution\n\nmodeling\n\nGIS\n\nmaps\n\ndata\n\ntrail run\n\nexercise\n\nexplore\n\nillustration\n\n\n\n–White Pines Revisited\n\n\n\n\n\nJan 7, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMount Eddy Trail Run\n\n\n\nspecies distribution\n\nmodeling\n\nGIS\n\nmaps\n\ndata\n\ntrail run\n\nexercise\n\nexplore\n\nillustration\n\n\n\n–Foxtail Pines Revisited\n\n\n\n\n\nJan 1, 2023\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nBaja Species 3\n\n\n\nGIS\n\ndata\n\ntrail run\n\nhike\n\nexplore\n\nphotography\n\nnature journal\n\nzine\n\nadventure\n\nGBIF\n\nbaja\n\nmexico\n\ntravel\n\n\n\n–Sierra La Leguna Biodiversity\n\n\n\n\n\nDec 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nBaja Species 2\n\n\n\nGIS\n\ndata\n\ntrail run\n\nhike\n\nexplore\n\nphotography\n\nnature journal\n\nzine\n\nadventure\n\nGBIF\n\nbaja\n\nmexico\n\ncacti\n\n\n\n–Giant Cardon Cacti\n\n\n\n\n\nDec 7, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nBaja Species 1\n\n\n\nGIS\n\ndata\n\ntrail run\n\nhike\n\nexplore\n\nphotography\n\nnature journal\n\nzine\n\nadventure\n\nGBIF\n\nbaja\n\nmexico\n\n\n\n–Crested Cara Cara\n\n\n\n\n\nDec 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nAdventure Zines\n\n\n\nGIS\n\ndata\n\ntrail run\n\nhike\n\nexplore\n\nillustration\n\nnature journal\n\nzine\n\nadventure\n\nart\n\n\n\n–Trail Running Zines\n\n\n\n\n\nNov 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nADSA Meeting Sketchnote\n\n\n\nresearch\n\nBIDS\n\nscicomm\n\nscience\n\ndata science\n\ncommunications\n\nvisualization\n\nillustration\n\ncontent creation\n\nscicomm portfolio\n\nsketchnotes\n\ndesign\n\nADSA\n\nUS-RSE\n\n\n\n–Live Meeting Sketchnote and Summary\n\n\n\n\n\nOct 25, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nPyrodiversity\n\n\n\nGIS\n\ndata\n\nUSFS\n\nwildfire\n\ntrail run\n\nhike\n\nexplore\n\nnational geographic\n\nillustration\n\nnature journal\n\nfire runner\n\n\n\n–Fire History in the Klamath Mountains\n\n\n\n\n\nOct 14, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nSLAC Method for Comics Creation\n\n\n\nart\n\ncomics\n\ncolor\n\nprocess\n\nillustration\n\ncolor\n\nprocess art\n\ndrawing\n\nthumbnails\n\ncartographer\n\n\n\n–A Relentless Forward Progress Method\n\n\n\n\n\nOct 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nDSxD Sketchnote\n\n\n\nresearch\n\nBIDS\n\nscicomm\n\nscience\n\ndata science\n\ncommunications\n\nvisualization\n\nillustration\n\ncontent creation\n\nscicomm portfolio\n\nsketchnotes\n\ndesign\n\nDSxD\n\n\n\n–Live Meeting Sketchnote and Summary\n\n\n\n\n\nSep 30, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nShasta Sketchers\n\n\n\nart\n\nsketching\n\nadventure\n\nnature\n\nnature journal\n\nmount shasta\n\nshastasketchers\n\ncommunity\n\nillustration\n\ndarmera\n\n\n\n–Nature Journaling Club\n\n\n\n\n\nSep 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nShasta Sketchers\n\n\n\nart\n\nsketching\n\nadventure\n\nbeer\n\nbikes\n\nmount shasta\n\nshastasketchers\n\ncommunity\n\n\n\n–Monthly Drink and Draw\n\n\n\n\n\nSep 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nHeart Rate Data Analysis\n\n\n\nGIS\n\ndata\n\nexercise\n\nquantified self\n\nheart rate\n\ncardio\n\ntraining\n\nadventure\n\n\n\n–Exercise Data Analysis\n\n\n\n\n\nAug 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMount Shasta Wilderness Wildflowers\n\n\n\nspecies distribution\n\nGIS\n\nmaps\n\ndata\n\nhike\n\nexercise\n\nexplore\n\nAnemone occidentalis\n\nwildflowers\n\nplants\n\nGBIF\n\ndr. seuss\n\n\n\n–Anemone occidentalis population\n\n\n\n\n\nAug 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nArt-venture Kit and Sketches\n\n\n\nart\n\nexplore\n\nwater color\n\npaint\n\ndraw\n\nadventure\n\nsketch\n\nillustration\n\nfire runner\n\n\n\n–Lightweight Portable Art Kits\n\n\n\n\n\nJul 20, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nUC Reserve Fire Data\n\n\n\nGIS\n\nmaps\n\ndata\n\nfire\n\nwildfire\n\nclimate\n\nresearch\n\ngeospatial\n\nfire runner\n\n\n\n–2020 Fire Data Visualization\n\n\n\n\n\nJul 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nHeadwaters Race\n\n\n\nGIS\n\nmaps\n\ndata\n\ntrail run\n\nexercise\n\nrace\n\nexplore\n\n3D\n\n\n\n–56km Ultra Marathon\n\n\n\n\n\nJul 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nCalifornia Pitcher Plant\n\n\n\nspecies distribution\n\nGIS\n\nmaps\n\ndata\n\ntrail run\n\nexercise\n\nexplore\n\ncobra lily\n\nillustration\n\n\n\n–Cobra Lily (Darlingtonia californica)\n\n\n\n\n\nJun 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nEdward Stuhl Wildflowers\n\n\n\ndata\n\nscraping\n\nweb\n\nextraction\n\nmeta-data\n\nwater color\n\nwildflowers\n\nplants\n\nmount shasta\n\nstuhl\n\n\n\n–Mount Shasta Wildflowers GBIF data\n\n\n\n\n\nJun 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nBay Area Insects\n\n\n\nspecies distribution\n\nmodeling\n\nGIS\n\nmaps\n\nexplore\n\nGBIF\n\ndata visualization\n\n\n\n–Insect Species Occurance Data Visualization\n\n\n\n\n\nMay 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMiracle Mile Species 5 and 6\n\n\n\nspecies distribution\n\nmodeling\n\nGIS\n\nmaps\n\ndata\n\ntrail run\n\nexercise\n\nexplore\n\n\n\n–Jeffrey’s and Ponderosa Pine\n\n\n\n\n\nMay 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nSugar Pine (Pinus lambertiana)\n\n\n\nspecies distribution\n\nmodeling\n\nGIS\n\nmaps\n\ndata\n\ntrail run\n\nexercise\n\nexplore\n\nPCT\n\nsugar pine\n\nPacific Crest Trail\n\n\n\n–Another Miracle Mile Species\n\n\n\n\n\nApr 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMiracle Mile Species 2 and 3\n\n\n\nspecies distribution\n\nmodeling\n\nGIS\n\nmaps\n\ndata\n\ntrail run\n\nexercise\n\nexplore\n\n\n\n–Foxtail Pine and Western White Pine\n\n\n\n\n\nApr 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMiracle Mile Species 1\n\n\n\nspecies distribution\n\nmodeling\n\nGIS\n\nmaps\n\ndata\n\ntrail run\n\nexercise\n\nexplore\n\nillustration\n\n\n\n– Pacific Yew (Taxus brevifolia)\n\n\n\n\n\nMar 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nTrout and Food Species\n\n\n\nspecies distribution\n\nmodeling\n\nGBIF\n\nGIS\n\nmaps\n\ndata\n\ntrout\n\n\n\n–Overlapping Species Occurance Data\n\n\n\n\n\nMar 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nSki Touring Movement Data\n\n\n\ndata\n\nmovement\n\nski touring\n\ndata visualization\n\ndata integration\n\nmeta-data\n\n\n\n–Visualization of Ski-Tours Around Mount Shasta\n\n\n\n\n\nFeb 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nUC Reserve System Environmental Data\n\n\n\ndata\n\nresearch\n\nforest\n\nreserve\n\nfire\n\ntutorial\n\n\n\n–Basic Plotting of Environmental Variables\n\n\n\n\n\nFeb 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nGeneric Markdown Comic Script\n\n\n\ncomics\n\nart\n\nscript\n\nwriting\n\nrmarkdown\n\n\n\n–Comic Script Template\n\n\n\n\n\nJan 20, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nScraping Weather Data\n\n\n\nweather\n\ndata\n\nscraping\n\nwebsite\n\nmeta-data\n\nresearch\n\n\n\n–Avalanche Website Data Scraping\n\n\n\n\n\nJan 15, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nZotero + Obsidian\n\n\n\nproject management\n\nresearch\n\ntools\n\nobsidian\n\nzotero\n\n\n\n–Knowledge Graph with PDF Management\n\n\n\n\n\nJan 1, 2022\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Obsidian\n\n\n\nproject management\n\nresearch\n\ntools\n\nobsidian\n\n\n\n–Personal Knowledge Graph in Markdown\n\n\n\n\n\nDec 15, 2021\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Comic Book Coloring Process\n\n\n\nart\n\ncomics\n\ncolor\n\nprocess\n\nillustration\n\ncolor theory\n\n\n\n–Clip Studio Paint Coloring Workflow\n\n\n\n\n\nAug 25, 2021\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMLK Shoreline iNaturalist data\n\n\n\nnature\n\niNaturalist\n\nGIS\n\nmaps\n\n\n\n–Overlapping Exercise and Species Occurance Data\n\n\n\n\n\nJun 23, 2021\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nMiracle Mile Conifer Species\n\n\n\nspecies distribution\n\nmodeling\n\nGBIF\n\nGIS\n\nmaps\n\n\n\n–Mapping Species Occurance\n\n\n\n\n\nJun 17, 2021\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nCycling Commuting Data 1\n\n\n\ndata\n\ncycling\n\nmeta-data\n\nexercise\n\n\n\n–Introduction to Tidy Data in R\n\n\n\n\n\nMar 15, 2021\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Trello for Project Management\n\n\n\nproject management\n\ntrello\n\nGTD\n\nSCRUM\n\n\n\n–Kanban Project Management Workflow\n\n\n\n\n\nNov 18, 2015\n\n\nRJ Cody Markelz\n\n\n\n\n\n\n\n\n\n\n\n\nArt Science Hackathon v1.0\n\n\n\nartsciencehack\n\noutreach\n\ndesign\n\nvisualization\n\nart\n\ndata\n\nsculpture\n\nscience\n\nexplore\n\n\n\n–Design Experiments With Data\n\n\n\n\n\nJan 1, 2015\n\n\nRJ Cody Markelz\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Link Tree",
    "section": "",
    "text": "Art Portfolio: codymarkelz.art\n\n\nAdventure Zine publishing company: www.montology.studio\n\n\nCommunity art gallery/studio/classroom space: www.darmera.studio\n\n\nMastodon: @codymarkelz@sunny.garden\n\n\nInstagram: codymarkelz\n\n\nGumroad: codymarkelz\n\n\nTwitter: codymarkelz\n\n\nGithub: rjcmarkelz\n\n\nlinkedin: codymarkelz"
  }
]